[
    {
        "id": "2505.00049",
        "img_path": "2505.00049/x2.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Evaluating Emotional Responses in Large Language Models: Methods, Benchmarks, and Interaction Scenarios",
                "B. Analyzing Cognitive Metrics for AI Agents: Frameworks, Data Sources, and Usability Studies",
                "C. A Comprehensive Review of AI Communication Styles: Psychological Perspectives and Application Domains",
                "D. Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications",
                "E. Assessing User Engagement with Conversational Agents: Tools, Experimental Data, and Behavior Modeling"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications"
            ],
            "img_path": "2505.00049/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what single number represents the total count of distinct primary categories that structure the authors' systematic analysis, an analysis specifically undertaken to address documented omissions in prior comprehensive studies of LLM psychological characteristics?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 5",
                "D. 6",
                "E. 7"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "6"
            ],
            "img_path": "2505.00049/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00023",
        "img_path": "2505.00023/x1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. CORG: Analyzing Single-Source Contexts for Enhanced Question Answering",
                "B. CORG: Generating Answers from Complex, Interrelated Contexts",
                "C. Framework for Synthesizing Responses in Isolated Contextual Settings",
                "D. Techniques for Summarizing Independent Textual Data in QA Systems",
                "E. Approaches to Simple Context Understanding for Automated Answer Generation"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "CORG: Generating Answers from Complex, Interrelated Contexts"
            ],
            "img_path": "2505.00023/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single word best describes the crucial capability that individual, simple solutions (like question pluralization for distracting contexts or descriptor addition for ambiguous ones) are stated to collectively lack, thereby proving insufficient for simultaneously addressing the full range of distracting, ambiguous, counterfactual, and duplicated context interrelationships found in real-world corpora?",
            "options": [
                "A. Robustness",
                "B. Specificity",
                "C. Generalization",
                "D. Consistency",
                "E. Isolation"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Generalization"
            ],
            "img_path": "2505.00023/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00053",
        "img_path": "2505.00053/x1.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Yong Zheng",
                "B. Zhi-Yu Sun",
                "C. Yu-Nan Song",
                "D. Xiao-Dong Xu",
                "E. Bao-Hua Sun"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Xiao-Dong Xu"
            ],
            "img_path": "2505.00053/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what approximate flight path length, in meters, is attributed to the F0-F2 section of RIBLL2 when it was primarily used for studying p- or sd-shell nuclei, a limitation that prompted the development of the F4 platform to engage the separator's full 55m length for heavier nuclei research?",
            "options": [
                "A. 26",
                "B. 55",
                "C. 10.64",
                "D. 1.169",
                "E. 25"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "26"
            ],
            "img_path": "2505.00053/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00021",
        "img_path": "2505.00021/plot.jpg",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Ustnlp16 at SemEval-2025 Task 9: Enhancing Semantic Understanding with Attention Mechanisms",
                "B. Ustnlp16 at SemEval-2025 Task 9: Leveraging Data Augmentation for Robust Text Classification",
                "C. Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss",
                "D. Ustnlp16 at SemEval-2025 Task 9: Exploring Transformer Architectures for Sentiment Analysis",
                "E. Ustnlp16 at SemEval-2025 Task 9: Integrating Multi-Task Learning for Improved NLP Model Generalization"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss"
            ],
            "img_path": "2505.00021/plot.jpg"
        },
        "level2_qa": {
            "question": "In this paper, describe the key mechanism through which the integrated data augmentation strategy, involving a specific sequence of random oversampling and Easy Data Augmentation relative to tokenization, enhances the model's ability to classify severely underrepresented food hazard categories.",
            "options": [
                "A. By applying Easy Data Augmentation before tokenization to generate diverse raw text, followed by random oversampling of the tokenized majority classes to balance the dataset, thereby improving overall accuracy.",
                "B. By first increasing the representation of minority classes to a target sample rate through random oversampling performed *after* tokenization, and then further diversifying these specific oversampled instances using Easy Data Augmentation to enhance lexical and structural variety, creating a synergistic effect.",
                "C. By independently applying random oversampling to all classes and Easy Data Augmentation exclusively to minority classes before any tokenization, allowing the transformer model to learn from a broader, albeit less structured, vocabulary.",
                "D. By using focal loss to prioritize minority classes during training, and then applying a combined Easy Data Augmentation and oversampling technique pre-tokenization to ensure that even rare semantic categories are sufficiently represented before model input.",
                "E. By performing random oversampling on the raw text of minority classes, followed by tokenization, and then applying Easy Data Augmentation only if the class imbalance remains above a predefined threshold, focusing primarily on lexical substitution."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "By first increasing the representation of minority classes to a target sample rate through random oversampling performed *after* tokenization, and then further diversifying these specific oversampled instances using Easy Data Augmentation to enhance lexical and structural variety, creating a synergistic effect."
            ],
            "img_path": "2505.00021/plot.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00025",
        "img_path": "2505.00025/photo.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Designing Scalable Neural Networks for Medical Image Analysis Using Convolutional Architectures",
                "B. A Framework for Integrating Biometric Data into Healthcare Large Language Models",
                "C. A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1",
                "D. Developing Context-Aware Clinical Decision Support Systems with Transformer Models",
                "E. Optimizing Transfer Learning Approaches for Disease Prediction in Medical NLP Applications"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1"
            ],
            "img_path": "2505.00025/photo.png"
        },
        "level2_qa": {
            "question": "In this paper, which core characteristic of the proposed method is primarily responsible for its success in creating a medical LLM that balances professional accuracy with significant reductions in memory and latency?",
            "options": [
                "A. The exclusive reliance on advanced knowledge distillation from a significantly larger teacher model to achieve knowledge transfer.",
                "B. The singular focus on 4-bit weight quantization as the most impactful model compression technique employed.",
                "C. The integrated and systematic application of techniques across the three dimensions of knowledge acquisition, model compression, and computational optimization.",
                "D. The development of a novel professional prompt template system that independently optimizes for both accuracy and efficiency across different medical problems.",
                "E. The prioritization of computational optimization techniques, such as Flash Attention and continuous batching, over strategies for knowledge retention and acquisition."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "systematically solving the lightweight problem of medical large models from three dimensions: knowledge acquisition, model compression, and computational optimization."
            ],
            "img_path": "2505.00025/photo.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00061",
        "img_path": "2505.00061/x3.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Optimizing Algorithm Efficiency in Automated Essay Grading Frameworks",
                "B. Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems",
                "C. Analyzing the Impact of Machine Learning Models on Student Performance Evaluation",
                "D. Developing Adaptive Feedback Mechanisms for Intelligent Tutoring Systems",
                "E. Evaluating Robustness of Neural Networks in Large-Scale Educational Assessments"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems"
            ],
            "img_path": "2505.00061/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, given that Strategy 3 initially presented the highest False Positive Rate at .435, what specific percentage of the simulated responses attributed to Strategy 3 was incorporated into the training dataset during the first adversarial training experiment, which aimed to improve system robustness against all three identified types of gaming responses?",
            "options": [
                "A. 30",
                "B. 43.5",
                "C. 70",
                "D. 100",
                "E. 66.7"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "70"
            ],
            "img_path": "2505.00061/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00028",
        "img_path": "2505.00028/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Optimizing Text-to-Text Dialogue Systems Using Modular Retrieval Techniques",
                "B. Improving Voice Command Recognition through Hybrid Neural Network Architectures",
                "C. Advancements in Context-Aware Speech Processing for Conversational AI",
                "D. Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation",
                "E. A Comparative Study of Generation Models in Multi-Turn Spoken Dialogue Systems"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation"
            ],
            "img_path": "2505.00028/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, within the contextual explanation of the 'Indexing' stage—one of the conventionally recognized operational phases of the general Retrieval-Augmented Generation (RAG) paradigm that the core research on the end-to-end Speech-to-Speech dialogue system leverages—what precise count represents the total number of different embedding model examples that are explicitly cited for the task of transforming input data segments into dense vector representations?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 1",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.00028/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00027",
        "img_path": "2505.00027/Figure3.jpg",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Jian Zhou",
                "B. Vivek Muthurangu",
                "C. Jiazheng Li",
                "D. Sirui Zhuge",
                "E. Hai Zhuge"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Jian Zhou"
            ],
            "img_path": "2505.00027/Figure3.jpg"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of nodes in the specific dimension that exhibits the lowest average sentence coverage, based on the Summ dataset verification and provided coverage statistics?",
            "options": [
                "A. 7975",
                "B. 12893",
                "C. 7527",
                "D. 10555",
                "E. 18304"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "10555"
            ],
            "img_path": "2505.00027/Figure3.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00059",
        "img_path": "2505.00059/x2.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Evaluating Whispered Speech Recognition in Noisy Environments: Challenges and Solutions",
                "B. A Comparative Study of Emotion Detection in Close-Talk Versus Distant Microphone Settings",
                "C. Robust Speech Recognition Techniques for Low-Volume and Muted Vocalizations",
                "D. BERSting at the Screams: A Benchmark for Distanced, Emotional and Shouted Speech Recognition",
                "E. Analyzing Acoustic Features for Emotion Classification in Casual Conversational Speech"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "BERSting at the Screams: A Benchmark for Distanced, Emotional and Shouted Speech Recognition"
            ],
            "img_path": "2505.00059/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the explicit goals for the BERSt dataset, which combination of design choices and resulting data characteristics most critically contributes to the documented difficulty for ASR and SER systems, specifically by confounding the interpretation of speech intensity as a sole indicator of distance or arousal, and simultaneously challenging reliance on linguistic context?",
            "options": [
                "A. The primary emphasis on recording speech at 19 distinct distances using single smartphones in varied home environments, specifically to offer an alternative to multi-microphone array datasets for distanced ASR.",
                "B. The deliberate prompting of seven basic emotions to allow for actor interpretation and enable generalized SER tasks, coupled with instructions to vary delivery intensity to specifically test arousal prediction in SER models.",
                "C. The generation of nearly 4 hours of speech from 98 actors with diverse regional and non-native accents across at least 98 different acoustic environments, designed to broadly test model generalization.",
                "D. The finding that ASR degrades with increased shout level and distance, attributed mainly to the high number of phone positions and the inclusion of \"scream\" as an intensity level.",
                "E. The combined strategy of using phonetically diverse but non-sensical phrases to create high surprisal, requiring actors to utter each phrase at spoken, shouted, and screamed levels for each of the seven emotions, and capturing these utterances across 19 varied phone positions including different rooms and obstructions."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "The combined strategy of using phonetically diverse but non-sensical phrases to create high surprisal, requiring actors to utter each phrase at spoken, shouted, and screamed levels for each of the seven emotions, and capturing these utterances across 19 varied phone positions including different rooms and obstructions."
            ],
            "img_path": "2505.00059/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00063",
        "img_path": "2505.00063/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. VORI-Data: A Dataset for Visual Document Understanding and Integrated Reasoning",
                "B. Multi-Modal Document Analysis: Decoupling Vision and Language for Enhanced Intelligence",
                "C. Benchmarking Reasoning Capabilities in Cross-Modal Document Interpretation",
                "D. GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling",
                "E. Exploring Vision-Text Fusion in Document Intelligence Frameworks"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling"
            ],
            "img_path": "2505.00063/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, the GDI Model’s intelligence-preserving training strategy, Layer-wise Adaptive Freeze-Tuning (LW-AFT), is developed based on specific empirical findings from layer-wise Supervised Fine-Tuning (SFT) analysis. Which of the following statements accurately synthesizes a key empirical observation that dictates LW-AFT's parameter allocation methodology, and the primary advantage this methodology offers over certain explicitly contrasted prior continual learning strategies?",
            "options": [
                "A. Observation: Language model layers consistently show minimal parameter updates, indicating their stability for cross-domain generalization. Advantage: LW-AFT primarily freezes these layers, outperforming data replay techniques by avoiding the need for pseudo-sample generation related to limited pre-training datasets.",
                "B. Observation: Parameter modifications are significantly more pronounced in vision layers compared to language layers during SFT. Advantage: LW-AFT allocates unfrozen parameters proportionally to these observed changes, offering a more comprehensive and efficient approach than continual learning methods reliant on a restricted number of pre-training datasets causing incomplete domain coverage.",
                "C. Observation: Both vision and language layers undergo substantial, equivalent parameter updates, necessitating a balanced approach to adaptation. Advantage: LW-AFT fine-tunes lightweight modules like LoRA across all layers, thereby being more computationally efficient than methods requiring full model retraining on extensive pre-training datasets.",
                "D. Observation: The critical layers for domain adaptation are those with the most minimal updates post-SFT, as they preserve foundational knowledge. Advantage: LW-AFT selectively allocates the entire budget of unfrozen parameters to only these minimally changed layers, providing superior generalization compared to regularization methods like EWC that constrain all parameters.",
                "E. Observation: Catastrophic forgetting is primarily mitigated by focusing on the initial layers of the vision backbone. Advantage: LW-AFT leverages this by applying domain-specific expert model fine-tuning (using a fraction 1/α of data) exclusively to early vision layers, making it more efficient than parameter freezing strategies like adapters which modify later layers."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Parameter modifications are significantly more pronounced in vision layers compared to language layers during SFT. LW-AFT allocates unfrozen parameters proportionally to these observed changes, offering a more comprehensive and efficient approach than continual learning methods reliant on a restricted number of pre-training datasets causing incomplete domain coverage."
            ],
            "img_path": "2505.00063/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00056",
        "img_path": "2505.00056/x1.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity",
                "B. Analyzing Social Media Trends Using Sentiment and Network Graphs",
                "C. Automated Recognition of Visual Content in Digital Memes via Neural Networks",
                "D. Semantic Grouping of Online Images Based on Contextual and Textual Features",
                "E. Evaluating Image Similarity in Viral Content Through Feature Extraction Techniques"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity"
            ],
            "img_path": "2505.00056/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific count of distinct, *supplementary* primary similarity dimensions—beyond the initial dimension of the match itself—that are explicitly cited in the 'WAT Grandma' case study as contributing to the combined feature's prioritization of the 'fourth match based on the form dimension' over an 'erroneous third match'?",
            "options": [
                "A. 1",
                "B. 3",
                "C. 4",
                "D. 0",
                "E. 2"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2505.00056/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00074",
        "img_path": "2505.00074/fig2.jpg",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Ziyin Song",
                "B. Juntao Song",
                "C. Xu Yan",
                "D. Zhong Fang",
                "E. Hongming Weng"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Xu Yan"
            ],
            "img_path": "2505.00074/fig2.jpg"
        },
        "level2_qa": {
            "question": "In this paper, describe the core mechanism proposed to reconcile the contrasting observations from ARPES (negligible Fermi surface modifications) and PPMS (substantial transport property changes) following the phase transition to the Spin Density Wave state in KV$_2$Se$_2$O.",
            "options": [
                "A. A 'magnetic breakdown' phenomenon, distinct from conventional types, is induced in the SDW phase by spin-canting driven periodic spin modulation that reduces magnetic symmetry, leading to band degeneracy lifting and Fermi surface reconstruction, which in turn alters carrier trajectories, modifies carrier concentration, and strengthens electron-hole compensation, thus explaining the observed transport dichotomy.",
                "B. The transport changes are attributed to a conventional magnetic breakdown caused by the resurgence of metallic behavior at 100 K, which directly leads to quantum oscillations and modified Hall resistivity without significant Fermi surface reconstruction detectable by ARPES.",
                "C. The negligible influence of spin-orbit coupling on the z-collinear SDW Fermi surface, combined with the preservation of transport-relevant Fermi surface shapes observed by ARPES, indicates that the transport property changes primarily arise from temperature-dependent scattering rates rather than electronic structure modifications.",
                "D. The formation of a small energy gap of approximately 0.15 eV below the Fermi level during the SDW phase transition is the main driver for the altered transport characteristics, sufficiently explaining the enhanced Hall resistivity without requiring significant Fermi surface topological changes.",
                "E. The breaking of [C$_2$||C$_{4z}$] symmetry during the SDW transition directly induces changes in carrier concentration and strengthens electron-hole compensation, which are solely responsible for the modified transport properties, making the concept of 'magnetic breakdown' a secondary effect related to spin polarization."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "A 'magnetic breakdown' phenomenon, distinct from conventional types, is induced in the SDW phase by spin-canting driven periodic spin modulation that reduces magnetic symmetry, leading to band degeneracy lifting and Fermi surface reconstruction, which in turn alters carrier trajectories, modifies carrier concentration, and strengthens electron-hole compensation, thus explaining the observed transport dichotomy."
            ],
            "img_path": "2505.00074/fig2.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00147",
        "img_path": "2505.00147/x1.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Skill-Driven Contextual Math Learning Approaches for Large Language Models",
                "B. Context-Aware Adaptive Instruction Techniques for Math Problem Solving",
                "C. Enhancing Mathematical Reasoning in Language Models via Dynamic Skill Adaptation",
                "D. AdaptMI: Adaptive Skill-based In-context Math Instruction for Small Language Models",
                "E. In-Context Learning Frameworks for Mathematical Skill Development in AI Systems"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "AdaptMI: Adaptive Skill-based In-context Math Instruction for Small Language Models"
            ],
            "img_path": "2505.00147/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the explicitly stated average percentage decrease in performance observed for Small Language Models on the MATH dataset when skill-based selection is applied to questions already solvable by these models, compared to using non skill-based in-context selection strategies?",
            "options": [
                "A. 6",
                "B. 3.6",
                "C. 4",
                "D. 5",
                "E. 2"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.00147/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00091",
        "img_path": "2505.00091/11.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Adaptive Swarm Strategies for Autonomous UAV Navigation in Urban Low-Altitude Environments",
                "B. Multi-Agent Path Planning Techniques for UAV Deployment in Dense Urban Airspaces",
                "C. CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios",
                "D. Hierarchical Task Scheduling for Collaborative UAV Operations in Complex Cityscapes",
                "E. Dynamic Resource Allocation Models for UAV Fleets in Urban Surveillance Missions"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios"
            ],
            "img_path": "2505.00091/11.png"
        },
        "level2_qa": {
            "question": "In this paper, what single numerical datum, explicitly provided as part of the experimental methodology description, signifies the total count of comparative evaluation sequences executed to rigorously assess the proposed system's key performance attributes—specifically its adaptability and responsiveness critical for efficacy in complex, dynamic urban settings—against other existing models?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 20",
                "D. 21",
                "E. 50"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "50"
            ],
            "img_path": "2505.00091/11.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00076",
        "img_path": "2505.00076/fig3.jpg",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Yuzhi Wang",
                "B. Caiyuan Ye",
                "C. Xintian Xie",
                "D. Tiannian Zhu",
                "E. Jiaxuan Liu"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Caiyuan Ye"
            ],
            "img_path": "2505.00076/fig3.jpg"
        },
        "level2_qa": {
            "question": "In this paper, considering the MCMC sampling method's proposal selection, what is the aggregate probability that a single selected proposal will result in a change to the geometric arrangement or dimensions of the crystal structure, as opposed to its elemental makeup?",
            "options": [
                "A. 0.2",
                "B. 0.4",
                "C. 0.6",
                "D. 0.8",
                "E. 1.0"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "0.8"
            ],
            "img_path": "2505.00076/fig3.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00100",
        "img_path": "2505.00100/AI-Lab_Framework.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Evaluating the AI-Lab Intervention: Impact on Student Perception and Use of Generative AI in Early Undergraduate Computer Science Courses",
                "B. Assessing the Role of AI Tools in Enhancing Collaborative Learning among Computer Science Undergraduates",
                "C. Analyzing Student Engagement with Machine Learning Platforms in Introductory Programming Classes",
                "D. The Effect of Virtual Labs on Problem-Solving Skills in Early Computer Science Education",
                "E. Exploring Undergraduate Attitudes Towards Automated Code Generation in Foundational CS Courses"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Evaluating the AI-Lab Intervention: Impact on Student Perception and Use of Generative AI in Early Undergraduate Computer Science Courses"
            ],
            "img_path": "2505.00100/AI-Lab_Framework.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the section specifically claiming this study as the 'first empirical evaluation' of the AI-Lab Intervention, over how many semesters was this evaluation conducted?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 831"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2505.00100/AI-Lab_Framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00084",
        "img_path": "2505.00084/flow.jpg",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Analyzing Gravitational Wave Sources with Multi-Band Detectors: Implications for Dark Matter Distribution",
                "B. Characterizing Cosmic Expansion through High-Frequency Gravitational Wave Observations",
                "C. Discovering the Dispersion of Gravitational Waves using Multi-Band Observation including Deci-Hertz: A Unique Probe to Cosmic Acceleration",
                "D. Investigating the Role of Deci-Hertz Band in Understanding Black Hole Merger Rates",
                "E. Multi-Band Gravitational Wave Astronomy: Constraints on Modified Gravity Theories"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Discovering the Dispersion of Gravitational Waves using Multi-Band Observation including Deci-Hertz: A Unique Probe to Cosmic Acceleration"
            ],
            "img_path": "2505.00084/flow.jpg"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific numerical count of mock gravitational wave events generated from an AGN-motivated IMBH population model, considering a one-year observation window and a specified redshift interval, for use in the subsequent multi-band dispersion analysis?",
            "options": [
                "A. 10",
                "B. 8.6",
                "C. 1",
                "D. 371",
                "E. 2"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "371"
            ],
            "img_path": "2505.00084/flow.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00114",
        "img_path": "2505.00114/synthetic_data.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Evaluating Multilingual Models for Regional Arabic Dialect Recognition",
                "B. Neural Machine Translation Approaches for Under-Resourced Levantine Variants",
                "C. Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of Lebanese",
                "D. Adapting Language Models to Arabic Dialects: Challenges and Opportunities",
                "E. Cross-Dialectal Transfer Learning in Arabic NLP: A Lebanese Case Study"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of Lebanese"
            ],
            "img_path": "2505.00114/synthetic_data.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the methodology for creating the Lebanese Grammar Instruction Data (LGID) and the paper's overarching conclusions regarding dataset efficacy for Lebanese dialect translation, which statement accurately reflects the relationship between the LGID synthesis process and the primary findings on translation model performance?",
            "options": [
                "A. The selection of Claude 3.5 Sonnet for synthesizing LGID from \"The Fundamentals of Lebanese Grammar\" was primarily because its outputs were inherently more culturally authentic than data from Open Subtitles, aligning with the paper's emphasis on the LW dataset's superiority.",
                "B. The successful synthesis of 2,836 culturally relevant grammar examples for LGID using Claude 3.5 Sonnet demonstrates that large, non-native datasets like NN could be effectively enhanced for cultural authenticity if processed through similar advanced LLMs.",
                "C. The use of Claude 3.5 Sonnet to process entire chapters of a Lebanese grammar book for LGID was driven by its ability to generate descriptive content and handle extended context, a process distinct from, yet complementary to, the fine-tuning experiments that highlighted the value of the smaller, natively sourced LW dataset for overall translation performance.",
                "D. The paper concludes that the grammar-hint tuning approach, facilitated by the Claude 3.5 Sonnet-synthesized LGID, ultimately proved more effective than contrastive fine-tuning with the LW dataset due to the explicit grammatical guidance provided.",
                "E. The reliance on \"The Fundamentals of Lebanese Grammar\" and Claude 3.5 Sonnet for LGID creation underscores a limitation in the LW dataset, suggesting that natively sourced podcast data lacks sufficient grammatical structure for effective LLM fine-tuning."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The use of Claude 3.5 Sonnet to process entire chapters of a Lebanese grammar book for LGID was driven by its ability to generate descriptive content and handle extended context, a process distinct from, yet complementary to, the fine-tuning experiments that highlighted the value of the smaller, natively sourced LW dataset for overall translation performance."
            ],
            "img_path": "2505.00114/synthetic_data.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00137",
        "img_path": "2505.00137/updatedcircuitimage.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Minho Heo",
                "B. Sujan K.K.",
                "C. Sangram Deshpande",
                "D. Gregory T. Byrd",
                "E. Rushikesh Ubale"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Rushikesh Ubale"
            ],
            "img_path": "2505.00137/updatedcircuitimage.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement most accurately synthesizes the data transformation pathway from a raw transaction's static features to the input ready for quantum embedding by the variational quantum circuit, including the critical interfacing step between the classical and quantum components?",
            "options": [
                "A. Raw transaction features are directly fed into the variational quantum circuit after Pauli-Z basis measurement, with a subsequent LSTM layer refining these quantum features for fraud prediction.",
                "B. Static transaction features are reshaped by adding a dummy time dimension for LSTM processing, whose final hidden state `h_T` is then directly used as input to the variational quantum circuit, leveraging its inherent capacity to handle variable input dimensions.",
                "C. Following comprehensive preprocessing, static transaction features are processed by an LSTM (after being treated as a sequence of length 1), and its final hidden state `h_T` is projected by a fully connected layer to match the dimensionality required by the variational quantum circuit for enhanced feature representation.",
                "D. The variational quantum circuit first processes raw transaction data using superposition and entanglement, and its quantum-enhanced output vector `q_vec` is then processed by an LSTM, which in turn feeds a fully connected layer for fraud probability prediction.",
                "E. Transaction data undergoes Pauli-Z basis measurement to create a real-valued vector, which is then treated as a sequence of length 1 for LSTM processing, followed by a parameter-shift rule application before entering the variational quantum circuit."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Following comprehensive preprocessing, static transaction features are processed by an LSTM (after being treated as a sequence of length 1), and its final hidden state `h_T` is projected by a fully connected layer to match the dimensionality required by the variational quantum circuit for enhanced feature representation."
            ],
            "img_path": "2505.00137/updatedcircuitimage.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00105",
        "img_path": "2505.00105/Methodology.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Enhancing Retrieval Accuracy in RAG Systems through Advanced Embedding Augmentation",
                "B. Evaluating Scalability of Vector Indexing Methods in Information Retrieval Architectures",
                "C. Comparative Analysis of Attention Mechanisms for Improved Contextual Embeddings",
                "D. Adaptive Training Strategies for Language Models in Resource-Constrained Environments",
                "E. Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques"
            ],
            "img_path": "2505.00105/Methodology.png"
        },
        "level2_qa": {
            "question": "In this paper, a single number, show the research data.",
            "options": [
                "A. 0.3",
                "B. 4",
                "C. 8",
                "D. 50",
                "E. 2"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "8"
            ],
            "img_path": "2505.00105/Methodology.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00210",
        "img_path": "2505.00210/fig_GenAI_Model_Specific_Properties.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Anpeng Wu",
                "B. Suk Ki Lee",
                "C. Federico Agostini",
                "D. Jiahui Xu",
                "E. Hyunwoong Ko"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Suk Ki Lee"
            ],
            "img_path": "2505.00210/fig_GenAI_Model_Specific_Properties.png"
        },
        "level2_qa": {
            "question": "In this paper, given the context that diffusion models can incorporate physical constraints into their guided denoising steps for process control, which single sentence accurately describes a critical research gap identified in the text that directly undermines the comprehensive application of this specific constraint-incorporation capability?",
            "options": [
                "A. The separation between generation and control functions prevents the translation of probabilistic understanding into actionable controls, irrespective of constraint incorporation.",
                "B. The inherent difficulty in adapting generative models developed for other domains to manufacturing-specific complexities restricts the effective formulation of such physical constraints.",
                "C. Insufficient physical understanding of manufacturing phenomena fundamentally limits the ability to define and integrate the very physical constraints intended to guide the diffusion models.",
                "D. The iterative nature of diffusion models, while enabling process optimization, inherently complicates the real-time incorporation of dynamic physical constraints not identified as a primary research gap.",
                "E. The challenge in leveraging generative ML for control lies primarily in the lack of a functional control-oriented perspective to translate probabilistic outputs, rather than in the definition or application of physical constraints themselves."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Insufficient physical understanding of manufacturing phenomena fundamentally limits the ability to define and integrate the very physical constraints intended to guide the diffusion models."
            ],
            "img_path": "2505.00210/fig_GenAI_Model_Specific_Properties.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00111",
        "img_path": "2505.00111/genio_architecture.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Enhancing Network Performance in Telco Edge Computing Using OSS Frameworks",
                "B. Integrating AI-Driven Analytics for Optimized Telco Edge Operations",
                "C. Scalability Solutions for Distributed OSS in Telecom Edge Environments",
                "D. Security-by-Design at the Telco Edge with OSS: Challenges and Lessons Learned",
                "E. Evaluating Resource Management Strategies in Telco Edge Networks"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Security-by-Design at the Telco Edge with OSS: Challenges and Lessons Learned"
            ],
            "img_path": "2505.00111/genio_architecture.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the challenges associated with GENIO's software architecture and the specific needs of business users utilizing the IaaS model for applications demanding robust isolation, which factor presents the most critical latent risk to the efficacy of hard isolation mechanisms, potentially undermining a business user's application security despite their choice of dedicated virtual machines?",
            "options": [
                "A. The difficulty in managing unpatched or unknown vulnerabilities within the custom Linux kernel configuration—essential for SDN software—which, if exploited, can lead to kernel exploits that directly break the isolation mechanisms of dedicated virtual machines used by business users.",
                "B. The exploitation of misconfigurations in unrestricted OS accounts within edge applications deployed by business users, leading to privilege escalation within their own leased resources.",
                "C. The threat of interception and replay attacks on inter-OLT links, primarily affecting data in transit for end-users consuming SaaS applications, rather than the isolation of business user VMs.",
                "D. The risk of firmware manipulation in ONUs by attackers targeting end-user premises, potentially leading to service disruption for those specific end-users.",
                "E. The challenge of managing digital signatures for container images on the public registry, which primarily affects the initial deployment integrity for business users but not the runtime isolation provided by VMs."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The difficulty in managing unpatched or unknown vulnerabilities within the custom Linux kernel configuration—essential for SDN software—which, if exploited, can lead to kernel exploits that directly break the isolation mechanisms of dedicated virtual machines used by business users."
            ],
            "img_path": "2505.00111/genio_architecture.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00225",
        "img_path": "2505.00225/architecture.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Enhancing Fault Detection in Power Grids with Transformer-Based Sequence Models",
                "B. Modeling Electrical Load Patterns Using Temporal Tabular Neural Networks",
                "C. Analyzing Outage Severity in Electrical Networks via Longitudinal Data Techniques",
                "D. Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal Tabular Transformers",
                "E. Forecasting Power Consumption Trends Using Tabular Deep Learning Frameworks"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal Tabular Transformers"
            ],
            "img_path": "2505.00225/architecture.png"
        },
        "level2_qa": {
            "question": "In this paper, what single numerical figure quantifies the average enhancement in customer contentment, as measured by a composite score integrating penalties for both premature and delayed restoration estimates, achieved by the proposed transformer-based longitudinal model over conventional approaches across a multi-year, multi-company dataset?",
            "options": [
                "A. 34,000",
                "B. 19.08",
                "C. 3",
                "D. 1",
                "E. 0.001"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "19.08"
            ],
            "img_path": "2505.00225/architecture.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00109",
        "img_path": "2505.00109/x23.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Characterization of Gamma-Ray Bursts Observed by Swift and Fermi during the Initial SRG Campaigns",
                "B. Multi-Wavelength Analysis of Quasar Variability Using ART-XC and eROSITA Data from SRG Surveys",
                "C. New Active Galactic Nuclei Detected by the ART-XC and eROSITA Telescopes during the First Five SRG All-Sky X-ray Surveys. Part 2",
                "D. Survey of Supernova Remnants Detected in the First Five All-Sky X-ray Observations by SRG Instruments",
                "E. Spectral Properties of Galaxy Clusters Identified in the ART-XC and eROSITA SRG Surveys: Initial Findings"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "New Active Galactic Nuclei Detected by the ART-XC and eROSITA Telescopes during the First Five SRG All-Sky X-ray Surveys. Part 2"
            ],
            "img_path": "2505.00109/x23.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement accurately reflects the limitations encountered in constraining intrinsic absorption ($N_{\rm H}$) for certain Seyfert types using the SRG all-sky survey data primarily utilized for detailed spectral modeling, and the rationale for excluding other available survey data from this specific modeling process?",
            "options": [
                "A. For at least one Sy1.9 galaxy (SRGA J000132.9+240237), reliable constraints on $N_{\rm H}$ could not be obtained from the SRG all-sky survey data used for detailed spectral modeling, and ART-XC survey data was not incorporated into this modeling due to concerns about Eddington bias from its low count statistics.",
                "B. Intrinsic absorption constraints from ART-XC survey data were found to be unreliable for all Seyfert 1 galaxies due to insufficient photon counts, prompting the exclusive use of eROSITA data which successfully constrained $N_{\rm H}$ for all Sy1.9 and Sy2 galaxies.",
                "C. While eROSITA data allowed for $N_{\rm H}$ determination in most Seyfert 1 and Sy1.9 galaxies, it proved insufficient for the Seyfert 2 galaxy (object no. 9), whose strong absorption could only be inferred by combining eROSITA with ART-XC data despite the latter's Eddington bias.",
                "D. The primary limitation in constraining $N_{\rm H}$ arose from the ART-XC data's broad energy bands, whereas eROSITA data successfully constrained $N_{\rm H}$ for all eleven Seyfert galaxies, including the radio-loud SRGA J000132.9+240237.",
                "E. All Seyfert 2 type galaxies (Sy1.9 and Sy2) showed high intrinsic absorption ($N_{\rm H} \\sim 10^{22}$ cm$^{-2}$) robustly constrained using eROSITA data, while ART-XC data, though not used for $N_{\rm H}$, was essential for determining the power-law slope $\\Gamma$ due to its harder energy band coverage."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "For at least one Sy1.9 galaxy (SRGA J000132.9+240237), reliable constraints on $N_{\rm H}$ could not be obtained from the SRG all-sky survey data used for detailed spectral modeling, and ART-XC survey data was not incorporated into this modeling due to concerns about Eddington bias from its low count statistics."
            ],
            "img_path": "2505.00109/x23.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00153",
        "img_path": "2505.00153/x3.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Philippe Gonzalez",
                "B. Jong E. Han",
                "C. Bhanuja Ainary",
                "D. Sarah Jeffreson",
                "E. Martin Avanzini"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Bhanuja Ainary"
            ],
            "img_path": "2505.00153/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, which sentence best describes the primary initial safeguarding mechanism applied to raw voice input within the public Audo-Sight system's input management to ensure age-appropriateness before further processing and potential MLLM interaction?",
            "options": [
                "A. NeMo Guardrails are applied after MLLM output, analyzing textual responses to filter content based on pre-set BVI-cognizant rules and detected user age categories.",
                "B. The private system's user identification module is leveraged in public settings, cross-referencing voice signatures with a database to infer age and subsequently filter queries before MLLM engagement.",
                "C. Raw voice input is directly fed to an Age-Range Detector that analyzes vocal characteristics to estimate user age, thereby enabling an age-based filtering mechanism to prevent inappropriate queries from being processed by the MLLM.",
                "D. A Safe Query Filter operates in conjunction with the Whisper speech-to-text module, performing semantic analysis on the transcribed query to block restricted topics before the query is sent to the Age-Range Detector and then the MLLM.",
                "E. Both voice and image inputs are simultaneously processed by a unified safeguarding component in the Input Management stage, which uses combined multimodal cues to determine age and filter queries before cognition engine engagement."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Raw voice input is directly fed to an Age-Range Detector that analyzes vocal characteristics to estimate user age, thereby enabling an age-based filtering mechanism to prevent inappropriate queries from being processed by the MLLM."
            ],
            "img_path": "2505.00153/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00144",
        "img_path": "2505.00144/x3.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Chuanyi Li",
                "B. Kui Liu",
                "C. Xin Xia",
                "D. David Lo",
                "E. Feifei Niu"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Feifei Niu"
            ],
            "img_path": "2505.00144/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, considering only the specific IRBL approaches explicitly detailed with their distinct embedding and matching techniques in the section starting 'HyLoc(Lam et al.,2015)...', what is the total number of these studies that utilize a Pre-trained Language Model (PLM, e.g., Transformer-based models like BERT, CodeBERT) for vectorization and subsequently use direct vector similarity (e.g., cosine similarity) for matching, rather than a Deep Neural Network (DNN) for the matching phase?",
            "options": [
                "A. 3",
                "B. 4",
                "C. 5",
                "D. 6",
                "E. 9"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "5"
            ],
            "img_path": "2505.00144/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00279",
        "img_path": "2505.00279/x1.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Adaptive Strategies for Single Skill Level Optimization in Interactive Systems",
                "B. Evaluating Player Performance Metrics Across Diverse Gaming Environments",
                "C. Policies of Multiple Skill Levels for Better Strength Estimation in Games",
                "D. Machine Learning Approaches to Skill Progression Prediction in Competitive Play",
                "E. Dynamic Difficulty Adjustment Based on Real-Time User Feedback in Video Games"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Policies of Multiple Skill Levels for Better Strength Estimation in Games"
            ],
            "img_path": "2505.00279/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the specific rating values provided for the chess experiments, what is the numerical difference between the total count of distinct rating points covered by the target ranks to predict and the total count of distinct rating points covered by the employed imitation models?",
            "options": [
                "A. 600",
                "B. 699",
                "C. 700",
                "D. 701",
                "E. 100"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "700"
            ],
            "img_path": "2505.00279/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00284",
        "img_path": "2505.00284/x1.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. DarkSense: Optimized Multimodal Perception Framework for Urban Traffic Analysis",
                "B. LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous Driving",
                "C. StreamDrive: Real-Time Multimodal Sensor Fusion for Vehicle Navigation",
                "D. LiteNav: Efficient End-to-End Sensor Integration for Autonomous Vehicles",
                "E. RapidFusion: Lightweight Multimodal Data Processing for Intelligent Driving Systems"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous Driving"
            ],
            "img_path": "2505.00284/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific numerical value representing the quantity of distinct test environments sourced from the nuScenes prediction task, which were employed for the comprehensive assessment of the various Vision-Language Model based autonomous driving agents?",
            "options": [
                "A. 5",
                "B. 12",
                "C. 2",
                "D. 150",
                "E. 4"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "150"
            ],
            "img_path": "2505.00284/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00289",
        "img_path": "2505.00289/x2.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Yuhan Ma",
                "B. Xiaofei Xie",
                "C. Junjie Wang",
                "D. Xiaoning Du",
                "E. Xiangwei Zhang"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Junjie Wang"
            ],
            "img_path": "2505.00289/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the quantitative performance assessments provided for methodologies *other than* PatchFuzz when applied to JavaScript engine datasets, how many distinct, named systems are detailed with specific metrics indicating their substantial challenges or failures in processing or accurately identifying relevant security aspects of git commits?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 3",
                "E. 4"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2505.00289/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00237",
        "img_path": "2505.00237/pipeline.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Adaptive Path Planning for Autonomous Vehicles Using Reinforcement Learning",
                "B. Robust Trajectory Optimization in Unstructured Environments via Deep Neural Networks",
                "C. Multi-Agent Coordination Strategies for Real-Time Collision Avoidance",
                "D. Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction",
                "E. Sensor Fusion Techniques for Enhanced Motion Tracking in Dynamic Settings"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction"
            ],
            "img_path": "2505.00237/pipeline.png"
        },
        "level2_qa": {
            "question": "In this paper, how many more milliseconds per object does the WTA-based predictor take for model inference compared to the proposed one-shot EBL predictor, based on the cited performance figures?",
            "options": [
                "A. 3",
                "B. 19",
                "C. 55",
                "D. 58",
                "E. 61"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "55"
            ],
            "img_path": "2505.00237/pipeline.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00031",
        "img_path": "2505.00031/x4.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Enhancing Large Language Models with Reinforcement Learning for Adaptive Problem Solving",
                "B. Integrating Symbolic Reasoning into Neural Networks for Improved Question Answering",
                "C. Dynamic Memory Networks for Structured Abstract Reasoning in Complex Tasks",
                "D. Hierarchical Planning Approaches for Efficient Multi-Step Inference in Language Models",
                "E. Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving"
            ],
            "img_path": "2505.00031/x4.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific numerical value represents the performance improvement in test accuracy on the Hendrycks MATH benchmark achieved by the LEPA+REINFORCE variant over the standard LEPA algorithm, expressed in percentage points?",
            "options": [
                "A. 0.2",
                "B. 30.2",
                "C. 30.6",
                "D. 1.0",
                "E. 0.4"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "0.4"
            ],
            "img_path": "2505.00031/x4.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00019",
        "img_path": "2505.00019/x19.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. A Comparative Analysis of Tokenization Techniques in Large Language Models",
                "B. Exploring Optimization Strategies for Neural Network Training Efficiency",
                "C. Evaluating Dataset Augmentation Methods for Natural Language Understanding",
                "D. An Empirical Study on Prompt Compression for Large Language Models",
                "E. A Theoretical Framework for Attention Mechanisms in Transformer Architectures"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "An Empirical Study on Prompt Compression for Large Language Models"
            ],
            "img_path": "2505.00019/x19.png"
        },
        "level2_qa": {
            "question": "In this paper, provide a single sentence that encapsulates the study's current position on the causal factors dictating the observed divergence in response length adjustments between LLMs like GPT-3.5-turbo and Claude-3-Haiku when subjected to prompt compression, based on its reported analyses and stated future work.",
            "options": [
                "A. The study conclusively identifies specific architectural differences between GPT-3.5-turbo and Claude-3-Haiku as the primary causal factors for their distinct response length behaviors to compression.",
                "B. The paper presents the observed differences in response length as a consistently predictable outcome of prompt compression, with the mechanisms fully elucidated through word omission analysis.",
                "C. The study characterizes the contrasting response length patterns as statistically observed phenomena influenced by multiple variables like prompt content and compression pattern, with the fundamental driving mechanisms deferred for future investigation.",
                "D. The research primarily attributes the divergent response lengths to the varying efficacy of the six compression methods on different LLM families, a finding supported by the Longbench evaluation.",
                "E. The paper posits that while response length variations are noted, they are considered secondary to model hallucinations in terms of the depth of causal understanding achieved regarding the impact of prompt compression across all tested LLMs."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The study characterizes the contrasting response length patterns as statistically observed phenomena influenced by multiple variables like prompt content and compression pattern, with the fundamental driving mechanisms deferred for future investigation."
            ],
            "img_path": "2505.00019/x19.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00029",
        "img_path": "2505.00029/main_v3.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Balancing Dialogue Context and Domain Adaptation: Methods for Incremental Knowledge Integration",
                "B. Mitigating Knowledge Drift in Neural Conversational Models through Hierarchical Fine-Tuning",
                "C. Selective Parameter Updating for Domain-Specific Dialogue Systems with Stability Preservation",
                "D. Enhancing Dialogue Agents with Modular Knowledge Injection Techniques to Prevent Performance Degradation",
                "E. Keep the General, Inject the Specific: Structured Dialogue Fine-Tuning for Knowledge Injection without Catastrophic Forgetting"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Keep the General, Inject the Specific: Structured Dialogue Fine-Tuning for Knowledge Injection without Catastrophic Forgetting"
            ],
            "img_path": "2505.00029/main_v3.png"
        },
        "level2_qa": {
            "question": "In this paper, for the methodology aimed at enhancing Large Vision Language Models (LVLMs) with domain-specific knowledge using image datasets—where such knowledge is represented by a few images lacking textual labels yet allowing for diverse contextual variations, and the goal is to enable context-aware textual responses—what is the explicitly stated typical maximum for the number of such images representing a single item of domain-specific knowledge?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 5",
                "E. An undefined quantity, as the primary constraint is the absence of textual labels rather than a specific image count."
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "5"
            ],
            "img_path": "2505.00029/main_v3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00278",
        "img_path": "2505.00278/x3.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. ReCo: Resource-Constrained Scheduling with Probabilistic Matching for Enhancing IC Fabrication Efficiency",
                "B. MoDe: Multi-Objective Defect Prediction Using Graph Embedding Techniques in Semiconductor Testing",
                "C. OpTe: Optimization Techniques for Dynamic Task Allocation in Automated Test Equipment Environments",
                "D. AdMa: Adaptive Machine Learning Models for Fault Detection and Diagnosis in Integrated Circuit Manufacturing",
                "E. DeCo: Defect-Aware Modeling with Contrasting Matching for Optimizing Task Assignment in Online IC Testing"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "DeCo: Defect-Aware Modeling with Contrasting Matching for Optimizing Task Assignment in Online IC Testing"
            ],
            "img_path": "2505.00278/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, aggregating information solely from the textual descriptions provided for 'Case 1' and 'Case 2', what is the precise total number of unique defect type identifiers (those explicitly prefixed with '#') that are mentioned?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.00278/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00365",
        "img_path": "2505.00365/x2.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Weidong Bao",
                "B. Zhengyi Zhong",
                "C. Ji Wang",
                "D. Jianguo Chen",
                "E. Lingjuan Lyu"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Zhengyi Zhong"
            ],
            "img_path": "2505.00365/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, describe the complete fate of a client-trained Decoder for a task (Task B) that the server subsequently identifies as adversarial, specifically regarding its handling by both the client and the server after the client detects a data drift signaling a transition from this Task B to a new Task C.",
            "options": [
                "A. The Decoder for Task B is discarded by the client without being added to its local pool due to Task B's adversarial nature and the reinitialization of a new Decoder for Task C; it was also not stored by the server.",
                "B. The Decoder for Task B is added to the client's local Decoder pool and is also stored in the server's Decoder pool after robust aggregation, despite Task B being adversarial, to aid future global model updates.",
                "C. The Decoder for Task B is added to the client's local Decoder pool, making it available for future client-side inference on Task B, while it is explicitly not stored in the server's Decoder pool due to Task B's adversarial classification.",
                "D. The Decoder for Task B is not added to the client's local Decoder pool but is specially handled and stored by the server as part of its adversarial task monitoring, though it remains inaccessible for client-side inference on Task B.",
                "E. The Decoder for Task B is added to the client's local Decoder pool; however, the server, while not storing this specific Decoder, uses a reinitialized proxy Decoder conceptually representing Task B during any Krum-based aggregation of Encoders from that period."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The Decoder for Task B is added to the client's local Decoder pool, making it available for future client-side inference on Task B, while it is explicitly not stored in the server's Decoder pool due to Task B's adversarial classification."
            ],
            "img_path": "2505.00365/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00260",
        "img_path": "2505.00260/fig1_2columns.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. High-resolution spectral analysis for quantum magnetometry applications",
                "B. Wideband covariance magnetometry below the diffraction limit",
                "C. Subwavelength imaging techniques using narrowband magnetic sensors",
                "D. Advanced signal processing methods in nanoscale magnetic field detection",
                "E. Broadband magnetic resonance imaging beyond conventional resolution limits"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Wideband covariance magnetometry below the diffraction limit"
            ],
            "img_path": "2505.00260/fig1_2columns.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the minimum reported single-shot readout noise ($\\sigma_R$) value achieved for an NV defect after implementing the resonantly-assisted spin-to-charge conversion technique?",
            "options": [
                "A. 15",
                "B. 4",
                "C. 3",
                "D. 20",
                "E. 75"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.00260/fig1_2columns.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00179",
        "img_path": "2505.00179/Fig8.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Phase Space Analysis of Quasiperiodic Attractors in Multi-Frequency Standard Maps",
                "B. Impact of Nonlinear Resonances in Two-Parameter Driven Hamiltonian Systems",
                "C. Isochronous bifurcations dependence on the driving mode phase shift in two-harmonic standard maps",
                "D. Chaotic Transitions Induced by Frequency Modulation in Coupled Standard Maps",
                "E. Comparative Study of Invariant Manifolds in Variable Phase Shift Dynamical Maps"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Isochronous bifurcations dependence on the driving mode phase shift in two-harmonic standard maps"
            ],
            "img_path": "2505.00179/Fig8.png"
        },
        "level2_qa": {
            "question": "In this paper, for how many distinct (m1, m2) pairs explicitly analyzed in the context of secondary shearless curves does a phase shift of φ=π lead to a pitchfork bifurcation that results in the observation of precisely one shearless curve?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 3",
                "E. 4"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2505.00179/Fig8.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00223",
        "img_path": "2505.00223/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Qizhi Li",
                "B. Shilong Zhang",
                "C. Qian Xiao",
                "D. Wenshan Hong",
                "E. Sahil Tippireddy"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Wenshan Hong"
            ],
            "img_path": "2505.00223/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value in eV is explicitly stated as the chosen effective Hubbard parameter for the DFT+U treatment of Cu 3d electrons in Hg1223?",
            "options": [
                "A. 0.07",
                "B. 0.25",
                "C. 1.96",
                "D. 4",
                "E. 1000"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.00223/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00251",
        "img_path": "2505.00251/x1.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Adaptive Gradient Descent Strategies for Scalarization in Multi-objective Optimization",
                "B. Constraint Handling Techniques in Evolutionary Multi-objective Optimization Using Reference Points",
                "C. Multi-start Optimization Method via Scalarization based on Target Point-based Tchebycheff Distance for Multi-objective Optimization",
                "D. Hybrid Metaheuristic Approaches for Pareto Front Approximation in Multi-objective Problems",
                "E. Distance-based Selection Methods Incorporating Weighted Chebyshev Metrics for Multi-objective Search"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Multi-start Optimization Method via Scalarization based on Target Point-based Tchebycheff Distance for Multi-objective Optimization"
            ],
            "img_path": "2505.00251/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single numerical figure, explicitly presented as research data, quantifies the maximum observed improvement in computational efficiency achieved by the proposed multi-start optimization method when benchmarked against existing algorithms like NSGA-II, NSGA-III, and MOEA/D-DE?",
            "options": [
                "A. 4",
                "B. 3",
                "C. 474",
                "D. 2",
                "E. 1"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "474"
            ],
            "img_path": "2505.00251/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00315",
        "img_path": "2505.00315/x1.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Adaptive Routing Strategies for Dynamic Sparse Attention in Neural Networks",
                "B. Mixture of Sparse Attention: Content-Based Learnable Sparse Attention via Expert-Choice Routing",
                "C. Hierarchical Expert Selection for Scalable Content-Driven Attention Mechanisms",
                "D. Sparse Attention Optimization through Multi-Expert Routing Frameworks",
                "E. Content-Guided Expert Mixtures for Efficient Neural Attention Models"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Mixture of Sparse Attention: Content-Based Learnable Sparse Attention via Expert-Choice Routing"
            ],
            "img_path": "2505.00315/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the maximum reported perplexity improvement for MoSA over a dense baseline given an identical compute budget?",
            "options": [
                "A. 0%",
                "B. -5%",
                "C. 27%",
                "D. 25%",
                "E. 50%"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "27%"
            ],
            "img_path": "2505.00315/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00374",
        "img_path": "2505.00374/main2.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. A Novel Multi-Scale Attention Framework for Hyperspectral Image Denoising",
                "B. Deep Residual Networks for Efficient Multispectral Image Classification",
                "C. Adaptive Feature Fusion Techniques in High-Resolution Satellite Image Reconstruction",
                "D. Graph-Based Semi-Supervised Learning for Hyperspectral Image Segmentation",
                "E. Towards Lightweight Hyperspectral Image Super-Resolution with Depthwise Separable Dilated Convolutional Network"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Towards Lightweight Hyperspectral Image Super-Resolution with Depthwise Separable Dilated Convolutional Network"
            ],
            "img_path": "2505.00374/main2.png"
        },
        "level2_qa": {
            "question": "In this paper, provide the single sentence from the provided text that most directly articulates the principal performance-related drawback commonly observed across various model compression techniques (like knowledge distillation, pruning, low-rank factorization, and quantization) when applied to super-resolution, a drawback the DSDCN's design philosophy aims to overcome.",
            "options": [
                "A. Moreover, existing methods often rely on large models with a high number of parameters or require the fusion with panchromatic or RGB images, both of which are often impractical in real-world scenarios.",
                "B. However, hyperspectral super-resolution remains an ill-posed problem due to the high spectral dimensionality of the data and the scarcity of available training samples.",
                "C. Specifically, our model leverages multiple depthwise separable convolutions, similar to the MobileNet architecture, and further incorporates a dilated convolution fusion block to make the model more flexible for the extraction of both spatial and spectral features.",
                "D. As a result, numerous lightweight super-resolution models have gained significant attention in recent years, focusing on reducing model parameters and computational complexity through various strategies.",
                "E. However, these models often exhibit a significant performance gap compared to state-of-the-art super-resolution methods."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "However, these models often exhibit a significant performance gap compared to state-of-the-art super-resolution methods."
            ],
            "img_path": "2505.00374/main2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00334",
        "img_path": "2505.00334/x2.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Hybrid Fourier-Transform Networks for Multimodal Image Reconstruction",
                "B. Graph-Based Diffusion Techniques for Video Frame Interpolation",
                "C. Quaternion Wavelet-Conditioned Diffusion Models for Image Super-Resolution",
                "D. Adaptive Wavelet Frames in Deep Learning for Medical Image Enhancement",
                "E. Multi-Scale Convolutional Models with Quaternion Transform for Image Denoising"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Quaternion Wavelet-Conditioned Diffusion Models for Image Super-Resolution"
            ],
            "img_path": "2505.00334/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most accurately synthesizes the implications of ResQu's performance on the ShipSpotting dataset in the context of the CFW module's impact on structural fidelity, considering ResQu's overall training strategy?",
            "options": [
                "A. ResQu's zero-shot success on ShipSpotting, leveraging its fine-tuned Stable Diffusion priors, inherently demonstrates that its quaternion wavelet-aware encoder achieves maximal structural fidelity, rendering CFW customization redundant for domain-specific applications.",
                "B. The comparable performance of ResQu on the ShipSpotting dataset without retraining, potentially utilizing a CFW module pretrained by StableSR, indicates that custom-training the CFW offers no significant additional benefits for structural fidelity in unseen domains.",
                "C. To achieve its competitive zero-shot results on ShipSpotting, ResQu must consistently employ its custom-trained CFW, indicating that robust generalization inherently relies on optimizing for structural fidelity through domain-specific CFW training prior to zero-shot deployment.",
                "D. The ShipSpotting results, while achieved without dataset-specific retraining of the main model, prove that the foundational Stable Diffusion priors alone are sufficient for ResQu to match the structural fidelity of specialized, fully trained systems, irrespective of the specific CFW configuration.",
                "E. ResQu's strong zero-shot generalization to the ShipSpotting dataset underscores its effectiveness; however, the superior structural fidelity achieved with its custom-trained CFW suggests that peak performance in this specific aspect on any given domain likely requires more targeted CFW optimization than the generalized model provides."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "ResQu's strong zero-shot generalization to the ShipSpotting dataset underscores its effectiveness; however, the superior structural fidelity achieved with its custom-trained CFW suggests that peak performance in this specific aspect on any given domain likely requires more targeted CFW optimization than the generalized model provides."
            ],
            "img_path": "2505.00334/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00295",
        "img_path": "2505.00295/fgstp.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Xiaojie Jin",
                "B. Xinlong Zhao",
                "C. Iva Laginja",
                "D. Vibha Raghu",
                "E. Shan Du"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Xinlong Zhao"
            ],
            "img_path": "2505.00295/fgstp.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the GasVid dataset curation, how many distinct difficulty categories were explicitly defined and enumerated based on criteria like camera distance and background complexity, prior to the final allocation of the 9 training and 5 testing videos?",
            "options": [
                "A. 3",
                "B. 5",
                "C. 9",
                "D. 10",
                "E. 14"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "5"
            ],
            "img_path": "2505.00295/fgstp.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00342",
        "img_path": "2505.00342/x2.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Rui Ren",
                "B. Guangba Yu",
                "C. Yulun Wu",
                "D. Zhihan Jiang",
                "E. Wenwei Gu"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Zhihan Jiang"
            ],
            "img_path": "2505.00342/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the reported maximum percentage error for the timeline reconstruction phase, a critical precursor enabling LLMPrism's cross-step diagnosis capabilities by monitoring deviations in training step durations, which itself is built upon the system's initial identification of jobs through spatial communication patterns and the subsequent classification of their Data Parallelism (DP) and Pipeline Parallelism (PP) strategies?",
            "options": [
                "A. 0.3",
                "B. 4",
                "C. 10",
                "D. 2024",
                "E. 0.03"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "0.3"
            ],
            "img_path": "2505.00342/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00302",
        "img_path": "2505.00302/framework.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Spatial-Temporal Residual Networks for High-Dimensional Time Series Classification",
                "B. Graph-Based Deep Learning Models for Anomaly Detection in Multivariate Data Streams",
                "C. Evolutionary Neural Architectures for Sequential Data Representation in Temporal Graphs",
                "D. Temporal Attention Evolutional Graph Convolutional Network for Multivariate Time Series Forecasting",
                "E. Hybrid Convolutional and Recurrent Networks for Long-Term Time Series Pattern Recognition"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Temporal Attention Evolutional Graph Convolutional Network for Multivariate Time Series Forecasting"
            ],
            "img_path": "2505.00302/framework.png"
        },
        "level2_qa": {
            "question": "In this paper, beyond directly utilizing the temporal features ξ(l) (referred to as 'current period’s time characteristics') provided by the TMSA module, how many distinct supplementary types of information or processes does the Evolvable Graph Construction (EGC) module explicitly integrate or execute to define and evolve the adjacency matrix A(l)?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 0"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.00302/framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00356",
        "img_path": "2505.00356/gr_plot_rmsse.jpeg",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Evaluating the Impact of Data Frequency on Global Forecasting Accuracy",
                "B. Optimizing Model Complexity for Enhanced Global Forecasting Performance",
                "C. Comparative Analysis of Static Versus Dynamic Global Prediction Models",
                "D. Do global forecasting models require frequent retraining?",
                "E. Assessing the Role of Data Quality in Global Forecasting Systems"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Do global forecasting models require frequent retraining?"
            ],
            "img_path": "2505.00356/gr_plot_rmsse.jpeg"
        },
        "level2_qa": {
            "question": "In this paper, considering the computational time (CT) analysis for deep learning models on the M5 dataset, what is the stated percentage of CT reduction where the benefits of less frequent retraining largely cease and the reduction effectively plateaus?",
            "options": [
                "A. 30",
                "B. 75",
                "C. 90",
                "D. 60",
                "E. 50"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "50"
            ],
            "img_path": "2505.00356/gr_plot_rmsse.jpeg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00154",
        "img_path": "2505.00154/fig2.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. A. B. Murray",
                "B. Orencio Duran",
                "C. C. W. Lester",
                "D. B. Andreotti",
                "E. P. Claudin"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "C. W. Lester"
            ],
            "img_path": "2505.00154/fig2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence best describes the core mechanistic underpinning and validation pathway of the proposed ripple formation model, particularly emphasizing the functional role of observed scale-free transport phenomena?",
            "options": [
                "A. The model's predictive success for impact ripple wavelengths across diverse environments hinges on its derivation from scale-free, power-law behaviors of critical transport quantities (P0(ℓ), n↑(ℓ), ε̄(ℓ)), which reflect sediment transport criticality and are essential inputs for the ripple growth dispersion relation.",
                "B. The primary innovation of the model is its reliance on the scale-free hoplength distribution (P0(ℓ) ~ ℓ⁻¹) alone to establish a new characteristic length scale, thereby explaining constant ripple sizes by demonstrating the irrelevance of atmospheric density for ripple wavelength.",
                "C. The model demonstrates that impact ripple formation is solely governed by the critical state of sediment transport near the entrainment threshold, with the impact-ejection lag distance (⟨ε⟩) emerging as a secondary consequence of this criticality rather than an independent, primary mechanistic factor.",
                "D. Validation of the model primarily rests on its ability to disregard the explicitly scale-free nature of grain trajectories, focusing instead on a constant average impact-ejection lag (⟨ε⟩) that is assumed to remain unaffected by the broader dynamics of critical sediment transport or hoplength distributions.",
                "E. The ripple growth dispersion relation, central to the model, is derived by assuming that the observed scale-free distributions of various transport quantities can be effectively simplified and approximated by a single, dominant characteristic hoplength, thus linking the new model back to traditional theories but with a numerically refined length scale."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "This agreement also implies that ripple emergence is tied to the critical nature of sediment transport, because the dispersion relations of Figure 4 (black lines) are derived using the power-law scalings observed during transport (Fig. 3; Methods)."
            ],
            "img_path": "2505.00154/fig2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00290",
        "img_path": "2505.00290/x1.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Hierarchical Attention Networks for Enhanced Molecular Taste Characterization",
                "B. Feature Contribution Analysis in Multi-Level Deep Learning Models for Chemical Property Prediction",
                "C. Fine-Grained Structural Embedding for Predicting Molecular Reactivity Profiles",
                "D. Multi-Scale Representation Learning for Odorant-Receptor Interaction Modeling",
                "E. Multi-Hierarchical Fine-Grained Feature Mapping Driven by Feature Contribution for Molecular Odor Prediction"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Multi-Hierarchical Fine-Grained Feature Mapping Driven by Feature Contribution for Molecular Odor Prediction"
            ],
            "img_path": "2505.00290/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct deep learning modules or components that are explicitly proposed and integrated as novel contributions (not pre-existing methods) within the overall HMFNet architecture to address both fine-grained local feature extraction and class imbalance in molecular odor prediction?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.00290/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00310",
        "img_path": "2505.00310/x1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Statistical Learning for Heterogeneous Treatment Effects: Pretraining, Prognosis, and Prediction",
                "B. Machine Learning Approaches to Personalized Medicine: Challenges and Opportunities",
                "C. Adaptive Models for Dynamic Treatment Regimes: Theory and Applications",
                "D. Bayesian Methods in Causal Inference: Estimating Dose-Response Relationships",
                "E. Deep Neural Networks for Predicting Clinical Outcomes from Electronic Health Records"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Statistical Learning for Heterogeneous Treatment Effects: Pretraining, Prognosis, and Prediction"
            ],
            "img_path": "2505.00310/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what singular numerical year is identified as the publication year for both the National Cancer Institute's definition pertinent to factors informative of outcome likelihood irrespective of treatment intervention, and for the work by Athey et al. concerning the advantageous use of baseline response estimations in guiding behavioral nudges?",
            "options": [
                "A. 2015",
                "B. 2025",
                "C. 1987",
                "D. 2001",
                "E. 2014"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2025"
            ],
            "img_path": "2505.00310/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00422",
        "img_path": "2505.00422/x1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Toward Automated Regulatory Decision-Making: Trustworthy Medical Device Risk Classification with Multimodal Transformers and Self-Training",
                "B. Enhancing Medical Device Safety Assessment Using Hierarchical Neural Networks and Ensemble Learning",
                "C. A Deep Learning Framework for Predictive Analysis of Clinical Trial Outcomes in Medical Technologies",
                "D. Integrating Sensor Data and Natural Language Processing for Improved Healthcare Risk Management",
                "E. Advanced Feature Extraction Techniques for Biomedical Signal Classification in Regulatory Compliance"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Toward Automated Regulatory Decision-Making: Trustworthy Medical Device Risk Classification with Multimodal Transformers and Self-Training"
            ],
            "img_path": "2505.00422/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific percentage is explicitly stated as the accuracy of an SVM-based standard multimodal fusion *before* this baseline was enhanced by the self-training mechanism?",
            "options": [
                "A. 90.4",
                "B. 87.1",
                "C. 77.2",
                "D. 54.8",
                "E. 3.3"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "87.1"
            ],
            "img_path": "2505.00422/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00383",
        "img_path": "2505.00383/x2.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Niko R. Reed",
                "B. Stephen J. DeVience",
                "C. Zechuan Yin",
                "D. Johannes Cremer",
                "E. Declan M. Daly"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Declan M. Daly"
            ],
            "img_path": "2505.00383/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the outlined strategy for $V_B^-$ NMR experiments, what core methodological principle justifies adapting AC sensitivity frameworks from NV centers to $V_B^-$ centers, and what novel nanoscale-specific effect is uniquely analyzed for $V_B^-$ performance evaluation?",
            "options": [
                "A. The chemical and thermal inertness shared by hBN and diamond provides the basis for using identical AC sensitivity models, with a primary focus on optimizing optical initialization for $V_B^-$ at the nanoscale.",
                "B. $V_B^-$ centers' superior stability within a single atomic layer of the hBN surface enables direct application of NV center AC sensitivity protocols, with back-action effects being the sole new consideration for nanoscale $V_B^-$ NMR.",
                "C. The similarity of underlying physical mechanisms between $V_B^-$ and NV centers justifies basing $V_B^-$ AC sensitivity calculations on established NV center models, while the paper specifically accounts for unconventional diffusion dynamics in flow-restricted nanoscale regimes for $V_B^-$ NMR signal analysis.",
                "D. The recent demonstration of AC sensing with $V_B^-$ allows leveraging NV center noise models primarily due to shared spin-1 defect characteristics, while the main analytical extension involves assessing performance degradation below 10 nm from the surface for $V_B^-$ centers.",
                "E. The necessity to detect picotesla AC magnetic signals for ultralow-mass NMR mandates basing $V_B^-$ sensitivity calculations on NV center dynamical decoupling protocols, with the primary novel analysis focusing on comparing statistically versus uniformly polarized samples for $V_B^-$ systems."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The similarity of underlying physical mechanisms between $V_B^-$ and NV centers justifies basing $V_B^-$ AC sensitivity calculations on established NV center models, while the paper specifically accounts for unconventional diffusion dynamics in flow-restricted nanoscale regimes for $V_B^-$ NMR signal analysis."
            ],
            "img_path": "2505.00383/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00402",
        "img_path": "2505.00402/x2.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Huan Yan",
                "B. Haotian Wang",
                "C. Jinhui Yi",
                "D. Jian Yuan",
                "E. Yong Li"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Jinhui Yi"
            ],
            "img_path": "2505.00402/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the challenge that road districts lack ground truth labels, which necessitates an unsupervised approach using Node2vec for modeling their spatial correlations that are noted to intensify during abnormal situations, what specific numerical value defines the dimensionality of the embedding generated for each road district, which subsequently informs the modeling of courier-specific correlations?",
            "options": [
                "A. 2",
                "B. 4",
                "C. 128",
                "D. 0.9",
                "E. 12.11"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The 128-dimensional output embedding Roadj, wherej𝑗jitalic_jdenotes road districtj𝑗jitalic_j, will be part of the model input in the next component."
            ],
            "img_path": "2505.00402/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00368",
        "img_path": "2505.00368/fig5.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Hierarchical Modeling of Urban Air Traffic Control Using Multi-Agent Systems",
                "B. Integrating Smart Transportation Networks with Blockchain for Urban Mobility",
                "C. Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic Approach",
                "D. A Decentralized Framework for Autonomous Drone Coordination in City Environments",
                "E. Applying Reinforcement Learning to Optimize Airborne Logistics in Metropolitan Areas"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic Approach"
            ],
            "img_path": "2505.00368/fig5.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most accurately and comprehensively describes the specific function of the Reasoning Layer within the tailored three-layer holon structure for UAM-SoS?",
            "options": [
                "A. The Reasoning Layer autonomously executes multimodal trip plans and directly manages resource allocation across air taxis and ground transport using LLM-derived instructions.",
                "B. The Reasoning Layer leverages Large Language Models primarily for processing natural language passenger requests and for performing airspace compliance validation.",
                "C. The Reasoning Layer is responsible for real-time coordination among all UAM assets, including eVTOLs, electric scooters, and vertiport systems, ensuring seamless operational flow.",
                "D. The Reasoning Layer encapsulates and processes real-time operational status and data from all UAM resources to provide input for the LLM's adaptive planning capabilities.",
                "E. The Reasoning Layer, through LLMs, generates detailed, executable subtasks for each leg of a multimodal journey and validates these against dynamic conditions like weather and airspace status."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The Reasoning Layer leverages Large Language Models primarily for processing natural language passenger requests and for performing airspace compliance validation."
            ],
            "img_path": "2505.00368/fig5.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00135",
        "img_path": "2505.00135/x4.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. DepthNet: Enhancing Monocular Depth Estimation for Stereo Reconstruction",
                "B. StereoVision: A Novel Framework for Converting 2D Videos into 3D Scenes",
                "C. Mono2Stereo: Learning Disparity Maps from Single-View Video Sequences",
                "D. RealTime Stereo Synthesis Using Single Camera Input and Optical Flow",
                "E. Eye2Eye: A Simple Approach for Monocular-to-Stereo Video Synthesis"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Eye2Eye: A Simple Approach for Monocular-to-Stereo Video Synthesis"
            ],
            "img_path": "2505.00135/x4.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the development of the Eye2Eye framework from the Lumiere model, encompassing both its low-resolution generation and its distinct high-resolution synthesis stage, what is the total count of unique Lumiere architectural components (i.e., Lumiere's original base model or Lumiere's original SSR model) or their direct experimental modifications (e.g., an altered version of Lumiere's SSR model specifically tested by the authors) that were either (a) successfully adapted and incorporated into any stage of the final Eye2Eye pipeline, or (b) explicitly evaluated by the authors for the super-resolution task and subsequently rejected before they finalized Eye2Eye's specific super-resolution approach?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 0"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.00135/x4.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00224",
        "img_path": "2505.00224/Fig1_Si_cavity_smaller.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Hybrid Integration of Broadband Quantum Sources with Silicon Photonic Circuits",
                "B. Scalable Fabrication of Quantum Light Emitters for Near-Infrared Photonic Chips",
                "C. On-Chip Generation of Single Photons Using III-V Nanostructures on Silicon",
                "D. Monolithically Integrated C-Band Quantum Emitters on Foundry Silicon Photonics",
                "E. Development of Tunable Quantum Dot Arrays on Silicon Photonics Platforms"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Monolithically Integrated C-Band Quantum Emitters on Foundry Silicon Photonics"
            ],
            "img_path": "2505.00224/Fig1_Si_cavity_smaller.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the numerical value obtained by dividing the optical lifetime of Er3+ ensembles in the anatase phase by the Purcell enhanced optical lifetime measured for a single Er3+ ion in the rutile phase when resonant with the cavity, rounded to the nearest integer?",
            "options": [
                "A. 496",
                "B. 117",
                "C. 0.23",
                "D. 4.26",
                "E. 0.0086"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "117"
            ],
            "img_path": "2505.00224/Fig1_Si_cavity_smaller.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00364",
        "img_path": "2505.00364/x2.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Hierarchical Embeddings for Enhanced Node Classification in Graph Neural Networks",
                "B. From GNNs to Trees: Multi-Granular Interpretability for Graph Neural Networks",
                "C. Temporal Dynamics in Graph Neural Networks for Time-Series Prediction",
                "D. Graph Neural Network Architectures for Large-Scale Network Anomaly Detection",
                "E. Multi-View Learning Approaches for Improved Graph Representation Learning"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "From GNNs to Trees: Multi-Granular Interpretability for Graph Neural Networks"
            ],
            "img_path": "2505.00364/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most precisely characterizes a key limitation pertaining to the depth of interpretability in certain prior hybrid Neural Tree methodologies developed for CNNs, which TIF's architecture, with its hierarchical, multi-granular approach, inherently aims to surmount?",
            "options": [
                "A. Certain hybrid methods provided explanations derived solely from the final layer of their underlying CNNs.",
                "B. Semi-hybrid approaches did not adopt the decision branch mechanism, despite drawing on class hierarchy from Decision Trees.",
                "C. The greedy algorithms utilized by some for dynamic tree generation frequently led to the formation of suboptimal structures.",
                "D. A dependency on manually curated, predefined concepts, such as WordNet data, was essential in some systems to avert suboptimal structures.",
                "E. Prior graph coarsening techniques invariably reduced graphs to a fixed granularity, capturing connectivity only at a specific, singular level."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Certain hybrid methods provided explanations derived solely from the final layer of their underlying CNNs."
            ],
            "img_path": "2505.00364/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01040",
        "img_path": "2505.01040/framework.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Feature Extraction Using Spatial Attention and Region Consistency Analysis",
                "B. Image Segmentation through Multi-channel Fusion and Boundary Refinement",
                "C. Texture Classification Based on Global Attention Mechanisms and Region Homogeneity",
                "D. Object Recognition Leveraging Channel Dependency and Inter-region Correlation Methods",
                "E. Edge Detection based on Channel Attention and Inter-region Independence Test"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Edge Detection based on Channel Attention and Inter-region Independence Test"
            ],
            "img_path": "2505.01040/framework.png"
        },
        "level2_qa": {
            "question": "In this paper, while CAM-EDIT demonstrates notable F-measure scores (0.635 and 0.460 on specific datasets) and achieves F-measure improvements ranging from 19.2% to 26.5% over traditional edge detection techniques, what distinct numerical percentage value is explicitly reported to quantify its specific performance enhancement in terms of noise robustness when benchmarked against baseline methods under Gaussian noise conditions?",
            "options": [
                "A. 0.635",
                "B. 19.2",
                "C. 2.2",
                "D. 0.460",
                "E. 26.5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "2.2"
            ],
            "img_path": "2505.01040/framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01057",
        "img_path": "2505.01057/fig1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Multi-Scale Geometric Filtering Techniques for Enhanced Object Recognition in Medical Imaging",
                "B. Dynamic Feature Embedding Using Higher Order Manifold Learning for Scene Understanding",
                "C. Spectral Smoothing Approaches for Robust Texture Analysis in Complex Image Data",
                "D. GeloVec: Higher Dimensional Geometric Smoothing for Coherent Visual Feature Extraction in Image Segmentation",
                "E. Topological Data Analysis for Improved Boundary Detection in Visual Segmentation Tasks"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "GeloVec: Higher Dimensional Geometric Smoothing for Coherent Visual Feature Extraction in Image Segmentation"
            ],
            "img_path": "2505.01057/fig1.png"
        },
        "level2_qa": {
            "question": "In this paper, which introduces GeloVec as a CNN-based attention smoothing framework employing modified Chebyshev distance metrics and a multispatial transformation matrix with tensorial projections, what specific mean Intersection over Union (mIoU) percentage gain is achieved on the FSSD dataset compared to state-of-the-art methods, a performance outcome linked to its core innovations such as the adaptive sampling weights system?",
            "options": [
                "A. 2.1",
                "B. 2.7",
                "C. 3.4",
                "D. 2.4",
                "E. 5.0"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "2.4"
            ],
            "img_path": "2505.01057/fig1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01091",
        "img_path": "2505.01091/Model.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Cross-Domain Deep Learning Framework for Automated MRI Analysis and Clinical Insight Extraction",
                "B. Multimodal Transformer-Based Approach for Ultrasound Image Classification and Diagnostic Text Summarization",
                "C. Unified Neural Network Model for Multispectral Medical Image Segmentation and Report Automation",
                "D. Hybrid Vision-Language Architecture for CT Scan Interpretation and Radiology Workflow Optimization",
                "E. Any-to-Any Vision-Language Model for Multimodal X-ray Imaging and Radiological Report Generation"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Any-to-Any Vision-Language Model for Multimodal X-ray Imaging and Radiological Report Generation"
            ],
            "img_path": "2505.01091/Model.png"
        },
        "level2_qa": {
            "question": "In this paper, what single number representing research data indicates the total count of distinct patient studies initially extracted from the MIMIC-CXR repository, from which all X-rays (including both frontal and lateral views and the associated radiology report for each patient) were derived before any division into training and test sets?",
            "options": [
                "A. 154.721",
                "B. 33.588",
                "C. 78.584",
                "D. 121.133",
                "E. 44.996"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "78.584"
            ],
            "img_path": "2505.01091/Model.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00443",
        "img_path": "2505.00443/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Centralized Storage-Based Generation Models",
                "B. Collaborative Learning for Enhanced Text Summarization",
                "C. Distributed Retrieval-Augmented Generation",
                "D. Hybrid Neural Architectures for Data-Driven Retrieval",
                "E. Scalable Query Processing in Knowledge-Enhanced Systems"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Distributed Retrieval-Augmented Generation"
            ],
            "img_path": "2505.00443/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, a single sentence, describe the context we give you.",
            "options": [
                "A. The context is DRAG's framework establishing robust data privacy by decentralizing knowledge, a process that inherently accepts reduced retrieval efficiency compared to centralized systems, though TARW partially mitigates this by optimizing peer discovery.",
                "B. The context is the Topic-Aware Random Walk (TARW) algorithm being the central component of DRAG that not only facilitates efficient peer discovery but also directly enforces data sharing policies defined by users, thereby single-handedly ensuring both privacy and retrieval performance.",
                "C. The context is DRAG operating as an auxiliary P2P network that complements existing centralized RAG systems by handling queries for highly dynamic or sensitive information, using TARW to locate specialized peers, while general knowledge queries are still routed to the main central database.",
                "D. The context is DRAG's utilization of LLMs solely within the TARW algorithm for query topic extraction, which, while improving peer discovery targeting, primarily serves to reduce the computational load on individual peers rather than fundamentally enabling the system's core privacy benefits or its overall retrieval effectiveness compared to centralized models.",
                "E. The context is DRAG's integrated approach where its architectural decentralization, eliminating a central knowledge base to enhance data privacy and user control, is synergistically combined with the Topic-Aware Random Walk (TARW) algorithm, which leverages LLMs for targeted peer discovery, thereby enabling efficient knowledge retrieval comparable to centralized systems but with significantly reduced communication overhead compared to flooding, thus addressing key limitations of both centralized and basic decentralized RAG."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "The context is DRAG's integrated approach where its architectural decentralization, eliminating a central knowledge base to enhance data privacy and user control, is synergistically combined with the Topic-Aware Random Walk (TARW) algorithm, which leverages LLMs for targeted peer discovery, thereby enabling efficient knowledge retrieval comparable to centralized systems but with significantly reduced communication overhead compared to flooding, thus addressing key limitations of both centralized and basic decentralized RAG."
            ],
            "img_path": "2505.00443/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00416",
        "img_path": "2505.00416/x2.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. ScaleTrack: Evaluating User Behavior in Automated GUI Testing",
                "B. Back-Track: A Framework for Optimizing GUI Automation Performance",
                "C. Scaling GUI Agents for Enhanced User Interaction Analysis",
                "D. ScaleTrack: Scaling and back-tracking Automated GUI Agents",
                "E. Automated GUI Agents: Adaptive Scaling and Error Correction Techniques"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "ScaleTrack: Scaling and back-tracking Automated GUI Agents"
            ],
            "img_path": "2505.00416/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement provides the most accurate and comprehensive explanation of how ScaleTrack's distinct strategies for (i) unifying GUI data and (ii) integrating forward and backward action analysis in its training, individually address the stated limitations in GUI grounding and planning respectively, and also correctly identifies how its specific coordinate representation choice directly supports one of these enhancements?",
            "options": [
                "A. ScaleTrack's unification of GUI data primarily enhances planning by providing diverse historical action contexts, while its forward-backward action analysis in training directly addresses insufficient data for GUI grounding; its point-based coordinates improve the processing speed for both grounding and planning.",
                "B. The core of ScaleTrack's approach to GUI grounding involves backtracking historical actions to understand GUI evolution, while its solution for planning limitations is the unification of diverse GUI samples into a common template. Its relative coordinate system primarily ensures compatibility with various MLLM input constraints.",
                "C. ScaleTrack rectifies the lack of training data for GUI grounding through its careful collection and unification of GUI samples, and mitigates the oversight of historical action analysis in planning with its forward prediction and backtracking method; its adoption of point-format relative coordinates specifically enhances the precision of the grounding process.",
                "D. ScaleTrack's forward prediction and backtracking strategy is chiefly designed to scale the training data for GUI grounding models by creating synthetic historical paths, while its data unification technique improves planning by ensuring consistent action sequences. Its box-format coordinate system is chosen for its prevalence in GUI agent operations.",
                "E. By focusing on point-based relative coordinates, ScaleTrack effectively addresses the problem of insufficient training data for both GUI grounding and planning, while its novel training strategy of backtracking historical behaviors mainly serves to unify GUI element descriptions from diverse sources."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "ScaleTrack rectifies the lack of training data for GUI grounding through its careful collection and unification of GUI samples, and mitigates the oversight of historical action analysis in planning with its forward prediction and backtracking method; its adoption of point-format relative coordinates specifically enhances the precision of the grounding process."
            ],
            "img_path": "2505.00416/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00496",
        "img_path": "2505.00496/SurveyFlow.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Assessing the Reliability of Human Control in Automated Nuclear Defense Systems",
                "B. Out of the Loop Again: How Dangerous is Weaponizing Automated Nuclear Systems?",
                "C. The Ethics of Autonomous Decision-Making in Strategic Weaponry",
                "D. Implications of AI Integration in Global Nuclear Deterrence Frameworks",
                "E. Evaluating Risk Factors in Fully Automated Military Command Protocols"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Out of the Loop Again: How Dangerous is Weaponizing Automated Nuclear Systems?"
            ],
            "img_path": "2505.00496/SurveyFlow.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the reported findings from the survey experiments, what singular outcome highlights the primary assessed benefit of integrating AI with nuclear threats in certain circumscribed situations, despite acknowledged escalatory risks?",
            "options": [
                "A. Deterrence",
                "B. Automation",
                "C. Advantages",
                "D. Accidents",
                "E. Resolve"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "advantages"
            ],
            "img_path": "2505.00496/SurveyFlow.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00430",
        "img_path": "2505.00430/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Energy-Efficient Signal Processing in Multi-hop MIMO Networks",
                "B. Optimizing Beamforming Techniques for Wireless Sensor Networks",
                "C. Over-the-Air Inference over Multi-hop MIMO Networks",
                "D. Distributed Learning Algorithms in Massive MIMO Systems",
                "E. Latency Reduction Strategies for Multi-hop Wireless Communications"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Over-the-Air Inference over Multi-hop MIMO Networks"
            ],
            "img_path": "2505.00430/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence accurately describes the core methodological difference in how precoding matrices are determined within the proposed multi-hop MIMO framework versus the approach cited in reference [9], particularly concerning the timing and dependency relative to neural network weight training?",
            "options": [
                "A. The proposed framework, similar to reference [9], iteratively updates precoding matrices and neural network weights simultaneously through back-propagation across the MIMO channel for optimal joint adaptation.",
                "B. In contrast to reference [9] where precoding matrices are trained concurrently with neural network weights, the proposed method calculates precoding matrices by solving an optimization problem only after the PrototypeNet weights have been fully trained.",
                "C. Reference [9] obtains precoding matrices post-neural network training, whereas the proposed framework determines them prior to training PrototypeNet weights, relying solely on initial channel state information.",
                "D. Both the proposed framework and reference [9] adopt an identical strategy of deriving precoding matrices from pre-trained neural network weights, differing only in the multi-hop versus single-hop application.",
                "E. The proposed method eliminates the need for precoding matrices by directly using PrototypeNet weights for over-the-air transmission, a significant departure from the precoding-dependent approach of reference [9]."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "In contrast to reference [9] where precoding matrices are trained concurrently with neural network weights, the proposed method calculates precoding matrices by solving an optimization problem only after the PrototypeNet weights have been fully trained."
            ],
            "img_path": "2505.00430/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00497",
        "img_path": "2505.00497/x2.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Adaptive Framework for Real-Time Audio-Visual Speech Enhancement in Noisy Environments",
                "B. KeySync: A Robust Approach for Leakage-free Lip Synchronization in High Resolution",
                "C. Deep Temporal Modeling for Accurate Facial Expression Recognition in High-Definition Videos",
                "D. Multi-Modal Fusion Techniques for Improved Video Captioning Using Lip Movement Analysis",
                "E. Neural Architectures for Efficient Noise Reduction in High Resolution Audio Transmission"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "KeySync: A Robust Approach for Leakage-free Lip Synchronization in High Resolution"
            ],
            "img_path": "2505.00497/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which sentence best synthesizes the core differentiating strength of the KeySync framework by elucidating how its architectural choices and strategic focus comprehensively address the specific set of interconnected and previously inadequately resolved challenges inherent to lip synchronization, setting it apart from the limitations observed across various preceding methodologies?",
            "options": [
                "A. KeySync's distinction lies in its integrated two-stage, keyframe-based architecture with tailored masking, which holistically and effectively tackles the often-neglected or poorly managed triad of temporal inconsistency, expression leakage, and facial occlusions, unlike prior methods that typically offered piecemeal, insufficient, or problem-specific solutions.",
                "B. KeySync primarily leverages advanced diffusion model techniques for its keyframe interpolation and masking, leading to state-of-the-art temporal consistency and occlusion handling, while expression leakage is addressed as a secondary benefit of this core architecture.",
                "C. KeySync's innovation is its direct improvement over Wav2Lip by using a keyframe-based approach instead of GANs for frame generation, which inherently provides better temporal stability and reduces the need for complex lip-sync expert models to guide alignment.",
                "D. The critical advantage of KeySync is its novel LipLeak metric, which, when integrated into its two-stage training, allows for unprecedented reduction in expression leakage, making it superior to all other methods that lack such a targeted evaluative feedback loop for this specific issue.",
                "E. KeySync effectively solves temporal consistency by adopting KeyFace's interpolation, and separately addresses occlusions via its unique masking; however, expression leakage is primarily mitigated by its reliance on ReferenceNet for strong identity preservation, which minimizes conflicting expressions."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "KeySync's distinction lies in its integrated two-stage, keyframe-based architecture with tailored masking, which holistically and effectively tackles the often-neglected or poorly managed triad of temporal inconsistency, expression leakage, and facial occlusions, unlike prior methods that typically offered piecemeal, insufficient, or problem-specific solutions."
            ],
            "img_path": "2505.00497/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01065",
        "img_path": "2505.01065/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Assessing the Impact of AI on Cybersecurity Defense Mechanisms",
                "B. Good News for Script Kiddies? Evaluating Large Language Models for Automated Exploit Generation",
                "C. Automated Vulnerability Detection Using Large Language Models",
                "D. Enhancing Penetration Testing through Machine Learning Techniques",
                "E. A Comparative Study of Neural Networks for Malware Classification"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Good News for Script Kiddies? Evaluating Large Language Models for Automated Exploit Generation"
            ],
            "img_path": "2505.01065/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single number represents the total count of distinct vulnerable program versions (encompassing both original and refactored variants of the selected labs) that constitute the complete benchmark used for evaluating LLM exploit generation capabilities?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 5",
                "D. 7",
                "E. 10"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "10"
            ],
            "img_path": "2505.01065/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00337",
        "img_path": "2505.00337/x1.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Jiayan Huo",
                "B. Zhenmei Shi",
                "C. Xuyang Guo",
                "D. Zhao Song",
                "E. Jiahao Zhang"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Xuyang Guo"
            ],
            "img_path": "2505.00337/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement most accurately characterizes the overall efficacy and specific observed patterns of providing law-specific hints to text-to-video models, as detailed in the prompt-hint ablation study?",
            "options": [
                "A. Providing law-specific hints consistently improves model performance across all physical laws, especially when multiple levels of hints are provided.",
                "B. Law-specific hints generally enhance physical law adherence, although the degree of improvement varies significantly depending on the specific law and the model architecture.",
                "C. While hints sometimes lead to minor improvements for a few physical laws, they frequently fail to enhance, and can even degrade, performance for many laws, sometimes at multiple hint levels, indicating that prompt refinement alone is insufficient to address the models' inherent limitations in physical understanding.",
                "D. The impact of hints is primarily positive, with negative effects only observed in rare, isolated cases related to phenomenological principles and never for Newtonian mechanics.",
                "E. Hints are most effective when they are highly detailed (second-level hints), consistently overcoming initial deficiencies, whereas first-level hints often show mixed or negative results."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "While hints sometimes lead to minor improvements for a few physical laws, they frequently fail to enhance, and can even degrade, performance for many laws, sometimes at multiple hint levels, indicating that prompt refinement alone is insufficient to address the models' inherent limitations in physical understanding."
            ],
            "img_path": "2505.00337/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00300",
        "img_path": "2505.00300/x1.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Thermal Instabilities in Accretion Disks around Magnetized Neutron Stars",
                "B. Radiative Transfer Effects in High-Energy Flows near Compact Objects",
                "C. Neutrino Emission Mechanisms in Black Hole Accretion Environments",
                "D. Magnetohydrodynamic Turbulence in Photon-Dominated Stellar Accretion",
                "E. Magnetized Accretion onto Neutron Stars: from Photon-trapped to Neutrino-cooled Flows"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Magnetized Accretion onto Neutron Stars: from Photon-trapped to Neutrino-cooled Flows"
            ],
            "img_path": "2505.00300/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, describe in a single sentence the key characteristics of the steady-state equilibrium achieved in the neutron star's hydrostatic atmosphere under low accretion rates, specifically identifying the mechanism for inward energy transport through it and the primary method of balancing the accretion power.",
            "options": [
                "A. The atmosphere achieves equilibrium primarily through magnetic pressure balancing gravitational forces, with radiative diffusion transporting energy outwards and photon emission from the surface balancing accretion power.",
                "B. Equilibrium is maintained by strong poloidal magnetic fields arresting the inflow, while energy is transported via MRI-driven turbulence within the atmosphere and dissipated through plasmoid-mediated reconnection events.",
                "C. A toroidal magnetic field mediates the inward transport of energy and angular momentum through the hydrostatic atmosphere, enabling sustained accretion, and a steady state is achieved when neutrino emission from the dense, hot regions effectively balances the incoming accretion power.",
                "D. The hydrostatic atmosphere's equilibrium is characterized by centrifugal forces balancing gravity, facilitating accretion via a radiatively inefficient flow (RIAF) structure extending to the surface, with energy balanced by advection onto the neutron star.",
                "E. Thermal pressure fully supports the atmosphere against collapse, allowing accretion to proceed via convective overturn, with the primary energy balance achieved through trapping of radiation within the optically thick flow."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "A toroidal magnetic field mediates the inward transport of energy and angular momentum through the hydrostatic atmosphere, enabling sustained accretion, and a steady state is achieved when neutrino emission from the dense, hot regions effectively balances the incoming accretion power."
            ],
            "img_path": "2505.00300/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00432",
        "img_path": "2505.00432/PX4_architecture.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. D. Orsucci",
                "B. Welf Rehberg",
                "C. Mihir Kulkarni",
                "D. Sindre M. Hegre",
                "E. Kostas Alexis"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Sindre M. Hegre"
            ],
            "img_path": "2505.00432/PX4_architecture.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the explicitly stated numerical value representing the update frequency, in Hertz, of the angular velocity state topic on the Pixracer Pro, which serves as the scheduling trigger for the custom neural control module's inference callback?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 5",
                "D. 650",
                "E. 650650650650"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "650650650650"
            ],
            "img_path": "2505.00432/PX4_architecture.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00389",
        "img_path": "2505.00389/x1.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Multi-Stage Framework for Semi-Supervised Sentence Embedding Optimization",
                "B. Deep Contextual Encoding for Supervised Text Classification Tasks",
                "C. Efficient Bidirectional Transformers for Sentence-Level Semantic Analysis",
                "D. CSE-SFP: Enabling Unsupervised Sentence Representation Learning via a Single Forward Pass",
                "E. Hierarchical Attention Models for Enhanced Document Representation Learning"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "CSE-SFP: Enabling Unsupervised Sentence Representation Learning via a Single Forward Pass"
            ],
            "img_path": "2505.00389/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, how does CSE-SFP simultaneously generate the anchor embedding f(xi) and the positive instance embedding f(xi)+ from a single input xi within one forward pass for InfoNCE loss, and which specific representations (Rep1 or Rep2) assume these roles, leveraging what distinct derivation processes?",
            "options": [
                "A. Rep2 serves as the anchor f(xi) and Rep1 as the positive instance f(xi)+; this is achieved via a two-stage prompt where Rep1 is derived primarily through the model's encoding capabilities from an earlier stage of the prompt and Rep2 through its generative capabilities from a later stage, ensuring their distinction via differing guiding templates, embedding collection positions, and attention scopes, all within a single forward pass facilitated by the PLM's unidirectional attention.",
                "B. Rep1 serves as the anchor f(xi) and Rep2 as the positive instance f(xi)+; this is achieved by processing the input text twice with different dropout masks applied in each pass, where one pass emphasizes encoding and the other generation.",
                "C. The anchor f(xi) and positive instance f(xi)+ are generated by using Rep1 and Rep2 interchangeably, derived from applying two varied pre-defined templates (e.g., PromptEOL and PromptSTH) to the same input text, with their distinction arising solely from the template differences in a single pass.",
                "D. CSE-SFP generates Rep1 (encoding-focused) and Rep2 (generative-focused) from a two-stage prompt in one pass; these are then concatenated to form the anchor f(xi), while the original input serves as the positive f(xi)+, with distinction arising from Rep1 and Rep2 capturing different aspects.",
                "E. Rep2 serves as the anchor f(xi) and Rep1 as the positive instance f(xi)+; their distinction for contrastive learning is primarily due to Rep1 interacting exclusively with the prompt's prefix and Rep2 observing Rep1 but being instructed to be different, without specific reliance on the model's encoding versus generative capabilities."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "CSE-SFP designates Rep2 as the anchor sentence embedding f(xi) and Rep1 as the positive instance embedding f(xi)+, obtained simultaneously in a single forward pass using a two-stage prompt that leverages the model's unidirectional attention; Rep1 primarily relies on encoding capabilities from an earlier prompt stage, while Rep2 depends on generative abilities from a later stage, with their distinction further ensured by varied guiding templates, embedding collection positions, and attention scopes."
            ],
            "img_path": "2505.00389/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00380",
        "img_path": "2505.00380/x1.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Anjith George",
                "B. Hyelin Nam",
                "C. A. Chebboubi",
                "D. Ran Adler",
                "E. Sebastien Marcel"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Anjith George"
            ],
            "img_path": "2505.00380/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence best describes the core research impetus for conducting a comprehensive evaluation of presentation attack vulnerabilities in NIR-VIS cross-spectral face recognition systems?",
            "options": [
                "A. The primary impetus is to investigate the unaddressed vulnerability of cross-spectral systems, particularly those like DIU that bridge NIR-VIS modalities, to presentation attacks, a specific research area not covered by earlier studies that only examined NIR's standalone properties against some attack types.",
                "B. The research is primarily driven by the need to demonstrate the superior performance of Domain Invariant Units (DIU) in handling diverse modalities with minimal paired data, thereby establishing DIU as the leading CFR framework for general use.",
                "C. The impetus stems from Bhattacharjee et al.'s conclusive findings that NIR-reflective inks render cross-spectral face recognition systems highly vulnerable, prompting this paper to confirm these extensive vulnerabilities across various advanced CFR architectures.",
                "D. The core motivation is to highlight the general advantages of NIR imaging, such as its inherent robustness to illumination variations and better visibility through glasses, to encourage wider adoption of NIR-VIS CFR systems irrespective of attack scenarios.",
                "E. The research impetus is to develop novel loss functions, such as the cosine contrastive and distillation losses mentioned in the DIU framework, for training more robust cross-spectral face recognition models from scratch using limited datasets like MCXFace."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The primary impetus is to investigate the unaddressed vulnerability of cross-spectral systems, particularly those like DIU that bridge NIR-VIS modalities, to presentation attacks, a specific research area not covered by earlier studies that only examined NIR's standalone properties against some attack types."
            ],
            "img_path": "2505.00380/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00468",
        "img_path": "2505.00468/control_algorithm.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Optimization of Energy Consumption in HVAC Systems Using Adaptive Environmental Sensing",
                "B. Assessment of Indoor Air Quality Impact on Occupant Productivity in Office Buildings",
                "C. Modeling the Effects of Radiant Cooling on Human Thermal Response in Urban Environments",
                "D. Investigation of Ventilation Strategies for Improving Airflow Distribution in Multi-Zone Structures",
                "E. Evaluation of Thermal Control Based on Spatial Thermal Comfort with Reconstructed Environmental Data"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Evaluation of Thermal Control Based on Spatial Thermal Comfort with Reconstructed Environmental Data"
            ],
            "img_path": "2505.00468/control_algorithm.png"
        },
        "level2_qa": {
            "question": "In this paper, considering a single snapshot data collection scenario used for constructing the POD basis matrix, what is the total number of minutes the heating system is actively engaged in heating?",
            "options": [
                "A. 15",
                "B. 30",
                "C. 40",
                "D. 50",
                "E. 60"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "40"
            ],
            "img_path": "2505.00468/control_algorithm.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01104",
        "img_path": "2505.01104/x2.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Zheng Hui",
                "B. Do Huu Dat",
                "C. Nam Hyeonu",
                "D. Po-Yuan Mao",
                "E. Tae-Hyun Oh"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Do Huu Dat"
            ],
            "img_path": "2505.01104/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence best articulates the core philosophy behind the proposed method's specific adaptation of subject-driven generation principles, particularly how this adaptation enables improved attribute-object binding while simultaneously circumventing common dependencies found in alternative compositional and subject-driven approaches?",
            "options": [
                "A. The method primarily focuses on maximizing subject identity preservation using exact-object embeddings derived from synthetic images, thereby enhancing attribute binding through highly specific visual prototypes.",
                "B. By fine-tuning the entire image encoder and text encoder, the method creates highly specialized prototype embeddings that rigidly enforce attribute binding, similar to how subject-driven models ensure identity.",
                "C. The approach leverages prototype embeddings with a deliberate acceptance of reduced precision in subject identity compared to specialized subject-driven methods, thereby gaining flexibility for robust attribute binding and image diversity without needing explicit human-annotated layouts often required by other compositional techniques.",
                "D. The core innovation lies in using attention map control combined with synthetic reference images for subject-driven generation, which allows direct manipulation of latent space to ensure precise attribute-object pairing, a technique superior to layout-based methods.",
                "E. The method pioneers the use of subject-driven techniques for attribute binding by ensuring prototype embeddings perfectly mirror exact-object embeddings, thereby eliminating the need for segmentation-based localization training common in other compositional models."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The approach leverages prototype embeddings with a deliberate acceptance of reduced precision in subject identity compared to specialized subject-driven methods, thereby gaining flexibility for robust attribute binding and image diversity without needing explicit human-annotated layouts often required by other compositional techniques."
            ],
            "img_path": "2505.01104/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01159",
        "img_path": "2505.01159/x2.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. A Deep Learning Approach to Multi-Scale Boundary Value Problems with Variable Coefficients",
                "B. Neural Network Models for Nonlinear Dynamics in Singular Perturbation Systems",
                "C. A Parameter-Driven Physics-Informed Neural Network Framework for Solving Two-Parameter Singular Perturbation Problems Involving Boundary Layers",
                "D. Adaptive Mesh Refinement Techniques for Multi-Parameter Differential Equations",
                "E. An Energy-Based Framework for Solving Reaction-Diffusion Equations Using Physics-Informed Networks"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "A Parameter-Driven Physics-Informed Neural Network Framework for Solving Two-Parameter Singular Perturbation Problems Involving Boundary Layers"
            ],
            "img_path": "2505.01159/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific numerical value representing the sum of the number of interior collocation points (ηo), the number of boundary collocation points (ηb), and the number of hidden layers, when these parameters are configured for a two-dimensional, time-independent singular perturbation problem?",
            "options": [
                "A. 1264",
                "B. 11002",
                "C. 11000",
                "D. 1258",
                "E. 11008"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "11008"
            ],
            "img_path": "2505.01159/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01106",
        "img_path": "2505.01106/x1.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Kou Murayama",
                "B. Celeste Kidd",
                "C. Rania Abdelghani",
                "D. Hélène Sauzéon",
                "E. Pierre-Yves Oudeyer"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Rania Abdelghani"
            ],
            "img_path": "2505.01106/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, a single sentence, describe the context we give you.",
            "options": [
                "A. The study primarily demonstrates that providing middle school students with 'efficient' pre-formulated questions for ChatGPT significantly boosts their science investigation learning outcomes and AI literacy, regardless of their metacognitive skills.",
                "B. The research highlights that most middle school students (14-15 years old) possess adequate skills to effectively use GenAI tools like ChatGPT for complex science tasks, primarily needing minor guidance on advanced prompt engineering rather than fundamental AI literacy.",
                "C. A key methodological aspect involved assessing students' ability to extract and utilize textual information from problem descriptions, while deliberately excluding image-based context to simplify the task of formulating effective ChatGPT prompts.",
                "D. The investigation reveals a concerning pattern where middle school students' interaction with ChatGPT for science problems is characterized by over-reliance, suboptimal questioning and evaluation strategies, and misconceptions about AI capabilities, leading to moderate learning gains despite unlimited tool access and often irrespective of prior subject knowledge.",
                "E. The study's findings advocate for restricting student access to GenAI tools in educational settings until they develop strong metacognitive skills, as self-reported AI understanding was found to be the primary determinant of successful learning outcomes."
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "The investigation reveals a concerning pattern where middle school students' interaction with ChatGPT for science problems is characterized by over-reliance, suboptimal questioning and evaluation strategies, and misconceptions about AI capabilities, leading to moderate learning gains despite unlimited tool access and often irrespective of prior subject knowledge."
            ],
            "img_path": "2505.01106/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01073",
        "img_path": "2505.01073/x2.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Pengfei Li",
                "B. Runnan Qi",
                "C. Zongyuan Li",
                "D. Yanan Ni",
                "E. Lumin Jiang"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Zongyuan Li"
            ],
            "img_path": "2505.01073/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, identify the single sentence that explicitly states the direct operational consequence for Large Language Models (LLMs) stemming from the dual challenge of insufficient domain-specific data in their pre-training and the impracticality of extensive post-training for specialized scenarios.",
            "options": [
                "A. The lack of domain-specific data in the pre-training of Large Language Models (LLMs) severely limits LLM-based decision systems in specialized applications, while post-training a model in the scenarios requires significant computational resources.",
                "B. These limitations consequently compel LLMs to operate on flawed knowledge representations.",
                "C. How to autonomously and computationally obtain accurate knowledge remains an unsolved problem.",
                "D. Usually, reflection achieves better results than non-learning methods but still suffers from hallucination in the reflecting stage.",
                "E. As a result, researchers who post-train a model must face a choice: either accept relatively low capabilities of smaller/quantilized/LoRA models or invest huge computing resources to complete the training of large models with hundreds of billions of parameters."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "These limitations consequently compel LLMs to operate on flawed knowledge representations."
            ],
            "img_path": "2505.01073/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01081",
        "img_path": "2505.01081/x2.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Optimizing Neural Network Architectures for Visual Pattern Recognition in ARC Tasks",
                "B. A Reinforcement Learning Approach to Adaptive Program Generation in Abstract Reasoning",
                "C. Hierarchical Feature Extraction Methods for Enhanced Performance on the ARC Dataset",
                "D. Probabilistic Models for Incremental Learning in Automated Program Synthesis",
                "E. MADIL: An MDL-based Framework for Efficient Program Synthesis in the ARC Benchmark"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "MADIL: An MDL-based Framework for Efficient Program Synthesis in the ARC Benchmark"
            ],
            "img_path": "2505.01081/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, a single number, show the research data.",
            "options": [
                "A. 2024",
                "B. 4",
                "C. 7",
                "D. 20",
                "E. 2"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "7"
            ],
            "img_path": "2505.01081/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01083",
        "img_path": "2505.01083/framework_newli.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. DexFlow: A Unified Approach for Dexterous Hand Pose Retargeting and Interaction",
                "B. HandPoseNet: Real-Time Estimation of Dynamic Hand Movements for Virtual Reality",
                "C. Multi-Finger Gesture Recognition Using Deep Neural Networks for Robotic Manipulation",
                "D. Adaptive Control Strategies for Biomechanical Hand Models in Teleoperation Systems",
                "E. Unified Framework for Object Interaction Modeling and Grasp Stability Assessment"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "DexFlow: A Unified Approach for Dexterous Hand Pose Retargeting and Interaction"
            ],
            "img_path": "2505.01083/framework_newli.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct objects for which optimized grasp trajectories, supporting cross-hand topology migration and covering dynamic adjustments, were generated to form the comprehensive benchmark dataset?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 50",
                "D. 292",
                "E. 68"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "50"
            ],
            "img_path": "2505.01083/framework_newli.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00394",
        "img_path": "2505.00394/x5.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Adaptive Neural Pathways for Enhanced Video Segmentation in Dynamic Environments",
                "B. Robust Feature Extraction Using Temporal-Spike Models in Biased Visual Streams",
                "C. Optimized Transport Mechanisms for Saliency Mapping in Multi-Modal Video Data",
                "D. Composite Bias Correction via Spike-Integrated Region Proposal Networks",
                "E. SOTA: Spike-Navigated Optimal TrAnsport Saliency Region Detection in Composite-bias Videos"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "SOTA: Spike-Navigated Optimal TrAnsport Saliency Region Detection in Composite-bias Videos"
            ],
            "img_path": "2505.00394/x5.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the exact number of distinct loss components integrated into the final overall loss function during the simultaneous optimization of both the T-net and F-net modules within the SOTA framework, as described in the methodology and illustrated by the interplay of adversarial training between the two networks?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.00394/x5.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01022",
        "img_path": "2505.01022/x1.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Analyzing Developer Behavior Patterns for Efficient Bug Resolution Using Graph Neural Networks",
                "B. A Heterogeneous Graph Approach to Predicting Software Vulnerabilities in Large Codebases",
                "C. Optimizing Commit Message Generation Through Multimodal Machine Learning Techniques",
                "D. Identifying Refactoring Opportunities via Code Similarity Graphs and Deep Learning",
                "E. Detecting the Root Cause Code Lines in Bug-Fixing Commits by Heterogeneous Graph Learning"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Detecting the Root Cause Code Lines in Bug-Fixing Commits by Heterogeneous Graph Learning"
            ],
            "img_path": "2505.01022/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the numerical difference between the highest and the lowest percentage points of MFR improvement achieved by RC_Detector compared to state-of-the-art approaches, based on the experimental results provided?",
            "options": [
                "A. 62.01",
                "B. 48.33",
                "C. 5.17",
                "D. 131.65",
                "E. 56.84"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "62.01"
            ],
            "img_path": "2505.01022/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00375",
        "img_path": "2505.00375/x6.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Predicting Delivery Route Efficiency in Urban Logistics with Imbalanced Demand",
                "B. Learning to Estimate Package Delivery Time in Mixed Imbalanced Delivery and Pickup Logistics Services",
                "C. Analyzing Pickup and Delivery Patterns for Optimizing Fleet Scheduling",
                "D. Modeling Time Variability in Pure Pickup Logistics Networks Using Machine Learning",
                "E. Optimization of Delivery Time Estimation under Homogeneous Delivery and Pickup Scenarios"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Learning to Estimate Package Delivery Time in Mixed Imbalanced Delivery and Pickup Logistics Services"
            ],
            "img_path": "2505.00375/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, provide a single sentence that accurately describes the specific refinement within TransPDT's mobility modeling component which directly rectifies an identified oversight in Wen et al. (2023a)'s approach to factors influencing location transitions, distinct from the model's general use of Transformer encoders for spatio-temporal dependencies.",
            "options": [
                "A. The adoption of a Transformer encoder architecture for modeling historical package routes, which inherently captures long-distance dependencies more effectively than the RNN-based methods potentially implied by Wen et al. (2023a)'s focus on route sequencing.",
                "B. The implementation of a dedicated pattern memory with an attention mechanism to manage the imbalanced nature of pickup tasks, a factor Wen et al. (2023a) did not explicitly isolate for its impact on courier decision-making regarding location transitions.",
                "C. The division of daily operations into discrete time slots (12 slots of 2 hours each) to construct distinct location-pair matrices that incorporate both spatial distance and time-of-day specific mobility patterns, thereby addressing Wen et al. (2023a)'s neglect of these dynamic influences on location transitions.",
                "D. The utilization of an attention-based LSTM within the spatial mobility-based multi-task prediction module to predict the intermediate probability of package handling, which offers a more granular approach than Wen et al. (2023a)’s method of ranking package and location sequences.",
                "E. The formulation of route prediction as an auxiliary task to delivery time prediction, which provides a more comprehensive model of courier spatial movement than Wen et al. (2023a)’s singular focus on ranking sequences without considering the full dynamics of location transitions."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The division of daily operations into discrete time slots (12 slots of 2 hours each) to construct distinct location-pair matrices that incorporate both spatial distance and time-of-day specific mobility patterns, thereby addressing Wen et al. (2023a)'s neglect of these dynamic influences on location transitions."
            ],
            "img_path": "2505.00375/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00421",
        "img_path": "2505.00421/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. High-Fidelity 3D Model Reconstruction from Stereo Video Sequences",
                "B. Temporal Optimization Techniques for Live 2D Character Animation",
                "C. Real-Time Animatable 2DGS-Avatars with Detail Enhancement from Monocular Videos",
                "D. Monocular Video-Based Facial Expression Transfer with Style Adaptation",
                "E. Enhanced Detail Synthesis for Static 2D Graphics Using Machine Learning"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Real-Time Animatable 2DGS-Avatars with Detail Enhancement from Monocular Videos"
            ],
            "img_path": "2505.00421/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the sum of the dimensionalities of the SMPL pose parameters input to the global pose encoder and the learnable feature vector representing a triangle index used within the local geometry encoder's input construction?",
            "options": [
                "A. 72",
                "B. 256",
                "C. 263",
                "D. 328",
                "E. 335"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "328"
            ],
            "img_path": "2505.00421/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00490",
        "img_path": "2505.00490/ufl_formulation_2.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Adaptive Resource Allocation Strategies in Dynamic Workforce Environments",
                "B. Optimal Interactive Learning on the Job via Facility Location Planning",
                "C. Hierarchical Task Scheduling for Enhanced Employee Performance",
                "D. Data-Driven Approaches to Facility Management and Workflow Optimization",
                "E. Integrating Machine Learning with Supply Chain Logistics for Operational Efficiency"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Optimal Interactive Learning on the Job via Facility Location Planning"
            ],
            "img_path": "2505.00490/ufl_formulation_2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the arithmetic sum of all distinct integer percentage points explicitly stated as COIL's cost reductions over baselines (interpreting a range X%-Y% as contributing both X and Y to the sum) based on the reported experimental results?",
            "options": [
                "A. 35",
                "B. 39",
                "C. 43",
                "D. 55",
                "E. 57"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "55"
            ],
            "img_path": "2505.00490/ufl_formulation_2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00450",
        "img_path": "2505.00450/buffer.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Analyzing the Impact of Urban Rail Projects on Residential Property Values Using Spatial Panel Models",
                "B. Spatial vertical regression for spatial panel data: Evaluating the effect of the Florentine tramway's first line on commercial vitality",
                "C. A Comparative Study of Horizontal Regression Techniques in Spatial Econometrics for Transportation Infrastructure",
                "D. Assessing Economic Growth in Florentine Districts Through Temporal Panel Data Analysis",
                "E. Modeling Commercial Activity Changes in City Centers Using Non-Spatial Time Series Methods"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Spatial vertical regression for spatial panel data: Evaluating the effect of the Florentine tramway's first line on commercial vitality"
            ],
            "img_path": "2505.00450/buffer.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the explicitly stated number of yearly time periods constituting the pre-treatment phase for the commercial vitality analysis, a duration identified as a factor contributing to potential overfitting with traditional estimation methods?",
            "options": [
                "A. 4",
                "B. 5",
                "C. 10",
                "D. 11",
                "E. 21"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "10"
            ],
            "img_path": "2505.00450/buffer.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01030",
        "img_path": "2505.01030/silence-sync.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Challenges in Multimedia Literacy Among Deaf Content Creators",
                "B. Economic Impacts of Accessibility Technology on Deaf Professionals",
                "C. Barriers to Employment: The Deaf Multimedia Authoring Tax",
                "D. Navigating Career Development for Deaf Individuals in Digital Media",
                "E. The Role of Assistive Tools in Enhancing Employment for Deaf Authors"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Barriers to Employment: The Deaf Multimedia Authoring Tax"
            ],
            "img_path": "2505.01030/silence-sync.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the exact playback speed (to two decimal digits) to which the TTS system's speaking rate was adjusted in the referenced CHI 2024 video to address English voiceover timing relative to ASL signing?",
            "options": [
                "A. 1.25x",
                "B. 1.50x",
                "C. 1.10x",
                "D. 1.35x",
                "E. 2.00x"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "1.35x"
            ],
            "img_path": "2505.01030/silence-sync.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00426",
        "img_path": "2505.00426/x1.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Optimizing Reinforcement Learning for Multi-Component Integration",
                "B. Unsupervised Feature Extraction Techniques in Part Segmentation",
                "C. Leveraging Pretrained Diffusion Models for Zero-Shot Part Assembly",
                "D. Evaluating Graph Neural Networks for Modular Assembly Tasks",
                "E. Transfer Learning Approaches in Automated Component Recognition"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Leveraging Pretrained Diffusion Models for Zero-Shot Part Assembly"
            ],
            "img_path": "2505.00426/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single integer represents the ratio of the specific component count threshold (above which assembly errors markedly increase in zero-shot settings) to the number of distinct intermediate noise levels explicitly named and utilized in experimental validation?",
            "options": [
                "A. 2",
                "B. 4",
                "C. 5",
                "D. 10",
                "E. 20"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "5"
            ],
            "img_path": "2505.00426/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.00488",
        "img_path": "2505.00488/Adapt_RL_latest_new.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. HARMONY: Hierarchical Adaptive Robotics for Multi-environment Navigation and Yield",
                "B. MULE: Multi-terrain and Unknown Load Adaptation for Effective Quadrupedal Locomotion",
                "C. QUADRA: Quadrupedal Robot Dynamics Analysis under Variable Payload Conditions",
                "D. SENTINEL: Sensor-Enhanced Navigation Techniques for Irregular Terrain Exploration",
                "E. ROBUST-LEG: Reinforced Optimization for Balanced Stability and Terrain Traversing in Robotic Legs"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "MULE: Multi-terrain and Unknown Load Adaptation for Effective Quadrupedal Locomotion"
            ],
            "img_path": "2505.00488/Adapt_RL_latest_new.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the distinct training phases for the locomotion control framework, what is the specific number of training iterations dedicated exclusively to refining the policy component primarily responsible for learning corrective actions to adapt to payload variations and diverse terrains, after the initial establishment of baseline locomotion capabilities?",
            "options": [
                "A. 1000",
                "B. 1500",
                "C. 500",
                "D. 2000",
                "E. 4096"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "500"
            ],
            "img_path": "2505.00488/Adapt_RL_latest_new.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01044",
        "img_path": "2505.01044/PerformanceDefault_Spells_Illustration.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Analyzing Survival Outcomes Using Enhanced Cox Proportional Hazards Models for Financial Risks",
                "B. Evaluating Credit Risk Dynamics Through Multi-State Recurrent Event Modeling Approaches",
                "C. A Comparative Study of Time-Dependent Covariates in Recurrent Event Financial Default Prediction",
                "D. Integrating Machine Learning with Cox Regression for Predicting Time to Default Events",
                "E. Towards modelling lifetime default risk: Exploring different subtypes of recurrent event Cox-regression models"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Towards modelling lifetime default risk: Exploring different subtypes of recurrent event Cox-regression models"
            ],
            "img_path": "2505.01044/PerformanceDefault_Spells_Illustration.png"
        },
        "level2_qa": {
            "question": "In this paper, what single sentence best synthesizes the critical insight derived from the comparative performance of the Andersen-Gill (AG), Prentice-Williams-Peterson (PWP), and Time to First Default (TFD) models regarding the practical modeling implications of recurrent default events and their baseline hazard characteristics in the South African mortgage data?",
            "options": [
                "A. The underperformance of the AG model implied varying baseline hazards across spells, yet the PWP model's comparable performance to the TFD model suggested that the overall impact or prevalence of these recurrent events was not significant enough in this dataset to warrant the PWP's additional complexity over the TFD model for estimating lifetime default risk.",
                "B. The Andersen-Gill model's failure confirmed that baseline hazards were constant across spells, making the Prentice-Williams-Peterson model's spell-specific approach unnecessarily complex and no better than the TFD model.",
                "C. The Prentice-Williams-Peterson model, by effectively modeling spell-specific baseline hazards, significantly outperformed both the AG and TFD models, proving indispensable for accurate PD estimation with this dataset.",
                "D. The Time to First Default model inherently accounted for the complexities of recurrent defaults and varying baseline hazards, rendering both the AG and PWP models redundant for the analyzed dataset.",
                "E. The South African mortgage data exhibited such a high prevalence and impact of recurrent defaults with stable baseline hazards across spells that only the AG model was theoretically suited, though it empirically underperformed due to limitations in the diagnostic tools used."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The underperformance of the AG model implied varying baseline hazards across spells, yet the PWP model's comparable performance to the TFD model suggested that the overall impact or prevalence of these recurrent events was not significant enough in this dataset to warrant the PWP's additional complexity over the TFD model for estimating lifetime default risk."
            ],
            "img_path": "2505.01044/PerformanceDefault_Spells_Illustration.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01139",
        "img_path": "2505.01139/x3.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Analyzing Passive Sybil Detection Techniques in Distributed Hash Tables",
                "B. Optimizing Data Retrieval Efficiency in IPFS Through Adaptive Routing Protocols",
                "C. Evaluating Consensus Mechanisms for Secure Peer-to-Peer Networks",
                "D. Active Sybil Attack and Efficient Defense Strategy in IPFS DHT",
                "E. Mitigating Network Partitioning Effects in Decentralized Storage Systems"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Active Sybil Attack and Efficient Defense Strategy in IPFS DHT"
            ],
            "img_path": "2505.01139/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the authors' experimental evaluation of D_KL distributions around non-attacked content using the Sridhar et al. detection threshold, what numerical value represents the percentage of lookups classified as false positives?",
            "options": [
                "A. 0.81",
                "B. 4.4",
                "C. 80",
                "D. 83",
                "E. 11"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "11"
            ],
            "img_path": "2505.01139/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01110",
        "img_path": "2505.01110/bpcw.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Adaptive Contextual Embeddings for Enhanced Large-Scale Language Models",
                "B. Optimizing Gradient Flow in Transformer Architectures for In-Context Learning",
                "C. Robust Feature Integration Techniques for Multi-Task Learning in NLP",
                "D. Scalable Memory-Augmented Networks for Improved Sequential Data Processing",
                "E. MateICL: Mitigating Attention Dispersion in Large-Scale In-Context Learning"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "MateICL: Mitigating Attention Dispersion in Large-Scale In-Context Learning"
            ],
            "img_path": "2505.01110/bpcw.png"
        },
        "level2_qa": {
            "question": "In this paper, what single-word phenomenon, increasingly problematic with a greater number of contextual examples in prior methods such as PCW that also segment context, is primarily counteracted by MateICL's strategy of recalibrating attention weights?",
            "options": [
                "A. Degradation",
                "B. Dispersion",
                "C. Constraint",
                "D. Indexing",
                "E. Overhead"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Dispersion"
            ],
            "img_path": "2505.01110/bpcw.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01074",
        "img_path": "2505.01074/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. NeuralNet Protocols: Deep Learning Approaches for Adaptive Wireless Systems",
                "B. Cognitive Radio Networks: Enhancing Spectrum Efficiency with AI Techniques",
                "C. WirelessAgent: Large Language Model Agents for Intelligent Wireless Networks",
                "D. Smart Mesh Networks: Distributed Algorithms for Autonomous Wireless Communication",
                "E. AI-Driven Optimization Methods in 5G and Beyond Wireless Infrastructure"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "WirelessAgent: Large Language Model Agents for Intelligent Wireless Networks"
            ],
            "img_path": "2505.01074/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, within the specific constraints detailed for the network slicing case study's eMBB slice, what is the numerical value representing the peak assignable bandwidth (in MHz) to an individual user, as dictated by its designated operational decision range?",
            "options": [
                "A. 5",
                "B. 6",
                "C. 20",
                "D. 90",
                "E. 120"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "20"
            ],
            "img_path": "2505.01074/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01079",
        "img_path": "2505.01079/x2.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Improving Editability in Image Generation with Layer-wise Memory",
                "B. Enhancing Image Quality through Multi-layer Feature Fusion",
                "C. Adaptive Memory Networks for Texture Synthesis in Image Generation",
                "D. Layer-specific Attention Mechanisms for Realistic Image Reconstruction",
                "E. Optimizing Generative Models with Hierarchical Context Embedding"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Improving Editability in Image Generation with Layer-wise Memory"
            ],
            "img_path": "2505.01079/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific percentage value is stated as the approximate initial computational time reduction achieved by Background Consistency Guidance (BCG) in single-step editing scenarios when compared to Latent Blending (LB), before considering the more substantial benefits in multi-step modifications?",
            "options": [
                "A. 0 (Based on BCG requiring no additional forward passes in multi-step contexts)",
                "B. 10 (The explicitly stated approximate reduction for single-step edits)",
                "C. 25 (A plausible higher arbitrary value for initial reduction)",
                "D. 50 (A significantly higher arbitrary value, potentially confused with larger multi-step gains)",
                "E. A value not numerically specified, only described qualitatively as an improvement."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "10"
            ],
            "img_path": "2505.01079/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01168",
        "img_path": "2505.01168/x2.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Harmonizing Intra-coherence and Inter-divergence in Ensemble Attacks for Adversarial Transferability",
                "B. Balancing Model Robustness and Gradient Obfuscation in Adversarial Training",
                "C. Optimizing Cross-Domain Consistency for Enhanced Adversarial Defense Mechanisms",
                "D. Evaluating Ensemble Strategies for Improved Robustness Against Black-Box Attacks",
                "E. Integrating Feature Alignment and Noise Injection in Adversarial Example Generation"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Harmonizing Intra-coherence and Inter-divergence in Ensemble Attacks for Adversarial Transferability"
            ],
            "img_path": "2505.01168/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, at what year was the concept of adversarial attacks first formalized, thereby exposing critical vulnerabilities in deep neural networks and catalyzing a surge in research within the field as referenced in the historical context of the study?",
            "options": [
                "A. 2019",
                "B. 2013",
                "C. 2014",
                "D. 2022",
                "E. 2023"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2013"
            ],
            "img_path": "2505.01168/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01121",
        "img_path": "2505.01121/x8.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Entropy Production and Fluctuation Theorems in Multi-Qubit Systems",
                "B. Nonclassical Correlations in Open Quantum Spin Chains under Thermal Noise",
                "C. Quantum Coherence Effects on Energy Transport in Coupled Qubit Networks",
                "D. Statistical Mechanics of Decoherence in Two-Particle Quantum Systems",
                "E. The thermodynamic uncertainty relation of a quantum-mechanically coupled two-qubit system"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "The thermodynamic uncertainty relation of a quantum-mechanically coupled two-qubit system"
            ],
            "img_path": "2505.01121/x8.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the approximate numerical value reported for the minimal thermodynamic uncertainty relation bound ($\\mathcal{Q}_{\\rm min}^{\\rm TQS}$) when a two-qubit system is subjected to strong inter-qubit coupling ($K \\gg 1$) combined with strong external driving fields ($\\tilde{\\Omega} > 3$)?",
            "options": [
                "A. 2.00",
                "B. 1.25",
                "C. 1.36",
                "D. 3.00",
                "E. 0.00"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "1.36"
            ],
            "img_path": "2505.01121/x8.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01146",
        "img_path": "2505.01146/figure3.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Advancements in Biomedical Text Mining: Algorithms, Benchmarks, and Use Cases",
                "B. Integrating Knowledge Graphs in Clinical NLP: Methods, Resources, and Evaluation",
                "C. Retrieval-Augmented Generation in Biomedicine: A Survey of Technologies, Datasets, and Clinical Applications",
                "D. A Comprehensive Review of Machine Learning Models for Medical Data Analysis",
                "E. Clinical Decision Support Systems: Technologies, Data Integration, and Future Directions"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Retrieval-Augmented Generation in Biomedicine: A Survey of Technologies, Datasets, and Clinical Applications"
            ],
            "img_path": "2505.01146/figure3.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the distinct approaches to knowledge graph interaction and prompt engineering detailed for ESCARGOT125 and NetMe 2.0, which statement accurately synthesizes their respective primary mechanisms for (1) accessing/creating knowledge graph information and (2) preparing that information for LLM consumption?",
            "options": [
                "A. Both ESCARGOT125 and NetMe 2.0 primarily rely on vectorizing knowledge graphs for semantic searching and use token-optimized retrieval for integrating knowledge into LLM prompts.",
                "B. ESCARGOT125 constructs knowledge graphs on-the-fly using OntoTagMe and transforms queries to retrieve UMLS-based diagnostic pathways, while NetMe 2.0 uses Cypher queries and selectively integrates knowledge through dynamic Graph of Thoughts.",
                "C. NetMe 2.0 employs Cypher queries for knowledge graph access and uses its Graph-RAG module for token-optimized retrieval into prompts, while ESCARGOT125 vectorizes knowledge graphs and uses dynamic Graph of Thoughts for prompt integration.",
                "D. ESCARGOT125 focuses on mining PubMed literature for knowledge graph construction and uses its Graph-RAG module for transforming graph data, whereas NetMe 2.0 utilizes pre-existing SPOKE biomedical knowledge graphs and implements token-optimized retrieval.",
                "E. ESCARGOT125 utilizes Cypher queries for retrieving information from knowledge graphs and employs dynamic Graph of Thoughts for selective prompt integration, whereas NetMe 2.0 focuses on on-the-fly knowledge graph construction with OntoTagMe and transforms this graph data into natural language prompts via its Graph-RAG module."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "ESCARGOT125 utilizes Cypher queries for retrieving information from knowledge graphs and employs dynamic Graph of Thoughts for selective prompt integration, whereas NetMe 2.0 focuses on on-the-fly knowledge graph construction with OntoTagMe and transforms this graph data into natural language prompts via its Graph-RAG module."
            ],
            "img_path": "2505.01146/figure3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01206",
        "img_path": "2505.01206/x2.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Carlos Brandl",
                "B. Fabian Egersdörfer",
                "C. Magdalena Görtz",
                "D. Anna-Katharina Nitschke",
                "E. Markus Hohenfellner"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Anna-Katharina Nitschke"
            ],
            "img_path": "2505.01206/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, acknowledging the Digital Twin's capacity to be 'predictive' and 'evolving' by reflecting the 'entire patient’s clinical journey' and utilizing 'continuous learning', which specific interaction pathway described within its operational framework is paramount for ensuring it 'support[s] and supplement[s] current clinical practice' rather than attempting to 'replac[e] rigorously derived clinical knowledge and guidelines'?",
            "options": [
                "A. The continuous updating of the Digital Cohort (DC) with patient data (PD) at intervals TDC, which refines the collective knowledge base used for training all models within the Resource Description Framework.",
                "B. The bi-directional communication pathway where the DT provides interpretable Decision Support output derived from predictions and simulations directly to the clinician, who then executes the medical decision.",
                "C. The implementation of the FHIR® protocol by the data transformer (A.a) to ensure consistent, secure, and up-to-date data formatting from distributed clinical data systems for machine learning algorithms.",
                "D. The periodic retraining of predictive models within the Resource Description Framework (RDF) using the comprehensive data backbone, including the Digital Cohort, facilitated by the Updater RDF (B2.a).",
                "E. The modular design (F1) of the Digital Twin, which allows for the standardized connection and independent validation of causal relationships and processing modules within the Resource Description Framework."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Bidirectional communication between the real and the digital world can be executed at each time point Tisubscript𝑇𝑖T_{i}italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTin real-time, passing multimodal data from the patient to the DT, expanding its patient-specific representation and allowing for predictions or simulations leading to an interpretable Decision Support output. This information is forwarded to the clinician in the real world to execute a medical decision related to medical interventions that lead to changes in the patient’s state and/or new data acquisition."
            ],
            "img_path": "2505.01206/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01150",
        "img_path": "2505.01150/sqra.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. R.A.Gruendl",
                "B. Ted K. Mburu",
                "C. Kangxuan Rong",
                "D. Campbell J. McColley",
                "E. Alexandra Werth"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Ted K. Mburu"
            ],
            "img_path": "2505.01150/sqra.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the distinct roles of Activity Theory (AT) in conceptual framing, the Synthetic Question-Response Analysis (SQRA) framework in pre-deployment validation, and the Qualtrics system in survey execution, which single sentence most accurately characterizes the primary mechanism ensuring continuous participant engagement for Group A specifically when the LLM API encounters a generation failure, thereby maintaining data collection integrity despite real-time AI unpredictability?",
            "options": [
                "A. Activity Theory's conceptualization of the AI as a mediating artifact guides the system to adaptively re-engage participants through alternative reflective prompts derived from its analytical components like subject-object-rules.",
                "B. The SQRA framework's iterative testing protocol is triggered in real-time to generate a validated alternative question from a pre-tested pool of synthetic interactions, ensuring immediate alignment with human response patterns.",
                "C. The Qualtrics system deploys a predefined backup question via a Branch logic when an API error prevents personalized question generation, ensuring the survey flow is not interrupted for the participant.",
                "D. Participant responses that lead to an API error are automatically re-submitted to the LLM API through the Qualtrics Web Service with incrementally adjusted prompt parameters until a valid question is successfully generated.",
                "E. The initial predefined question for Group A, designed with robust prompt engineering based on teamwork dynamics and SSRL, is re-presented to the participant to maintain thematic consistency and ensure reflective engagement."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "A Qualtrics Branch checks the response for validity; if an error occurs, a predefined backup question is used. The Branch stores either the AI-generated or backup question as piped text, which is displayed to the participant. This process is repeated for a set number of questions before the survey concludes."
            ],
            "img_path": "2505.01150/sqra.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01109",
        "img_path": "2505.01109/x2.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Evaluating Transfer Learning Approaches for Histopathological Image Classification",
                "B. Self-Supervision Enhances Instance-based Multiple Instance Learning Methods in Digital Pathology: A Benchmark Study",
                "C. Deep Learning Architectures for Whole Slide Image Analysis in Oncology",
                "D. Comparative Study of Supervised and Unsupervised Methods in Medical Image Segmentation",
                "E. Impact of Data Augmentation Techniques on CNN Performance in Pathology"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Self-Supervision Enhances Instance-based Multiple Instance Learning Methods in Digital Pathology: A Benchmark Study"
            ],
            "img_path": "2505.01109/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, by synthesizing information regarding the total MIL strategies benchmarked, the quantity of embedding-based MIL methods explicitly stated as included in the analysis, and the number of instance-based MIL methods newly introduced by the authors, what is the deduced count of *previously existing* instance-based MIL strategies that formed part of the comprehensive evaluation?",
            "options": [
                "A. 0",
                "B. 2",
                "C. 4",
                "D. 6",
                "E. 10"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2505.01109/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01120",
        "img_path": "2505.01120/pr-fig-1-3.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Evaluating the Impact of Data Cleaning on the Quality of Generated Pull Request Descriptions",
                "B. Analyzing the Role of Feature Engineering in Enhancing Pull Request Description Accuracy",
                "C. Assessing the Effects of Code Review Practices on Pull Request Approval Times",
                "D. Investigating the Influence of Automated Testing on Pull Request Merge Success Rates",
                "E. Exploring the Relationship Between Commit Message Quality and Pull Request Review Outcomes"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Evaluating the Impact of Data Cleaning on the Quality of Generated Pull Request Descriptions"
            ],
            "img_path": "2505.01120/pr-fig-1-3.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the precise numerical value representing the difference, in percentage points, between the highest and lowest average F1 score improvements that were explicitly reported for the individual ROUGE-1, ROUGE-2, and ROUGE-L metrics as a direct result of dataset refinement?",
            "options": [
                "A. 0.1",
                "B. 0.2",
                "C. 8.5",
                "D. 8.6",
                "E. 8.7"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "0.2"
            ],
            "img_path": "2505.01120/pr-fig-1-3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01234",
        "img_path": "2505.01234/x1.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Adaptive Machine Learning Techniques for Network Layer Security Enhancement",
                "B. Optimizing Signal Processing Algorithms for Wireless Sensor Networks",
                "C. Data-Driven Approaches to Medium Access Control in IoT Communications",
                "D. Evaluating Neural Network Models for Error Correction in Digital Transmission",
                "E. Robust Deep Learning-Based Physical Layer Communications: Strategies and Approaches"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Robust Deep Learning-Based Physical Layer Communications: Strategies and Approaches"
            ],
            "img_path": "2505.01234/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the discussion of transfer learning for enhancing robustness in beamforming under multi-user MISO downlink systems, what is the exact number of distinct wireless frequency bands explicitly stated as being utilized for knowledge transfer in order to improve adaptation efficiency and performance in challenging data-scarce scenarios?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2505.01234/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01224",
        "img_path": "2505.01224/pipeline.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Yan Luo",
                "B. Junjun Jiang",
                "C. Xin Xu",
                "D. Fei Ma",
                "E. Kui Jiang"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Kui Jiang"
            ],
            "img_path": "2505.01224/pipeline.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the empirical evaluations conducted, what precise quantitative value, denominated in decibels, represents the averaged margin of performance enhancement achieved by the proposed Relation-driven Mamba framework for UIE (RD-UIE) over the WMamba method, when this margin is consolidated across the complete set of underwater enhancement benchmark suites referenced in the performance analysis?",
            "options": [
                "A. 0.50",
                "B. 0.55",
                "C. 2.00",
                "D. 3.00",
                "E. The 0.55 dB figure represents a peak gain on one benchmark, not an average over the three."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "0.55"
            ],
            "img_path": "2505.01224/pipeline.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01273",
        "img_path": "2505.01273/x2.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Robust Prompt Engineering for Noise-Resilient Large Language Models",
                "B. Adaptive Fine-Tuning Techniques for Enhanced Model Generalization",
                "C. Mitigating Bias in Language Models through Contextual Prompt Optimization",
                "D. Anti-adversarial Learning: Desensitizing Prompts for Large Language Models",
                "E. Enhancing Language Model Robustness via Dynamic Input Transformation"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Anti-adversarial Learning: Desensitizing Prompts for Large Language Models"
            ],
            "img_path": "2505.01273/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most accurately describes the specific set of simultaneous requirements for LLM prompt desensitization in black-box scenarios that traditional privacy-preserving techniques (HE, MPC, FL) are stated to collectively fail in satisfying, thus highlighting the gap PromptObfus aims to fill?",
            "options": [
                "A. Traditional techniques are primarily ineffective because they cannot be applied to LLMs at all due to fundamental architectural incompatibilities, rather than specific operational tradeoffs.",
                "B. The principal inadequacy of established methods like HE, MPC, and FL in the context of LLM prompt privacy for black-box models lies in their collective failure to concurrently satisfy the demands for real-time performance, computational efficiency, and robust privacy protection.",
                "C. While computationally efficient, traditional privacy techniques for LLMs predominantly falter in black-box scenarios because they inadvertently compromise the semantic integrity of prompts, leading to unusable model outputs, a problem PromptObfus addresses through gradient feedback.",
                "D. The core challenge for methods such as HE, MPC, and FL is their inability to prevent privacy inference when user participation is high, which PromptObfus mitigates by eliminating the need for users to modify their prompts directly.",
                "E. Existing privacy solutions are largely sufficient for protecting PII within cloud LLMs, but they struggle specifically with the \"anti-adversarial\" requirement of making sensitive content imperceptible to humans while ensuring model outputs remain consistent."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "These methods often fail to simultaneously address the competing requirements of real-time performance, computational efficiency, and robust privacy protection."
            ],
            "img_path": "2505.01273/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01277",
        "img_path": "2505.01277/Figure_1.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Integrative Multi-Scale Modeling of Protein Dynamics Using Generative Sequence Approaches",
                "B. Evaluating Iterative Protein Design Strategies Through Hybrid Optimization and Predictive Scoring",
                "C. Scoring-Assisted Generative Exploration for Proteins (SAGE-Prot): A Framework for Multi-Objective Protein Optimization via Iterative Sequence Generation and Evaluation",
                "D. Framework for Multi-Objective Optimization in Protein Engineering via Evolutionary Sequence Sampling",
                "E. Sequence-Based Generative Models for Directed Protein Function Enhancement and Stability Assessment"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Scoring-Assisted Generative Exploration for Proteins (SAGE-Prot): A Framework for Multi-Objective Protein Optimization via Iterative Sequence Generation and Evaluation"
            ],
            "img_path": "2505.01277/Figure_1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the development of Quantitative Structure-Property Relationship (QSPR) models, what is the total count of unique hyperparameter types, as specified in the text describing their optimization via grid search for the explicitly named decision tree-based regression algorithms?",
            "options": [
                "A. 3",
                "B. 4",
                "C. 5",
                "D. 9",
                "E. 2"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "5"
            ],
            "img_path": "2505.01277/Figure_1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01286",
        "img_path": "2505.01286/x1.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Multi-Scale CNN Networks for Solar Energy Prediction Using Environmental Features",
                "B. 2DXformer: Dual Transformers for Wind Power Forecasting with Dual Exogenous Variables",
                "C. Graph-Based Neural Models for Short-Term Load Forecasting in Smart Grids",
                "D. Hybrid LSTM Architectures for Temperature Forecasting with Meteorological Data Integration",
                "E. Attention-Enhanced Recurrent Networks for Hydropower Generation Estimation Under Variable Conditions"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2DXformer: Dual Transformers for Wind Power Forecasting with Dual Exogenous Variables"
            ],
            "img_path": "2505.01286/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, the 2DXformer architecture distinctly categorizes its inputs into endogenous (historical power X), exogenous static (Zs, such as wind speed and direction), and exogenous dynamic (Zd) variables, applying channel-independent embedding to all, then using an attention mechanism specifically for inter-exogenous variable correlations, and finally employing a residual multi-layer perceptron to establish the influence of the combined exogenous variables on the endogenous variables.",
            "options": [
                "A. This differentiated processing primarily enhances spatiotemporal correlation extraction across all variable types simultaneously, leveraging the Encoder-Only Transformer architecture for deeper feature learning.",
                "B. This approach is specifically designed to mitigate the limitation of previous models where treating endogenous and exogenous variables uniformly led to unnecessary interactions and increased model complexity.",
                "C. The primary outcome of this variable categorization and specific processing is to ensure that exogenous dynamic variables (Zd) have a more significant modeled impact on predictions than exogenous static variables (Zs) through the residual MLP.",
                "D. By processing exogenous variables separately with attention and then combining their influence via an MLP, the model focuses exclusively on inter-variable relationships among exogenous inputs, thereby improving the processing of historical wind power data (X) independently.",
                "E. The channel-independent embedding of these three variable types is the sole mechanism through which 2DXformer addresses the lack of modeling for general inter-variable relationships, which was identified as the primary limitation in prior forecasting works."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "This approach is specifically designed to mitigate the limitation of previous models where treating endogenous and exogenous variables uniformly led to unnecessary interactions and increased model complexity."
            ],
            "img_path": "2505.01286/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01180",
        "img_path": "2505.01180/x1.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. MS-tree: An optimized cache-friendly B-tree variant",
                "B. BS-tree: A gapped data-parallel B-tree",
                "C. Parallel B-tree algorithms for efficient range queries",
                "D. Cache-aware indexing structures for large-scale databases",
                "E. A novel lock-free approach to concurrent B-tree updates"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "BS-tree: A gapped data-parallel B-tree"
            ],
            "img_path": "2505.01180/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, if the `succ_>=` operator, during a leaf node deletion of key `k`, identifies the start of a contiguous sequence where multiple slots (including gaps filled by duplication) effectively hold the value `k`, what is the prescribed action for this entire sequence according to the BS-tree's deletion logic?",
            "options": [
                "A. The entire sequence of slots is overwritten with the key value found immediately following this sequence within the node.",
                "B. Each slot in the sequence is individually set to MAXKEY, and the slot use count is decremented for each slot in the sequence.",
                "C. Keys from the position immediately after the sequence are shifted left to overwrite the sequence, compacting the node and ensuring no gaps remain from the deleted key.",
                "D. Only the first slot of the sequence identified by `succ_>=` is updated by copying the key value from the slot immediately following it, and this new value is then propagated backward to any preceding gap positions within the node but not necessarily within the identified sequence.",
                "E. The bitmap for used slots is updated to mark all positions in the sequence as unused, while their key values (`k`) remain unchanged, relying on the gap-filling rule to be naturally re-established by future insertions."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Then, we find the range of all positions having 56 (i.e., [5,6]) and copy into them the next value (i.e., 67)."
            ],
            "img_path": "2505.01180/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01152",
        "img_path": "2505.01152/x2.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Vector Field Analysis and Computational Techniques",
                "B. Spectral Decomposition Methods in Complex Systems",
                "C. Polarization Decomposition and Its Applications",
                "D. Applications of Phase Modulation in Signal Processing",
                "E. Advanced Transformations in Electromagnetic Wave Theory"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Polarization Decomposition and Its Applications"
            ],
            "img_path": "2505.01152/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, following the transformation of the nominal `(6)S2` child node to `(3)P2` by process (IV-B) due to specific element sum equalities in the Fig. 6 example, what two-letter acronym representing a fundamental type of entropy merging is explicitly stated as required for the subsequent correct simplification of `(3)P2` towards `(1)`?",
            "options": [
                "A. SC",
                "B. PF",
                "C. RV",
                "D. EP",
                "E. PC"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "PC"
            ],
            "img_path": "2505.01152/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01237",
        "img_path": "2505.01237/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Andrew Rouditchenko",
                "B. Edson Araujo",
                "C. Yuan Gong",
                "D. Saurabhchand Bhati",
                "E. Samuel Thomas"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Edson Araujo"
            ],
            "img_path": "2505.01237/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct key challenges does the proposed CAV-MAE Sync framework explicitly address to improve upon previous audio-visual learning methods, and what are they?",
            "options": [
                "A. Two: granularity mismatch and conflicting optimization objectives",
                "B. Three: granularity mismatch, conflicting optimization objectives, and spatial localization",
                "C. Four: granularity mismatch, conflicting optimization objectives, spatial localization, and model complexity",
                "D. One: only granularity mismatch between modalities",
                "E. Five: granularity mismatch, conflicting optimization objectives, spatial localization, model size, and data augmentation"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Three: granularity mismatch, conflicting optimization objectives, and spatial localization"
            ],
            "img_path": "2505.01237/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01292",
        "img_path": "2505.01292/x2.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Robust Aggregation Techniques for Enhancing Local Differential Privacy in Data Streams",
                "B. Evaluating Coarse-grained Threat Models in Differential Privacy for Streaming Data",
                "C. Adaptive Protocols for Secure Data Sharing under Local Differential Privacy Constraints",
                "D. Optimization of Noise Mechanisms for Privacy Preservation in Real-time Data Streams",
                "E. Fine-grained Manipulation Attacks to Local Differential Privacy Protocols for Data Streams"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Fine-grained Manipulation Attacks to Local Differential Privacy Protocols for Data Streams"
            ],
            "img_path": "2505.01292/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, under the proposed unified attack framework for manipulating streaming LDP protocols, what specific sequence of module actions and successful LDP mechanism exploitations must occur, beginning with the Manipulation Strategy Determination (MSD), for the Publication Manipulation Attack (PMA) to be ultimately engaged to alter the estimated statistics?",
            "options": [
                "A. MSD first identifies the publication strategy as optimal for reducing the manipulation gap. Subsequently, the Dissimilarity Manipulation Attack (DMA) is engaged to manipulate the private dissimilarity (`dīs`) such that it becomes greater than the potential publication error (`err`), thereby successfully steering the LDP aggregator to select the publication strategy. Only upon this successful steering is PMA invoked to manipulate the released statistics.",
                "B. MSD determines the approximation strategy is more beneficial. DMA is then invoked to minimize `dīs`. If, however, the calculated `err` is exceptionally low, causing `dīs` to be greater than `err`, the LDP aggregator chooses publication, and PMA is then invoked because a publication occurred.",
                "C. The Publication Manipulation Attack (PMA) module is directly selected by MSD if the primary LDP analytic task involves frequency estimation for categorical data. DMA then attempts to ensure the LDP aggregator publishes by manipulating `dīs` to be less than or equal to `err`, using the budget `epsilon_t,2`.",
                "D. Following MSD's decision, DMA is always invoked to manipulate `dīs` using techniques similar to the Maximum Gain Attack (MGA). If DMA successfully steers the aggregator to publish (irrespective of MSD's initial strategic choice), PMA then minimizes the manipulation gap `G_t` by targeting `f_tilde_t`.",
                "E. MSD determines that publication is beneficial. PMA is then immediately invoked to manipulate `f_hat_t` towards `f_tilde_t`. DMA is subsequently invoked to ensure the private dissimilarity `dīs`, calculated using budget `epsilon_t,1`, aligns with the publication decision by attempting to make `dīs` equal to `err`."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "MSD first identifies the publication strategy as optimal for reducing the manipulation gap. Subsequently, the Dissimilarity Manipulation Attack (DMA) is engaged to manipulate the private dissimilarity (`dīs`) such that it becomes greater than the potential publication error (`err`), thereby successfully steering the LDP aggregator to select the publication strategy. Only upon this successful steering is PMA invoked to manipulate the released statistics."
            ],
            "img_path": "2505.01292/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01305",
        "img_path": "2505.01305/x2.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Hong-Pei Chen",
                "B. Lo Pang-Yun Ting",
                "C. An-Shan Liu",
                "D. Chun-Yin Yeh",
                "E. Po-Lin Chen"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Lo Pang-Yun Ting"
            ],
            "img_path": "2505.01305/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific criterion for assigning a deterioration label of 1 to a patient's heart rate time series `X`, and which performance aspect of TARL is most significantly impacted by an increase in the `omega` parameter, implying a disregard for relation proximity during embedding learning?",
            "options": [
                "A. Criterion: The patient's Apache II illness level at the end of the time series `X` is higher than at its beginning. Impact: Earliness of detection, as TARL struggles to accurately capture when a patient's condition is likely to change.",
                "B. Criterion: The patient receives a confirmed clinical diagnosis of deterioration during the monitoring period of `X`. Impact: F-score, because the shapelet-transition KG becomes insufficiently structured.",
                "C. Criterion: The Apache II score for `X` falls into the 'above 30' severity level without considering change. Impact: Reliability of detection, because the impact of missing values is not adequately quantified by the transition-aware knowledge embedding.",
                "D. Criterion: Key shapelets indicative of deterioration, such as `s5`, are identified with high probability within `X`. Impact: The F-score, due to the weakening of shapelet transition time interval reinforcement.",
                "E. Criterion: Linear interpolation fails to impute more than a certain percentage of missing values in `X`. Impact: Earliness of detection, because higher-dimensional embeddings are unable to preserve essential time interval information."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Criterion: The patient's Apache II illness level at the end of the time series `X` is higher than at its beginning. Impact: Earliness of detection, as TARL struggles to accurately capture when a patient's condition is likely to change."
            ],
            "img_path": "2505.01305/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01207",
        "img_path": "2505.01207/fig-architecture.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. P-Map: Improving Dense-view Depth Estimation via Probabilistic Mapping",
                "B. T-Graph: Enhancing Sparse-view Camera Pose Estimation by Pairwise Translation Graph",
                "C. GraphFusion: Integrating Multi-view Features for Robust Camera Orientation Recovery",
                "D. Sparse Feature Networks for Real-time 3D Reconstruction from Limited Views",
                "E. TransGraphNet: Leveraging Spatial Relations for Enhanced Visual Odometry"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "T-Graph: Enhancing Sparse-view Camera Pose Estimation by Pairwise Translation Graph"
            ],
            "img_path": "2505.01207/fig-architecture.png"
        },
        "level2_qa": {
            "question": "In this paper, considering that T-Graph functions exclusively as a training supervision module for enhancing baseline model feature learning and is omitted during inference, what is the maximum reported percentage improvement in camera center accuracy specifically attributed to this methodology within the evaluation range of 2 to 8 viewpoints?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 4",
                "D. 8",
                "E. 6"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "6"
            ],
            "img_path": "2505.01207/fig-architecture.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01308",
        "img_path": "2505.01308/x2.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Adaptive Control Strategies for Multi-DOF Robotic Manipulators",
                "B. Optimization Techniques in Force Feedback for Autonomous Robots",
                "C. Desired Impedance Allocation for Robotic Systems",
                "D. Dynamic Modeling and Stability Analysis of Robotic Actuators",
                "E. Sensor Fusion Methods for Enhanced Robotic Perception"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Desired Impedance Allocation for Robotic Systems"
            ],
            "img_path": "2505.01308/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the pivotal conceptual innovation that allows for the integration of desired inertia into the Virtual Decomposition Control framework, thereby overcoming its inherent limitation in allocating second-order behavior, while critically maintaining the framework's established modularity and leading to enhanced interaction with substantially stiffer environments?",
            "options": [
                "A. The direct application of the 10-dimensional unique inertial parameter vector (phi_A) within the control law to enforce physical consistency at each control cycle.",
                "B. The redefinition of required end-effector velocity, coupled with the introduction of a required acceleration and a pseudo-impedance term, enabling second-order impedance behavior.",
                "C. The development of a novel fifth-order trajectory generator that inherently computes the necessary inertial components for smooth acceleration and deceleration.",
                "D. The explicit modeling of contact forces using a virtual wall and the stiffness parameter K_e, which allows the controller to anticipate and compensate for inertial effects during contact.",
                "E. The utilization of a Riemannian manifold to define the set of physically consistent inertial parameters, which simplifies the mathematical complexity of second-order behavior allocation."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The redefinition of required end-effector velocity, coupled with the introduction of a required acceleration and a pseudo-impedance term, enabling second-order impedance behavior."
            ],
            "img_path": "2505.01308/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01258",
        "img_path": "2505.01258/x1.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. A Novel Deep Learning Approach for Deterministic Bilevel Optimization",
                "B. Adaptive Algorithms for Robust Convex Programming in Noisy Environments",
                "C. Scalable Methods for Multilevel Stochastic Variational Inequalities",
                "D. Convergence Analysis of Decentralized Optimization Techniques with Delay",
                "E. A Provably Convergent Plug-and-Play Framework for Stochastic Bilevel Optimization"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "A Provably Convergent Plug-and-Play Framework for Stochastic Bilevel Optimization"
            ],
            "img_path": "2505.01258/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the primary mechanism within the PnPBO's unified theoretical analysis that allows it to accommodate diverse stochastic estimators (including biased and unbiased types for the upper-level variable) while demonstrating that optimal sample complexity, comparable to single-level optimization, is achievable for bilevel problems?",
            "options": [
                "A. The exclusive reliance on unbiased stochastic estimators for both upper and lower-level variables, which simplifies variance control.",
                "B. The application of a novel moving average technique solely to biased estimators for the upper-level variable to ensure hypergradient accuracy.",
                "C. The construction of a sophisticated Lyapunov function that synergistically integrates the analyses of monotonic descent behaviors, approximation errors, and estimator-specific variance terms from preceding analytical steps.",
                "D. The decoupling of step size conditions for upper and lower-level updates, which independently optimizes each level's convergence rate irrespective of the estimator used.",
                "E. The demonstration that MSEBA, when integrated into PnPBO, inherently possesses properties that make all other stochastic estimators converge at optimal rates without further specific analysis."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The construction of a sophisticated Lyapunov function that synergistically integrates the analyses of monotonic descent behaviors, approximation errors, and estimator-specific variance terms from preceding analytical steps."
            ],
            "img_path": "2505.01258/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01288",
        "img_path": "2505.01288/x2.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Quantao Yang",
                "B. Xiaohao Xu",
                "C. Nima Fazeli",
                "D. Changhe Chen",
                "E. Olov Andersson"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Changhe Chen"
            ],
            "img_path": "2505.01288/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what single-word term best identifies the core learned entity that is first established through self-supervised generative modeling of semantic action flows from extensive human video data, and then refined with minimal robot demonstrations, ultimately embodying the transferable knowledge critical for ViSA-Flow's success in low-data robotic manipulation?",
            "options": [
                "A. Flow",
                "B. Model",
                "C. Prior",
                "D. ViSA-Flow",
                "E. Representation"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Prior"
            ],
            "img_path": "2505.01288/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01282",
        "img_path": "2505.01282/x1.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Analyzing Memory Management in Ethereum Smart Contracts",
                "B. Optimizing Gas Efficiency in Blockchain Programming",
                "C. Micro-Patterns in Solidity Code",
                "D. Design Patterns for Secure Smart Contract Development",
                "E. Automated Detection of Vulnerabilities in Solidity Code"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Micro-Patterns in Solidity Code"
            ],
            "img_path": "2505.01282/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, regarding the stated rationale for the organizational structure of the 18 identified micro-patterns, what precise quantity of primary smart contract development concerns are explicitly enumerated within the text as being reflected by the adopted categorization scheme?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 18"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.01282/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01298",
        "img_path": "2505.01298/protohalos_6x5.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Spinning masters: on the impact of tidal forces and protohalo size on early spin evolution",
                "B. Angular Momentum Transfer in Galaxy Formation: Effects of Dark Matter Distribution and Halo Density",
                "C. The Role of Gravitational Interactions in Shaping Dark Matter Halo Morphology",
                "D. Early Spin Dynamics of Protohalos Influenced by Cosmic Web Filamentary Structures",
                "E. Investigating the Correlation Between Halo Mass Accretion Rates and Angular Momentum Evolution"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Spinning masters: on the impact of tidal forces and protohalo size on early spin evolution"
            ],
            "img_path": "2505.01298/protohalos_6x5.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement most comprehensively describes the resolution offered for the ambiguity in Tidal Torque Theory's coupling scale, the method of its determination at high redshift, and the consequential understanding of early deviations from TTT predictions?",
            "options": [
                "A. The paper determines that the tidal field couples with protohalo inertia tensors on scales approximately half their characteristic size, identified by analyzing different smoothing lengths at z=80, which explains why discrepancies from TTT predictions manifest systematically before the non-linear regime due to interactions with the forming cosmic web.",
                "B. By confirming R_lag, defined using M_FoF, as the universally optimal smoothing scale for all redshifts, the paper demonstrates that TTT predictions align perfectly with simulations up to the quasi-linear regime, thereby resolving the coupling scale ambiguity primarily through consistent mass-dependent protohalo sizing.",
                "C. The study primarily utilizes the NEXUS+ algorithm at z=0 to retrospectively define protohalo boundaries and tidal field characteristics at z=80, thereby identifying a precise coupling scale that eliminates all previously observed early TTT discrepancies.",
                "D. The paper concludes that the ambiguity in TTT's coupling scale is an inherent feature of early structure formation and cannot be resolved by current smoothing techniques, primarily demonstrating that discrepancies arise from the poorly defined eigenvalues of the tidal tensor in Lagrangian space.",
                "E. The research establishes that smoothing tidal fields precisely at the full characteristic Lagrangian radius (R_lag) of protohalos ensures Tidal Torque Theory's validity throughout the linear and quasi-linear regimes, attributing any observed discrepancies solely to environmental effects identified by NEXUS+ at later times."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The paper determines that the tidal field couples with protohalo inertia tensors on scales approximately half their characteristic size, identified by analyzing different smoothing lengths at z=80, which explains why discrepancies from TTT predictions manifest systematically before the non-linear regime due to interactions with the forming cosmic web."
            ],
            "img_path": "2505.01298/protohalos_6x5.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01399",
        "img_path": "2505.01399/x2.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Adaptive Manipulation Strategies for Autonomous Robots Using Multimodal Sensors",
                "B. Integrating Natural Language Processing with Robotic Grasping Systems",
                "C. Dynamic Robot Tool Use with Vision Language Models",
                "D. Vision-Guided Task Planning in Collaborative Human-Robot Environments",
                "E. Leveraging Deep Learning for Real-Time Object Recognition in Robotics"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Dynamic Robot Tool Use with Vision Language Models"
            ],
            "img_path": "2505.01399/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, reflecting on iTUP's capacity to handle quasi-static, dynamic, and cluster tool-use tasks through its VLM-driven integrated pipeline that reasons over semantic affordances and physical constraints, what single word is explicitly used in the text to describe this demonstrated breadth of capability?",
            "options": [
                "A. Stability",
                "B. Grounding",
                "C. Versatility",
                "D. Robustness",
                "E. Cognition"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Versatility"
            ],
            "img_path": "2505.01399/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01366",
        "img_path": "2505.01366/framework.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. A Reinforcement Learning Framework for Adaptive Control of Renewable Microgrids",
                "B. Fault Detection in Distributed Energy Systems Using Convolutional Neural Networks",
                "C. Deep Learning-Enabled System Diagnosis in Microgrids: A Feature-Feedback GAN Approach",
                "D. Multi-Agent Optimization Techniques for Energy Management in Smart Microgrids",
                "E. Enhanced Signal Processing Methods for Real-Time Monitoring of Grid-Connected Inverters"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Deep Learning-Enabled System Diagnosis in Microgrids: A Feature-Feedback GAN Approach"
            ],
            "img_path": "2505.01366/framework.png"
        },
        "level2_qa": {
            "question": "In this paper, by compelling the F2GAN's generator to synthesize data that preserves underlying system characteristics through a feature matching loss strategy—thereby enabling the discriminator to learn a richer feature space of normal and fault signatures—what is the most critical implied consequence for the operational efficacy of the entire two-stage diagnostic framework when faced with FDI attacks specifically designed to mimic genuine internal fault scenarios?",
            "options": [
                "A. The framework achieves a more reliable initial segregation in Stage 1, ensuring that data indicative of such mimicked FDI attacks are correctly identified as cyber-induced anomalies and *not* subsequently processed by Stage 2 for fault localization, thus preventing misattribution of cyber attacks as specific physical inverter switch faults.",
                "B. The feature matching loss directly enhances the supervised learning models in Stage 2, allowing them to more accurately classify the *type* of FDI attack (e.g., distinguishing between different FDI attack vectors) once an anomaly is detected by F2GAN.",
                "C. The richer feature space learned by the F2GAN's discriminator primarily improves the framework's ability to detect and adapt to zero-day attacks, while its effectiveness against FDI attacks mimicking known fault signatures remains comparable to conventional GANs.",
                "D. The primary consequence is the reduction in computational overhead for Stage 2, as the F2GAN's enhanced discriminator filters out most normal operational data more efficiently, allowing Stage 2 to focus solely on complex fault signatures passed from Stage 1.",
                "E. The framework's overall resilience is improved because the feature matching loss ensures that even if an FDI attack successfully bypasses Stage 1 by mimicking a real fault, Stage 2 models are robust enough to identify it as a cyber anomaly rather than a physical fault due to a shared, enriched feature space."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "it is flagged as a cyber-induced anomaly. The real fault samples are then passed to Stage 2"
            ],
            "img_path": "2505.01366/framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01352",
        "img_path": "2505.01352/fig1.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Arghadeep Pal",
                "B. Alekhya Ghosh",
                "C. Shuangyou Zhang",
                "D. Toby Bi",
                "E. Masoud Kheyri"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Arghadeep Pal"
            ],
            "img_path": "2505.01352/fig1.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific on-chip optical power threshold, in milliwatts, must be exceeded for the nondegenerate Four-Wave Mixing process to initiate the generation of sidebands around the pump, Stokes, and anti-Stokes lines, ultimately contributing to broadband comb spectra?",
            "options": [
                "A. 1",
                "B. 143",
                "C. 150",
                "D. 11",
                "E. 241"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "150"
            ],
            "img_path": "2505.01352/fig1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01469",
        "img_path": "2505.01469/x3.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Evaluating Machine Learning Models for Bug Report Prioritization: A Comparative Analysis",
                "B. Automatic techniques for issue report classification: A systematic mapping study",
                "C. Towards Enhanced Feature Extraction Methods in Software Defect Prediction",
                "D. A Survey on Natural Language Processing Applications in Software Maintenance",
                "E. Empirical Study of Developer Communication Patterns in Issue Tracking Systems"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Automatic techniques for issue report classification: A systematic mapping study"
            ],
            "img_path": "2505.01469/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the numerical sum derived from adding the count of studies that specifically employed RoBERTa as a classification model to the count of studies that specifically employed RoBERTa-based tokenizers for pre-processing?",
            "options": [
                "A. 5",
                "B. 4",
                "C. 9",
                "D. 11",
                "E. 12"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "9"
            ],
            "img_path": "2505.01469/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01485",
        "img_path": "2505.01485/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. HARMONY: Multi-stage Neural Parsing for Constraint Satisfaction Problems",
                "B. CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code",
                "C. SYNTHESYS: Automated Generation of Optimization Models from Natural Language Instructions",
                "D. ORCHESTRA: Adaptive Framework for Solving Nonlinear Programming via Modular Components",
                "E. CONDUCT: Deep Learning Approaches for Structured Code Synthesis in Mathematical Programming"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code"
            ],
            "img_path": "2505.01485/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of parameters, in billions, of the two open-source LLMs with the fewest parameters explicitly listed by model name and size that CHORUS was tested on?",
            "options": [
                "A. 8",
                "B. 14",
                "C. 22",
                "D. 40",
                "E. 46"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "22"
            ],
            "img_path": "2505.01485/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01446",
        "img_path": "2505.01446/advanced1.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Deep Reinforcement Learning Approaches for Autonomous Vehicle Path Planning",
                "B. Sensor Fusion Techniques in Autonomous Driving Systems Using RNN and GAN",
                "C. Traffic Pattern Prediction for Self-Driving Cars with Support Vector Machines",
                "D. Real-Time Object Detection and Classification in Driverless Vehicles with Transformer Models",
                "E. Waymo Driverless Car Data Analysis and Driving Modeling using CNN and LSTM"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Waymo Driverless Car Data Analysis and Driving Modeling using CNN and LSTM"
            ],
            "img_path": "2505.01446/advanced1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the developmental trajectory leading to the 'Advanced Model', what is the specific quantity of distinct prior model architectures or foundational architectural strategies that are explicitly detailed as having been implemented or individually trialed for the task of acceleration prediction?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 11"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.01446/advanced1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01433",
        "img_path": "2505.01433/x1.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Evaluating Molecular Docking Techniques for TCR and Peptide Binding Affinity",
                "B. Integrating Graph Neural Networks for Antigen Recognition in T Cell Receptors",
                "C. Deep Learning Approaches to Predicting Immune Response Based on TCR Sequences",
                "D. Enhancing TCR-Peptide Interaction Prediction with Pretrained Language Models and Molecular Representations",
                "E. Comparative Analysis of Structural Features Influencing TCR Specificity"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Enhancing TCR-Peptide Interaction Prediction with Pretrained Language Models and Molecular Representations"
            ],
            "img_path": "2505.01433/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the reported AUC-ROC score for LANTERN when evaluated on a generated negative dataset utilizing the random control approach, a method noted for its inherent variability and the challenges it introduces?",
            "options": [
                "A. 0.88",
                "B. 0.901",
                "C. 0.57",
                "D. 0.66",
                "E. 0.90"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "0.66"
            ],
            "img_path": "2505.01433/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02012",
        "img_path": "2505.02012/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Evaluating Query Optimization Using Synthesized Code Snippets from Large Language Models",
                "B. Enhancing Database Security through Language Model Generated Test Cases",
                "C. Testing Database Systems with Large Language Model Synthesized Fragments",
                "D. Performance Analysis of Distributed Databases Using AI-Synthesized Workloads",
                "E. Automated Schema Validation with Neural Network Generated Data Fragments"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Testing Database Systems with Large Language Model Synthesized Fragments"
            ],
            "img_path": "2505.02012/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, navigating the complexities of LLM-driven code synthesis—including their propensity for hallucination (mitigated by ShQveL's self-validation) and schema unawareness (addressed by providing schema information)—and considering ShQveL's overarching goal to enhance SQL feature coverage in test-case generation, what singular integer value quantifies the net discovery of unique, previously unrecorded defects across the entire suite of database systems upon which ShQveL's efficacy was evaluated?",
            "options": [
                "A. 50",
                "B. 5",
                "C. 17",
                "D. 55",
                "E. 200"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "55"
            ],
            "img_path": "2505.02012/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01466",
        "img_path": "2505.01466/breakloopsflow2.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. LoopPatterns: Enhancing Single-Gene Cancer Risk Prediction with Fam3Pro Extensions",
                "B. BreakLoops: A New Feature for the Multi-Gene, Multi-Cancer Family History-Based Model, Fam3Pro",
                "C. Fam3ProX: Integrating Epigenetic Markers into Multi-Cancer Family History Models",
                "D. GeneCascade: A Novel Approach to Multi-Cancer Susceptibility Using Familial Data",
                "E. MultiGeneHist: Evaluating Environmental and Genetic Factors in Cancer Family History Models"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "BreakLoops: A New Feature for the Multi-Gene, Multi-Cancer Family History-Based Model, Fam3Pro"
            ],
            "img_path": "2505.01466/breakloopsflow2.png"
        },
        "level2_qa": {
            "question": "In this paper, what critical characteristic related to familial relationships within a loop, following initial pedigree data optimization for computational efficiency, permits the `breakloops` algorithm to employ a method like Prim's algorithm, thereby guaranteeing the selection of an optimal set of loop breakers to minimize subsequent computational burden?",
            "options": [
                "A. The prior isolation of all family units into distinct subfamilies and the removal of any individuals not connected to a proband.",
                "B. The successful conversion of the entire pedigree data structure into a fully connected and undirected graph format.",
                "C. The presence of individuals within a loop who have participated in two or more matings as a parent, triggering a specialized greedy algorithm.",
                "D. Every individual involved in a loop has exactly one mating where they are a parent.",
                "E. The strategic limitation of cloning each identified loop breaker only a single time to disrupt cyclical inheritance patterns."
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Every individual involved in a loop has exactly one mating where they are a parent."
            ],
            "img_path": "2505.01466/breakloopsflow2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02015",
        "img_path": "2505.02015/x1.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Model-Driven Testing Approaches: An Analytical Review",
                "B. Requirements-Based Test Generation: A Comprehensive Survey",
                "C. Automated Test Case Design for Software Verification: Techniques and Trends",
                "D. Scenario-Based Software Testing: Methods and Applications",
                "E. A Survey on Traceability in Software Testing Processes"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Requirements-Based Test Generation: A Comprehensive Survey"
            ],
            "img_path": "2505.02015/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the systematic literature review methodology discussed, in which specific year was the seminal Kitchenham et al. reference—establishing the SLR process adopted in this study—published, and how does this year compare to the year cited for Wohlin's snowballing technique within the context of the literature search expansion?",
            "options": [
                "A. 2009, which is five years earlier than the year referenced for Wohlin's snowballing technique",
                "B. 2014, which is the same year as Wohlin's snowballing technique",
                "C. 2009, which is five years later than the year referenced for Wohlin's snowballing technique",
                "D. 2014, which is five years earlier than the year referenced for Kitchenham et al.",
                "E. 1994, which is the same year requirements-based test generation was introduced"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "2009, which is five years earlier than the year referenced for Wohlin's snowballing technique"
            ],
            "img_path": "2505.02015/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01414",
        "img_path": "2505.01414/x4.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Estimating Electron Density in Plasma via Spectral Line Analysis and Machine Learning",
                "B. Machine Learning Approaches for Classifying Plasma Emission Spectra",
                "C. Modeling Ionization Levels in Plasma Using Spectral Intensity Data",
                "D. Predicting Plasma Confinement Parameters Through Spectroscopic Feature Extraction",
                "E. Predicting Plasma Temperature From Line Intensities Using ML Models"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Predicting Plasma Temperature From Line Intensities Using ML Models"
            ],
            "img_path": "2505.01414/x4.png"
        },
        "level2_qa": {
            "question": "In this paper, by synthesizing the performance comparisons across all enumerated machine learning model categories—specifically regression, tree-based, and deep learning—how many distinct model types are explicitly stated or directly inferable to exhibit higher error (in terms of MAE/RMSE) than the general category of tree-based models?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 5",
                "D. 7",
                "E. 8"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "5"
            ],
            "img_path": "2505.01414/x4.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01380",
        "img_path": "2505.01380/x4.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Shuli Lv",
                "B. Chen Min",
                "C. Zhaolong Shen",
                "D. Pengda Mao",
                "E. Quan Quan"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Pengda Mao"
            ],
            "img_path": "2505.01380/x4.png"
        },
        "level2_qa": {
            "question": "In this paper, a single sentence, describe the context we give you.",
            "options": [
                "A. Swarm navigation fundamentally relies on each robot independently generating reactive paths based on its local sensors, with Robot0 providing only occasional, high-level directional updates, not a detailed shared tube.",
                "B. Robot0 computes a single, globally optimal virtual tube that is guaranteed safe for its entire length to the goal, which all robots then follow precisely using affine functions, eliminating the need for replanning or reactive obstacle avoidance.",
                "C. Every robot in the swarm autonomously executes long-horizon planning using Tube-RRT* to create its own virtual tube and then applies affine functions for its trajectory, making the system fully decentralized and computationally shared.",
                "D. The primary innovation is the continuous, real-time adaptation of the entire shared virtual tube by Robot0 based on aggregated sensor data from all swarm members, ensuring the tube always reflects the most current understanding of the complete environment up to the goal.",
                "E. The paper's core strategy involves Robot0 performing centralized, computationally efficient long-horizon optimal virtual tube planning to the goal (using approximate solutions), while individual swarm members derive their specific trajectories from this shared tube via affine functions, navigate within a 'committed' safe segment, and utilize distributed reactive control for local collision avoidance, with the system replanning the tube as robots progress beyond the committed zone."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "The paper's core strategy involves Robot0 performing centralized, computationally efficient long-horizon optimal virtual tube planning to the goal (using approximate solutions), while individual swarm members derive their specific trajectories from this shared tube via affine functions, navigate within a 'committed' safe segment, and utilize distributed reactive control for local collision avoidance, with the system replanning the tube as robots progress beyond the committed zone."
            ],
            "img_path": "2505.01380/x4.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01319",
        "img_path": "2505.01319/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Model See Model Do: Speech-Driven Facial Animation with Style Control",
                "B. Neural Techniques for Real-Time Speech Synthesis and Lip Movement Prediction",
                "C. Style-Adaptive Facial Expression Generation from Audio Signals",
                "D. Cross-Modal Learning for Emotion Recognition in Speech-Driven Avatars",
                "E. Temporal Dynamics of Speech and Facial Animation in Conversational Agents"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Model See Model Do: Speech-Driven Facial Animation with Style Control"
            ],
            "img_path": "2505.01319/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, a single number, show the research data: The count of distinct scenarios the window-based training approach for the network is explicitly designed to address.",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. Nw",
                "E. 2Nw"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2505.01319/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01447",
        "img_path": "2505.01447/framework.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Optimization of Renewable Energy Integration in EV Charging Networks",
                "B. LLM-Enabled EV Charging Stations Recommendation",
                "C. User Behavior Analysis in Smart Electric Vehicle Charging Systems",
                "D. Predictive Maintenance Models for EV Charging Infrastructure",
                "E. Blockchain-Based Security Framework for Electric Vehicle Charging Stations"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "LLM-Enabled EV Charging Stations Recommendation"
            ],
            "img_path": "2505.01447/framework.png"
        },
        "level2_qa": {
            "question": "In this paper, considering RecomBot's fundamental approach of utilizing natural language processing for user queries and integrating real-time, diverse data sources to transcend the 'fixed constraints' typical of conventional AI systems, which single word from its explicitly stated 'validated outcomes' resulting from testing MOST accurately characterizes its demonstrated success in managing the inherently 'dynamic and multifaceted nature' of optimal EV charging station selection?",
            "options": [
                "A. Capability",
                "B. Efficiency",
                "C. Scalability",
                "D. Personalization",
                "E. Optimization"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Capability"
            ],
            "img_path": "2505.01447/framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01184",
        "img_path": "2505.01184/x5.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Scalable Quantum Error Mitigation Techniques for Noisy Intermediate-Scale Quantum Devices",
                "B. Optimizing Classical-Quantum Data Exchange in Hybrid Computational Architectures",
                "C. Modular Design of Quantum Algorithms for Enhanced Parallel Processing",
                "D. Resource-Efficient Quantum Simulation Methods in High-Performance Computing Environments",
                "E. Distributed Quantum Circuit Cutting for Hybrid Quantum-Classical High-Performance Computing"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Distributed Quantum Circuit Cutting for Hybrid Quantum-Classical High-Performance Computing"
            ],
            "img_path": "2505.01184/x5.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the gate-cutting technique applied to a Controlled-Z (CZ) gate, what specific numerical value forms the base of the exponential relationship describing how the total number of generated circuits scales with 'k' gate cuts?",
            "options": [
                "A. 2",
                "B. 4",
                "C. 6",
                "D. k",
                "E. 156"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "6"
            ],
            "img_path": "2505.01184/x5.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01454",
        "img_path": "2505.01454/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Robust Aggregation Techniques for Secure Federated Learning in Adversarial Environments",
                "B. Optimizing Communication Overhead in Federated Learning with Adaptive Model Pruning",
                "C. Sparsification Under Siege: Defending Against Poisoning Attacks in Communication-Efficient Federated Learning",
                "D. Mitigating Data Poisoning Effects through Gradient Compression in Distributed Machine Learning",
                "E. Enhancing Privacy and Efficiency in Federated Learning via Dynamic Sparsity Control"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Sparsification Under Siege: Defending Against Poisoning Attacks in Communication-Efficient Federated Learning"
            ],
            "img_path": "2505.01454/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering FLARE's two-pronged defense (sparse index mask inspection and model update sign similarity analysis) is specifically engineered to detect falsified model parameters intended for untargeted global model degradation within sparsified FL, which of the following adversarial goals, even if pursued in a sparsified context, inherently targets a vulnerability that these specific defensive mechanisms are not designed to identify or mitigate, aligning with the paper's stated operational boundaries?",
            "options": [
                "A. An adversary aiming to introduce a backdoor into the global model via sparse updates that, while malicious, maintain high Jaccard similarity in their index masks and cosine similarity in parameter signs with a subgroup of benign clients, causing misclassification only for specific, rare inputs.",
                "B. Adversarial clients subtly manipulating their local data such that their sparsified updates, while individually appearing benign in terms of mask and sign distribution, collectively poison the global model towards diffuse, untargeted performance loss across most data samples.",
                "C. An attacker leveraging the metadata of sparsified communications (e.g., patterns of selected indices in sparse index masks over time from a particular client) to infer properties of that client's local dataset, without necessarily altering the parameters to cause model degradation.",
                "D. A rogue client submitting sparse updates with randomly generated index masks and parameter values, leading to chaotic and unpredictable global model behavior.",
                "E. Colluding attackers coordinating to submit sparse updates where the parameter values are significantly scaled up versions of benign updates but share similar sparse index masks, aiming to disproportionately influence the global model and degrade its stability."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "It is important to note that privacy leakage threats, such as those caused by privacy inference attacks or gradient leakage attacks, are beyond the scope of this paper."
            ],
            "img_path": "2505.01454/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01413",
        "img_path": "2505.01413/projection.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Maurice Koch",
                "B. Tobias Rau",
                "C. Vladimir Mikheev",
                "D. Seyda Öney",
                "E. Michael Becher"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Maurice Koch"
            ],
            "img_path": "2505.01413/projection.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the reported indicative accuracy results derived from a small sample size, what numerical value represents the maximum mean error, in pixels, for the perspective that exhibited comparatively greater inaccuracy, a phenomenon attributed to inconsistencies in marker detection affecting perspective mapping fidelity?",
            "options": [
                "A. 149",
                "B. 150",
                "C. 106",
                "D. 20",
                "E. 87"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "150"
            ],
            "img_path": "2505.01413/projection.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01440",
        "img_path": "2505.01440/x3.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Adaptive Multi-Agent Deep Reinforcement Learning for Collaborative Autonomous Navigation",
                "B. Hierarchical Reinforcement Learning with Contextual Feedback for Real-Time Vehicle Control",
                "C. Interactive Double Deep Q-network: Integrating Human Interventions and Evaluative Predictions in Reinforcement Learning of Autonomous Driving",
                "D. A Comparative Study of Model-Free and Model-Based Approaches in Autonomous Driving Systems",
                "E. Deep Policy Gradient Methods Incorporating Sensor Fusion for Urban Traffic Management"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Interactive Double Deep Q-network: Integrating Human Interventions and Evaluative Predictions in Reinforcement Learning of Autonomous Driving"
            ],
            "img_path": "2505.01440/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, to comprehensively validate the Human-in-the-Loop (HITL) strategy's effectiveness, distinct from iDDQN's direct performance metrics, what specific numerical value represents the Evaluation Prediction Module's (EPM) success rate in agreeing with scenarios where human interventions were associated with an increase in cumulative rewards over predicted agent-only actions?",
            "options": [
                "A. 5.8",
                "B. 2",
                "C. 3",
                "D. 94.2",
                "E. 4"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "94.2"
            ],
            "img_path": "2505.01440/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01415",
        "img_path": "2505.01415/Picture2.jpeg",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Comparative Analysis of Machine Learning Techniques for Rainfall Prediction in Tropical Wetlands",
                "B. Evaluating the Impact of Climate Change on Wetland Soil Moisture Dynamics Using Statistical Models",
                "C. Optimizing Sensor Networks for Real-Time Flood Monitoring in Coastal Ecosystems",
                "D. Assessing the Role of Remote Sensing Data in Modeling Evapotranspiration Patterns in Subtropical Marshes",
                "E. How Effective are Large Time Series Models in Hydrology? A Study on Water Level Forecasting in Everglades"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "How Effective are Large Time Series Models in Hydrology? A Study on Water Level Forecasting in Everglades"
            ],
            "img_path": "2505.01415/Picture2.jpeg"
        },
        "level2_qa": {
            "question": "In this paper, what is the numerical difference between the total count of variables established in the dataset after the selection process and the total count of investigated time series forecasting models (encompassing both task-specific and all foundation types) that were reported as being outperformed by Chronos?",
            "options": [
                "A. 20",
                "B. 21",
                "C. 25",
                "D. 32",
                "E. 33"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "21"
            ],
            "img_path": "2505.01415/Picture2.jpeg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01383",
        "img_path": "2505.01383/system.jpg",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Yan Miao",
                "B. Ji Chen",
                "C. Will Shen",
                "D. Hang Cui",
                "E. Sayan Mitra"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Yan Miao"
            ],
            "img_path": "2505.01383/system.jpg"
        },
        "level2_qa": {
            "question": "In this paper, what is the acronym for the 3D scene reconstruction technique, noted for faster and improved rendering capabilities over Neural Radiance Fields, that forms the core of the enhanced FalconGym simulation environment used to train the FalconWing's vision-based landing policy?",
            "options": [
                "A. COLMAP",
                "B. NeRF",
                "C. GSplat",
                "D. ViT",
                "E. ESC"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "GSplat"
            ],
            "img_path": "2505.01383/system.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01420",
        "img_path": "2505.01420/x1.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Roland S. Zimmermann",
                "B. Ziyue Wang",
                "C. David Lindner",
                "D. Victoria Krakovna",
                "E. Mary Phuong"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Mary Phuong"
            ],
            "img_path": "2505.01420/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the performance of the most capable frontier models evaluated, what is the aggregate count of proposed evaluation challenges across both stealth and situational awareness categories that these models did *not* successfully complete?",
            "options": [
                "A. 5",
                "B. 16",
                "C. 8",
                "D. 3",
                "E. 11"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "11"
            ],
            "img_path": "2505.01420/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01430",
        "img_path": "2505.01430/Flag_analysis.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Analyzing Algorithmic Fairness: Evaluating Performance Variations in Multimodal Generative Systems",
                "B. Towards Inclusive AI: Frameworks for Addressing Dataset Imbalances in Visual Language Models",
                "C. Characterizing Representation Distortions in Visual Synthesis: Methods for Measuring Diversity and Equity",
                "D. Quantifying Demographic Disparities in Image Generation: A Study of Cultural Influence on AI Outputs",
                "E. Deconstructing Bias: A Multifaceted Framework for Diagnosing Cultural and Compositional Inequities in Text-to-Image Generative Models"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Deconstructing Bias: A Multifaceted Framework for Diagnosing Cultural and Compositional Inequities in Text-to-Image Generative Models"
            ],
            "img_path": "2505.01430/Flag_analysis.png"
        },
        "level2_qa": {
            "question": "In this paper, what percentage signifies the contribution of embedding superposition, a consequence of latent space compression, to the occurrence of cultural conflation errors identified during the benchmarking of text-to-image models?",
            "options": [
                "A. 30",
                "B. 33",
                "C. 44",
                "D. 72",
                "E. 100"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "72"
            ],
            "img_path": "2505.01430/Flag_analysis.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01435",
        "img_path": "2505.01435/x2.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. AdaParse: An Adaptive Parallel PDF Parsing and Resource Scaling Engine",
                "B. Adaptive Streaming Techniques for Large-Scale Document Rendering",
                "C. Parallel Algorithms for Efficient XML Data Processing in Distributed Systems",
                "D. Resource Management Strategies for Scalable Web Content Analysis",
                "E. Dynamic Load Balancing in Multi-threaded Text Extraction Frameworks"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "AdaParse: An Adaptive Parallel PDF Parsing and Resource Scaling Engine"
            ],
            "img_path": "2505.01435/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the approximate ratio of PyMuPDF's stated throughput advantage over Nougat to AdaParse's stated overall throughput improvement when compared against state-of-the-art parsers?",
            "options": [
                "A. 0.13",
                "B. 17.00",
                "C. 10.38",
                "D. 7.94",
                "E. 135.00"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "7.94"
            ],
            "img_path": "2505.01435/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01475",
        "img_path": "2505.01475/x1.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Neural Graph Networks for Code Summarization",
                "B. BiGSCoder: State Space Model for Code Understanding",
                "C. Deep Learning Approaches to Software Vulnerability Detection",
                "D. Transformer-Based Models for Automated Code Generation",
                "E. Probabilistic Models in Program Analysis and Verification"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "BiGSCoder: State Space Model for Code Understanding"
            ],
            "img_path": "2505.01475/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence best synthesizes the configuration of the BiGSCoder-SC model concerning positional embeddings and dropout mechanisms, by integrating its specific training context (300k samples from 6 programming languages) with generalized statements about BiGSCoder variants?",
            "options": [
                "A. BiGSCoder-SC, being a 12-layer model trained on 300k samples, inherently includes positional embeddings as per the original BiGS design and incorporates the two specific dropout masks from the BiGSCoder-dropout variant for enhanced stability.",
                "B. The BiGSCoder-SC model, trained with 300k samples from 6 programming languages, operates without positional embeddings as is typical for BiGSCoder variants (excluding BiGSCoder-pos) and also lacks the specific dual dropout masks that are uniquely investigated in the BiGSCoder-dropout variant.",
                "C. To optimize for its 300k sample dataset (6 PLs), BiGSCoder-SC utilizes the positional embeddings stated as initially retained in BiGS but is distinct from BiGSCoder-dropout by not employing any of the specialized dropout configurations.",
                "D. BiGSCoder-SC, despite its 12-layer architecture and specific 300k/6PLs training data, is explicitly defined in the study as a variant that includes both positional embeddings (like BiGSCoder-pos) and the specialized dropout configuration (like BiGSCoder-dropout) to maximize code understanding.",
                "E. Reflecting findings that SSMs perform better without positional embeddings, BiGSCoder-SC (trained on 300k samples from 6 PLs) dispenses with them; however, it adopts the standard transformer-like multiple dropout layers throughout its BiGS layers, differing from the targeted approach of BiGSCoder-dropout."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The BiGSCoder-SC model, trained with 300k samples from 6 programming languages, operates without positional embeddings as is typical for BiGSCoder variants (excluding BiGSCoder-pos) and also lacks the specific dual dropout masks that are uniquely investigated in the BiGSCoder-dropout variant."
            ],
            "img_path": "2505.01475/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01453",
        "img_path": "2505.01453/MARL-HSS_Architecture.jpg",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Jinu Jayachandran",
                "B. Bharathkumar Hegde",
                "C. Yapei Chang",
                "D. M.S. Bieker",
                "E. Melanie Bouroche"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Bharathkumar Hegde"
            ],
            "img_path": "2505.01453/MARL-HSS_Architecture.jpg"
        },
        "level2_qa": {
            "question": "In this paper, describe the fundamental safety-critical check, governed by the Hybrid Safety Shield's lateral constraint mechanism, that must be satisfied for a MARL-initiated lane change to be allowed to start.",
            "options": [
                "A. The CAV's current velocity and acceleration must be within its predefined physical operational limits, ensuring the manoeuvre is physically executable.",
                "B. The longitudinal control barrier functions must confirm that continued travel in the current lane will remain safe for a predefined time headway, irrespective of target lane conditions.",
                "C. The optimisation-based component of HSS must calculate a safe longitudinal acceleration `asafe` that overrides any unsafe input from the motion planning layer before the manoeuvre begins.",
                "D. The rule-based system must ensure that sufficient lateral clearance exists in the target lane and that the steering input `ψsafe` can guide the vehicle safely into it if the manoeuvre proceeds.",
                "E. Longitudinal safety constraints, ensuring safe time headways, must be maintained with respect to both the leading and following vehicles anticipated in the target lane."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "The lateral safety constraints ensure that the lane change is initiated only when longitudinal safety constraints are maintained with both the leading and following vehicles in the target lane."
            ],
            "img_path": "2505.01453/MARL-HSS_Architecture.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01428",
        "img_path": "2505.01428/x3.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Adaptive Attention Mechanisms in Single-User Image Editing",
                "B. Multi-party Collaborative Attention Control for Image Customization",
                "C. Decentralized Feature Integration for Collaborative Visual Design",
                "D. Optimization Strategies for Multi-Modal Image Processing Systems",
                "E. Enhancing User Interaction through Dynamic Visual Customization Models"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Multi-party Collaborative Attention Control for Image Customization"
            ],
            "img_path": "2505.01428/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the minimum number of parallel diffusion processes required by the proposed MCA-Ctrl method to enable high-quality image customization that addresses both subject leakage and background inconsistency, and how does this compare to the number of separate applications typically handled by prior methods such as TIGIC and PHOTOSWAP?",
            "options": [
                "A. Three parallel diffusion processes, whereas prior methods handle only one application each",
                "B. Two parallel diffusion processes, matching the number of applications in prior methods",
                "C. Four parallel diffusion processes, which is twice as many as prior methods",
                "D. One parallel diffusion process, similar to prior single-task methods",
                "E. Five parallel diffusion processes, significantly more than prior approaches"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Three parallel diffusion processes, whereas prior methods handle only one application each"
            ],
            "img_path": "2505.01428/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01459",
        "img_path": "2505.01459/x2.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. MoxE: Mixture of xLSTM Experts with Entropy-Aware Routing for Efficient Language Modeling",
                "B. AdapNet: Adaptive Neural Routing with Confidence-Weighted Layers for Scalable Text Generation",
                "C. Entropy-Guided Transformer Ensembles for Robust Language Understanding",
                "D. Hybrid LSTM Architectures with Dynamic Expert Selection for Contextual Sequence Prediction",
                "E. Efficient Sequence Modeling via Attention-Based Mixture of Recurrent Experts"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "MoxE: Mixture of xLSTM Experts with Entropy-Aware Routing for Efficient Language Modeling"
            ],
            "img_path": "2505.01459/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, regarding the scalar value `d_t` computed by the difficulty module `D` to represent router uncertainty for each token, what is the maximum numerical value this scalar can assume according to its explicit definition as the output of a linear projection function?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 0.5",
                "E. 4"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2505.01459/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01445",
        "img_path": "2505.01445/Figure1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Deep Learning Approaches for Predicting Defects in Injection Moulding Processes",
                "B. Optimizing Production Efficiency Through AI-Driven Quality Assessment in Manufacturing",
                "C. Hybrid Machine Learning Models for Anomaly Detection in Plastic Injection Systems",
                "D. Explainable AI for Correct Root Cause Analysis of Product Quality in Injection Moulding",
                "E. Data-Driven Techniques for Enhancing Product Durability in Injection Moulding"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Explainable AI for Correct Root Cause Analysis of Product Quality in Injection Moulding"
            ],
            "img_path": "2505.01445/Figure1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the critical performance threshold, expressed as a percentage for the mean absolute percentage error (MAPE) on the experimental dataset, that Random Forest and Multilayer Perceptron models had to be *under* to be considered suitable for the core investigation involving the comparative analysis of model-agnostic explainability methods?",
            "options": [
                "A. 0.10%",
                "B. 0.30%",
                "C. 0.05%",
                "D. 1.00%",
                "E. 0.005%"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "0.05%"
            ],
            "img_path": "2505.01445/Figure1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02049",
        "img_path": "2505.02049/x3.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Junaid Bajwa",
                "B. Sier Ha",
                "C. Honghao Du",
                "D. Xianjia Yu",
                "E. Tomi Westerlund"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Sier Ha"
            ],
            "img_path": "2505.02049/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the variety of evaluation environments detailed to ensure comprehensive testing of the proposed odometry framework, what specific numerical figure, presented in meters, defines the operational range constraint encountered during data acquisition for the outdoor dataset uniquely characterized by its limited traversal scope due to experimental apparatus restrictions?",
            "options": [
                "A. 360",
                "B. 12",
                "C. 4",
                "D. 30",
                "E. 45"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "12"
            ],
            "img_path": "2505.02049/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02022",
        "img_path": "2505.02022/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Evaluating Deep Learning Architectures for Antibody Engineering Applications",
                "B. NbBench: Benchmarking Language Models for Comprehensive Nanobody Tasks",
                "C. A Comparative Study of Protein Modeling Techniques for Therapeutic Nanobodies",
                "D. Optimizing Sequence Prediction Models for Single-Domain Antibody Design",
                "E. Assessing Computational Frameworks in Synthetic Nanobody Development"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "NbBench: Benchmarking Language Models for Comprehensive Nanobody Tasks"
            ],
            "img_path": "2505.02022/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the count of distinct, pre-existing nanobody-specific deep learning models explicitly identified as being limited by narrow task design and isolated evaluation, thereby underscoring the rationale for NbBench?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 8",
                "E. 11"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.02022/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02024",
        "img_path": "2505.02024/fig1.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Exploring the Cognitive Foundations of Digital Agents in Human-Computer Interaction",
                "B. Advancements in Autonomous Systems: Integrating AI with Robotic Control Mechanisms",
                "C. The Evolution of Machine Learning Frameworks for Enhanced Digital Collaboration",
                "D. Towards Adaptive Artificial Intelligence: Bridging Human Intent and Automated Decision Making",
                "E. From Mind to Machine: The Rise of Manus AI as a Fully Autonomous Digital Agent"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "From Mind to Machine: The Rise of Manus AI as a Fully Autonomous Digital Agent"
            ],
            "img_path": "2505.02024/fig1.png"
        },
        "level2_qa": {
            "question": "In this paper, a single sentence, describe the context we give you",
            "options": [
                "A. The paper primarily introduces Manus AI as a theoretical framework for future AI, focusing on its transformer-based LLM's ability to achieve a 65% score on the GAIA test, with limited discussion on practical applications or its multi-agent system.",
                "B. Manus AI, developed by OpenAI in early 2025, excels in GAIA benchmarks due to its singular focus on a highly optimized Planner Agent, which independently processes multi-modal data to surpass GPT-4's reasoning capabilities without needing broader LLM support.",
                "C. The core innovation of Manus AI, as highlighted in its 2025 GAIA benchmark debut where it scored precisely 65%, is its reliance on existing LLM models like GPT-4, enhanced solely by a novel training process for specific tasks in robotics and gaming.",
                "D. This paper details Manus AI's completed deployment in healthcare and finance, emphasizing its multi-agent system comprised of exactly three agents that collectively use only textual data to achieve results comparable to, but not exceeding, GPT-4 on the GAIA test.",
                "E. Manus AI, introduced in early 2025, is a general-purpose agent that bridges intention with tangible outcomes through a multi-agent architecture, featuring a Planner Agent and underpinned by a transformer-based LLM, and has demonstrated state-of-the-art GAIA benchmark results exceeding a 65% score and outperforming models like GPT-4."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Manus AI, introduced in early 2025, is a general-purpose agent that bridges intention with tangible outcomes through a multi-agent architecture, featuring a Planner Agent and underpinned by a transformer-based LLM, and has demonstrated state-of-the-art GAIA benchmark results exceeding a 65% score and outperforming models like GPT-4."
            ],
            "img_path": "2505.02024/fig1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01451",
        "img_path": "2505.01451/x4.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. AdFocus: Enhancing Click-Through Rate Prediction in Multi-Slot Sponsored Search",
                "B. AdSight: Scalable and Accurate Quantification of User Attention in Multi-Slot Sponsored Search",
                "C. UserEngage: Modeling Interaction Patterns for Sponsored Search Optimization",
                "D. ClickMap: Visual Analytics for User Behavior in Multi-Position Ads",
                "E. SearchSense: Adaptive Ranking Algorithms for Sponsored Listings in Search Engines"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "AdSight: Scalable and Accurate Quantification of User Attention in Multi-Slot Sponsored Search"
            ],
            "img_path": "2505.01451/x4.png"
        },
        "level2_qa": {
            "question": "In this paper, for the multi-slot category composed of 'organic-top' and 'organic-bottom' slots, and noting the rule that this category's cluster/density label is 'True' if at least one constituent slot surpasses median Total Fixation Time (TFT) and Total Fixation Count (TFC) thresholds, what is the lowest numerical value among the observed fixation rates reported specifically for the 'organic-top' slot and the 'organic-bottom' slot?",
            "options": [
                "A. 44",
                "B. 42",
                "C. 36.5",
                "D. 29",
                "E. 46"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "29"
            ],
            "img_path": "2505.01451/x4.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01376",
        "img_path": "2505.01376/x1.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Temporal dynamics of species interactions in diverse ecological networks",
                "B. Mechanisms driving stability and diversity in complex biological assemblages",
                "C. Influence of environmental variability on population resilience in multispecies systems",
                "D. Fluctuating growth rates link turnover and unevenness in species-rich communities",
                "E. Patterns of species coexistence under fluctuating resource availability"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Fluctuating growth rates link turnover and unevenness in species-rich communities"
            ],
            "img_path": "2505.01376/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, when contrasting the long-term community stability under time-averaged neutrality, specifically considering the asymptotic Bray-Curtis similarity, what is the calculated difference between the provided lower boundary value for similarity in systems where abundances are narrowly distributed around their mode (where similarity is stated to be '>0.5') and the provided upper boundary value for similarity in systems exhibiting a power-law species abundance distribution (where similarity is stated to be '<0.15')?",
            "options": [
                "A. 0.15",
                "B. 0.50",
                "C. 0.35",
                "D. 0.65",
                "E. 0.30"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "0.35"
            ],
            "img_path": "2505.01376/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02091",
        "img_path": "2505.02091/main.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Adaptive Scheduling Algorithms for Convex Optimization in 5G Wireless Networks",
                "B. LLM-OptiRA: LLM-Driven Optimization of Resource Allocation for Non-Convex Problems in Wireless Communications",
                "C. Reinforcement Learning Approaches to Dynamic Spectrum Management in Mobile Communications",
                "D. Multi-Agent Systems for Efficient Resource Distribution in IoT-Based Wireless Environments",
                "E. Deep Neural Network Models for Energy-Efficient Signal Processing in Wireless Sensor Networks"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "LLM-OptiRA: LLM-Driven Optimization of Resource Allocation for Non-Convex Problems in Wireless Communications"
            ],
            "img_path": "2505.02091/main.png"
        },
        "level2_qa": {
            "question": "In this paper, which details LLM-OptiRA's advancement over prior methods (such as the limited approach in [13]) for complex non-convex problems, what specific research data figure, expressed as a percentage, quantifies the success rate of LLM-OptiRA with GPT-4 in solving these non-convex resource allocation tasks?",
            "options": [
                "A. 96",
                "B. 13",
                "C. 16",
                "D. 7",
                "E. 80"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "80"
            ],
            "img_path": "2505.02091/main.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02076",
        "img_path": "2505.02076/x1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Optimizing Maintenance Scheduling in Process Plants Using AI-Driven Predictive Models",
                "B. Integrating IoT Sensors and Machine Learning for Real-Time Process Monitoring",
                "C. Enhancing Safety Protocols in Industrial Systems Through Digital Twin Simulations",
                "D. Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants",
                "E. Adaptive Control Strategies for Process Plants Using Reinforcement Learning Techniques"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants"
            ],
            "img_path": "2505.02076/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, how many unique physical components of the Process Plant, explicitly listed as key elements besides the piping system, are described as interacting to perform the desired operations?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.02076/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02052",
        "img_path": "2505.02052/x5.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Leveraging Wearable Sensors for Enhanced Motion Pattern Analysis in Indoor Environments",
                "B. Dynamic Modeling of Foot-Ground Interaction to Optimize Robot Locomotion Control",
                "C. Integrating Pressure Sensor Data with Visual Recognition for Gesture Classification",
                "D. A Multi-Modal Framework for Predicting Physical Activities Using Environmental Context",
                "E. TxP: Reciprocal Generation of Ground Pressure Dynamics and Activity Descriptions for Improving Human Activity Recognition"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "TxP: Reciprocal Generation of Ground Pressure Dynamics and Activity Descriptions for Improving Human Activity Recognition"
            ],
            "img_path": "2505.02052/x5.png"
        },
        "level2_qa": {
            "question": "In this paper, to ensure the development of robust models capable of generalization despite the inherent challenges of limited real-world pressure data and the potential for overfitting during extensive training on synthetic data, what is the maximum number of consecutive epochs during which the validation loss can show no improvement before the training process is halted?",
            "options": [
                "A. 5",
                "B. 15",
                "C. 30",
                "D. 32",
                "E. 500"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "30"
            ],
            "img_path": "2505.02052/x5.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02087",
        "img_path": "2505.02087/x1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Multimodal Feature Fusion Techniques for Enhanced Medical Image Segmentation",
                "B. Transfer Learning Strategies in Large Language Models for Electronic Health Record Analysis",
                "C. Retrieval-augmented in-context learning for multimodal large language models in disease classification",
                "D. Self-supervised Contrastive Learning Approaches in Biomedical Text-Mining",
                "E. Hybrid Deep Learning Frameworks for Predictive Modeling of Patient Outcomes"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Retrieval-augmented in-context learning for multimodal large language models in disease classification"
            ],
            "img_path": "2505.02087/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the numerical result of multiplying the total count of specific MLLM models explicitly named as tested in the study by the number of different ResNet architectures mentioned for obtaining image embeddings?",
            "options": [
                "A. 8",
                "B. 9",
                "C. 15",
                "D. 12",
                "E. 20"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "15"
            ],
            "img_path": "2505.02087/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01421",
        "img_path": "2505.01421/overview.jpg",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. R. J. Smethurst",
                "B. Hugh Dickinson",
                "C. L. F. Fortson",
                "D. Tobias Géron",
                "E. Izzy L. Garland"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Tobias Géron"
            ],
            "img_path": "2505.01421/overview.jpg"
        },
        "level2_qa": {
            "question": "In this paper, for the sample of 6,640 galaxies that remained after the deduplication process, and based on the described classification scheme (where a galaxy is unbarred if p_strong_bar + p_weak_bar < 0.5), how many galaxies were ultimately classified as unbarred?",
            "options": [
                "A. 311",
                "B. 161",
                "C. 6640",
                "D. 6479",
                "E. 398"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "6479"
            ],
            "img_path": "2505.01421/overview.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01467",
        "img_path": "2505.01467/x2.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. shinySAE: Interactive Tools for Regional Data Analysis in Developing Economies",
                "B. Small Area Analysis Techniques for Health Metrics in Resource-Limited Settings",
                "C. Implementing R-Based Visualization for Epidemiological Studies in Low-Income Regions",
                "D. Advanced Statistical Models for Population Health Estimation in Emerging Economies",
                "E. sae4health: An R Shiny Application for Small Area Estimation in Low- and Middle-Income Countries"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "sae4health: An R Shiny Application for Small Area Estimation in Low- and Middle-Income Countries"
            ],
            "img_path": "2505.01467/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, describe the `sae4health` app's distinct procedural responses when data sparsity affects Admin-2 level area-models versus Admin-2 level direct estimates, and also characterize the primary purpose of an advanced modeling feature specifically available for Admin-2 analyses.",
            "options": [
                "A. The app responds to data sparsity in Admin-2 area-level models by preventing fitting and simultaneously disabling advanced options like nested models, a protocol influenced by the default settings used in the Nigeria stunting case study.",
                "B. The app prevents fitting for an area-level Admin-2 model if it fails the data sparsity check to ensure statistical validity, issues a warning if sparsity compromises interpretation of direct estimates at Admin-2, and offers a nested model option for Admin-2 models primarily to add Admin-1 fixed effects to mitigate over-smoothing.",
                "C. For any Admin-2 model, whether area-level or for direct estimates, the app applies a warning if data sparsity is encountered, and the nested model option for Admin-2 is exclusively activated if the app's national estimates deviate from official DHS reports.",
                "D. Data sparsity at the Admin-2 level primarily triggers the mandatory application of area-level covariates as an advanced option to ensure model fitting, while nested models are automatically selected when direct estimates exhibit less than an 8-fold variation across subnational areas.",
                "E. When an Admin-2 area-level model fails the sparsity check, the app's default response is to automatically fit a nested model to compensate, ensuring that interactive prevalence maps for Admin-2 always display results derived from these advanced settings to maintain consistency."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The app prevents fitting for an area-level Admin-2 model if it fails the data sparsity check to ensure statistical validity, issues a warning if sparsity compromises interpretation of direct estimates at Admin-2, and offers a nested model option for Admin-2 models primarily to add Admin-1 fixed effects to mitigate over-smoothing."
            ],
            "img_path": "2505.01467/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02016",
        "img_path": "2505.02016/x1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. SynthEDA: An Integrated Framework for Simulation and Analysis in Electronic Design Automation",
                "B. MultiEDA: Leveraging Multisensory Data Streams for Enhanced Design Automation",
                "C. Advancing Circuit Design Through Adaptive Multimodal Learning Techniques",
                "D. EDA-Net: A Deep Learning Approach for Automated Electronic Design Processes",
                "E. ForgeEDA: A Comprehensive Multimodal Dataset for Advancing EDA"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "ForgeEDA: A Comprehensive Multimodal Dataset for Advancing EDA"
            ],
            "img_path": "2505.02016/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the explicit enumeration of its constituent data types, what single number represents the total count of distinct circuit representation formats that the ForgeEDA dataset is stated to provide for analysis and development across the EDA flow?",
            "options": [
                "A. 3",
                "B. 4",
                "C. 5",
                "D. 6",
                "E. 20"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.02016/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02079",
        "img_path": "2505.02079/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. HandOcc: NeRF-based Hand Rendering with Occupancy Networks",
                "B. HandPose: Real-Time Hand Tracking using Deep Neural Networks",
                "C. NeRFNet: Volumetric Scene Reconstruction with Neural Radiance Fields",
                "D. OccupancyGAN: Generative Models for 3D Hand Shape Estimation",
                "E. Dynamic Hand Modeling with Implicit Surface Representations and Neural Networks"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "HandOcc: NeRF-based Hand Rendering with Occupancy Networks"
            ],
            "img_path": "2505.02079/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the combined total number of evaluation images utilized across the two specifically detailed ablation studies conducted on subsets of the InterHand2.6M dataset?",
            "options": [
                "A. 5,256",
                "B. 5,903",
                "C. 6,956",
                "D. 11,159",
                "E. 37,872"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "11159"
            ],
            "img_path": "2505.02079/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02093",
        "img_path": "2505.02093/x3.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Viktor Duplyakov",
                "B. Shadfar Davoodi",
                "C. Anton Morozov",
                "D. Grigoriy Shutov",
                "E. Dmitriy Popkov"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Grigoriy Shutov"
            ],
            "img_path": "2505.02093/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, regarding the preparation of seismic RMS data as input for the 3D deep convolutional neural network, where data is extracted from cubes centered at (x,y,z) grid point triplets, what is the specific numerical value given for the extent of these cubes along the axis corresponding to the z-coordinate?",
            "options": [
                "A. 3",
                "B. 9",
                "C. 46",
                "D. 2",
                "E. 4"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "46"
            ],
            "img_path": "2505.02093/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02017",
        "img_path": "2505.02017/node_structure.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Aokana: A GPU-Driven Voxel Rendering Framework for Open World Games",
                "B. Aokana: Enhancing Shader Optimization Techniques for Real-Time Graphics",
                "C. A Comprehensive Study on CPU-Based Voxel Processing for Simulation Environments",
                "D. Adaptive Lighting Models in Open World Game Engines Using Hybrid Rendering Approaches",
                "E. Integration of Procedural Terrain Generation with GPU-Accelerated Voxel Visualization"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Aokana: A GPU-Driven Voxel Rendering Framework for Open World Games"
            ],
            "img_path": "2505.02017/node_structure.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific linear voxel count along one axis that defines the common resolution of individual SVDAG-compressed data chunks, a characteristic consistently applied to the fundamental segmentation of the game map and maintained for chunks at varying Levels of Detail, such as LOD 1?",
            "options": [
                "A. 8",
                "B. 64",
                "C. 2",
                "D. 256",
                "E. 512"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "256"
            ],
            "img_path": "2505.02017/node_structure.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02056",
        "img_path": "2505.02056/x6.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Xuefeng Bai",
                "B. Xiucheng Li",
                "C. Yuchen Wang",
                "D. Weili Guan",
                "E. Liqiang Nie"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Yuchen Wang"
            ],
            "img_path": "2505.02056/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the proposed method's dual strategy involving concept alignment for mismatched classes and a confusion-aware calibrated margin for similar classes, which are collectively aimed at enhancing both accuracy and balance in pseudolabels across unsupervised learning (UL), semi-supervised learning (SSL), and transductive zero-shot learning (TRZSL) paradigms, what specific numerical research result quantifies its relative performance gain over the state-of-the-art?",
            "options": [
                "A. 5.00%",
                "B. 30.00%",
                "C. 6.29%",
                "D. 45.00%",
                "E. 12.58%"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "6.29%"
            ],
            "img_path": "2505.02056/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02230",
        "img_path": "2505.02230/genaigen.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. The GenAI Generation: Student Views of Awareness, Preparedness, and Concern",
                "B. Exploring Student Engagement with Artificial Intelligence in Higher Education",
                "C. Evaluating Educational Outcomes of AI-Enhanced Learning Tools",
                "D. Assessing Faculty Perspectives on AI Integration in Academic Curricula",
                "E. Student Attitudes Toward Emerging Technologies in Academic Settings"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The GenAI Generation: Student Views of Awareness, Preparedness, and Concern"
            ],
            "img_path": "2505.02230/genaigen.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the quantitative details provided about the survey's respondents, what numerical value represents the explicitly stated minimum percentage of participants whose extensive qualitative contributions were pivotal in revealing the 'core dual sentiment' concerning GenAI?",
            "options": [
                "A. 76",
                "B. 50",
                "C. 40",
                "D. 34",
                "E. 20"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "40"
            ],
            "img_path": "2505.02230/genaigen.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02096",
        "img_path": "2505.02096/x2.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Peiliang Zhang",
                "B. Fei Li",
                "C. Faegheh Sardari",
                "D. Yaru Chen",
                "E. Ruohao Guo"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Yaru Chen"
            ],
            "img_path": "2505.02096/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence accurately describes TeMTG's core procedural innovation for deeply integrating semantic knowledge from pre-trained models to address the feature misalignment and superficial semantic integration issues identified as limitations in prior methodologies?",
            "options": [
                "A. It directly utilizes segment-level pseudo-labels, generated by CLAP and CLIP, as the primary input for a separate classification head, thereby offering semantic guidance without direct modification of the audio-visual feature streams processed by the temporal graph.",
                "B. It constructs text embeddings from natural language descriptions derived from pseudo-labeled events and non-events, refines these modality-specific text embeddings via dedicated MLPs, and then deeply integrates them by fusing them with the original audio-visual features before subsequent feature aggregation and temporal modeling.",
                "C. It exclusively employs text embeddings generated from video-level labels to globally adjust the weights of the multi-hop temporal graph, enhancing long-range dependencies based on overall video semantics rather than segment-specific feature enhancement.",
                "D. It identifies noisy labels within the weak video-level supervision using text-based semantic similarity and filters these labels before they influence the training of the audio-visual feature extractors, ensuring cleaner initial feature representations.",
                "E. It leverages pre-trained models (CLAP/CLIP) solely to generate enhanced audio and visual features, which are then fed into a multi-hop temporal graph that implicitly learns semantic relationships without any explicit fusion of separately generated text embeddings."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "It constructs text embeddings from natural language descriptions derived from pseudo-labeled events and non-events, refines these modality-specific text embeddings via dedicated MLPs, and then deeply integrates them by fusing them with the original audio-visual features before subsequent feature aggregation and temporal modeling."
            ],
            "img_path": "2505.02096/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02071",
        "img_path": "2505.02071/COCA_alone_V2.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Hierarchical Compact Clustering Attention (COCA) for Unsupervised Object-Centric Learning",
                "B. Multi-Scale Graph Attention Networks for Supervised Semantic Segmentation",
                "C. Adaptive Feature Aggregation in Deep Convolutional Models for Image Classification",
                "D. Unsupervised Representation Learning via Generative Adversarial Networks with Attention Mechanisms",
                "E. Self-Supervised Contrastive Learning for Robust Object Detection in Complex Scenes"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Hierarchical Compact Clustering Attention (COCA) for Unsupervised Object-Centric Learning"
            ],
            "img_path": "2505.02071/COCA_alone_V2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering COCA-Net's objective of unsupervised object discovery from single images, what assertion best encapsulates the synergistic interplay between its foundational design philosophy for feature encoding, its unique clustering mechanism, and its overarching architectural strategy, especially when contrasted with the prevalent practices and underlying theories mentioned in the provided text?",
            "options": [
                "A. COCA-Net primarily achieves unsupervised object discovery by adopting a TokenCut-inspired graph-based clustering methodology, enhanced with a novel compactness score, and cascaded within a traditional bottom-up hierarchical framework that uses a pre-trained Vision Transformer backbone for initial feature extraction.",
                "B. COCA-Net distinguishes itself by employing a cascaded series of COCA layers, which embody a compactness-leveraging clustering algorithm, within a bottom-up hierarchical architecture; this system is initiated by a deliberately simple pixel feature encoder that avoids local patchification, thereby aligning with perceptual grouping principles to segment a variable number of objects without depending on the pre-trained backbones or multi-view supervision characteristic of some alternative approaches.",
                "C. The core innovation of COCA-Net lies in its five-step hierarchical agglomerative clustering process within each COCA layer, which directly builds upon traditional hierarchical methods by incorporating a pre-trained backbone to refine initial partitions generated by a top-down spectral graph clustering, thereby improving background segmentation.",
                "D. COCA-Net's superior performance in unsupervised object discovery is mainly attributed to its reliance on a graph-based clustering mechanism that leverages multi-view scene data for enhanced supervision, combined with a unique spatial inductive bias from its compactness algorithm, allowing it to outperform models limited by a fixed number of output masks.",
                "E. COCA-Net achieves object-centric representation by hierarchically clustering pixel features extracted by a sophisticated, pre-trained Vision Transformer backbone, which then feeds into COCA layers that iteratively apply a Normalized Cut algorithm, modified to incorporate compactness, for bottom-up object discovery and improved encoder-side mask generation."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "COCA-Net distinguishes itself by employing a cascaded series of COCA layers, which embody a compactness-leveraging clustering algorithm, within a bottom-up hierarchical architecture; this system is initiated by a deliberately simple pixel feature encoder that avoids local patchification, thereby aligning with perceptual grouping principles to segment a variable number of objects without depending on the pre-trained backbones or multi-view supervision characteristic of some alternative approaches."
            ],
            "img_path": "2505.02071/COCA_alone_V2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02094",
        "img_path": "2505.02094/x3.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. SkillMimic-V2: Enhancing Adaptive Control Strategies through Dense and Clean Demonstration Data",
                "B. Robust Interaction Learning: Leveraging High-Fidelity Demonstrations for Skill Generalization",
                "C. Generalizable Skill Acquisition from Multi-Modal Feedback in Human-Robot Collaboration",
                "D. SkillMimic-V2: Learning Robust and Generalizable Interaction Skills from Sparse and Noisy Demonstrations",
                "E. Sparse Data Reinforcement: Optimizing Interaction Skills with Noisy Sensor Inputs"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "SkillMimic-V2: Learning Robust and Generalizable Interaction Skills from Sparse and Noisy Demonstrations"
            ],
            "img_path": "2505.02094/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the exact number of core components that constitute the proposed comprehensive data augmentation framework, and how many distinct strategies are introduced specifically to facilitate effective RLID learning with augmented data?",
            "options": [
                "A. Three core components in the framework and two distinct RLID strategies",
                "B. Two core components in the framework and two distinct RLID strategies",
                "C. Two core components in the framework and one distinct RLID strategy",
                "D. Three core components in the framework and one distinct RLID strategy",
                "E. One core component in the framework and two distinct RLID strategies"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Two core components in the framework and two distinct RLID strategies"
            ],
            "img_path": "2505.02094/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02147",
        "img_path": "2505.02147/CNN_overview.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Yupeng Zhang",
                "B. Mridul Sharma",
                "C. Prajwal Thapa",
                "D. Jinu Nyachhyon",
                "E. Yagya Raj Pandeya"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Prajwal Thapa"
            ],
            "img_path": "2505.02147/CNN_overview.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the precise count of distinct, pre-trained architectural frameworks that the researchers explicitly selected, then uniformly adapted at their terminal processing stage for the 60-class herb identification problem, and subsequently benchmarked against one another?",
            "options": [
                "A. 1",
                "B. 5",
                "C. 6",
                "D. 60",
                "E. 121"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "6"
            ],
            "img_path": "2505.02147/CNN_overview.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02072",
        "img_path": "2505.02072/probabilities.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Analyzing Contextual Embeddings for Enhanced Language Understanding",
                "B. What do Language Model Probabilities Represent? From Distribution Estimation to Response Prediction",
                "C. From Sequence Modeling to Semantic Representation in Neural Networks",
                "D. Evaluating Probability Distributions in Neural Language Generation",
                "E. Predictive Mechanisms and Interpretation in Natural Language Processing Models"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "What do Language Model Probabilities Represent? From Distribution Estimation to Response Prediction"
            ],
            "img_path": "2505.02072/probabilities.png"
        },
        "level2_qa": {
            "question": "In this paper, when an LLM, shaped by potentially conflicting objectives from its training phases (e.g., source distribution estimation via pretraining vs. response prediction via reward-tuning), is instructed to explicitly report probabilities for target distribution estimation, what highlighted characteristic of this explicit reporting method itself exacerbates the difficulty in treating the output numbers as a veridical reflection of the target world event probabilities?",
            "options": [
                "A. The method's intrinsic reliance on logit normalization, which inherently mirrors and propagates the biases of the pretraining distribution.",
                "B. The method's documented failure to explicitly force the output to conform to a legal probability distribution, thereby allowing outputs that may not represent a coherent probabilistic assignment from any single underlying intended distribution.",
                "C. The method's inherent tendency to amplify the model's learned biases, such as predicting 'heads' in coin-flip scenarios, irrespective of explicit prompts about fairness or true probabilities.",
                "D. The method's mechanism of directly accessing and presenting the model's raw internal confidence scores, which are primarily optimized for maximizing response correctness during reward-based tuning rather than estimating event likelihoods.",
                "E. The method's fundamental requirement for extensive few-shot exemplars to accurately specify the desired target distribution, rendering it impractical for accurately assessing probabilities in novel or unprompted scenarios."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Notably, unlike logit probabilities, this method does not explicitly force a legal distribution (e.g., that all possibilities sum up to 1) as the output."
            ],
            "img_path": "2505.02072/probabilities.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01486",
        "img_path": "2505.01486/teaser.jpg",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Aerial Path Online Planning for Urban Scene Updation",
                "B. Real-Time Navigation Algorithms for Autonomous Urban Drones",
                "C. Sensor Fusion Techniques in Aerial Mapping of City Environments",
                "D. Dynamic Route Optimization for Delivery Drones in Metropolitan Areas",
                "E. Incremental 3D Reconstruction of Urban Landscapes Using UAV Data"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Aerial Path Online Planning for Urban Scene Updation"
            ],
            "img_path": "2505.01486/teaser.jpg"
        },
        "level2_qa": {
            "question": "In this paper, concerning the analysis of changed images presented in Table 4, which utilizes data from the WUSU dataset and incorporates a process of matching semantic labels for consistency with the 7 defined for the UrbanBIS benchmark, what specific number of distinct semantic labels is explicitly stated as being used for the itemized breakdown of these changes?",
            "options": [
                "A. 5",
                "B. 7",
                "C. 19",
                "D. 2",
                "E. 12"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "12"
            ],
            "img_path": "2505.01486/teaser.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02013",
        "img_path": "2505.02013/x3.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Siran Peng",
                "B. Zipei Wang",
                "C. Li Gao",
                "D. Xiangyu Zhu",
                "E. Tianshuo Zhang"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Siran Peng"
            ],
            "img_path": "2505.02013/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, regarding the inputs to the Large Language Model (LLM) within the VLF-Net's MLLM component, what is the exact count of distinct types of embedding sets that are explicitly described as being concatenated together before being passed to the LLM?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.02013/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01458",
        "img_path": "2505.01458/x1.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Advances in Sensor Fusion Techniques for Autonomous Robot Perception",
                "B. A Comparative Study of Machine Learning Algorithms for Robotic Grasping",
                "C. Optimization Strategies for Multi-Robot Coordination in Dynamic Environments",
                "D. A Survey of Robotic Navigation and Manipulation with Physics Simulators in the Era of Embodied AI",
                "E. Evaluating Reinforcement Learning Approaches for Mobile Robot Path Planning"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "A Survey of Robotic Navigation and Manipulation with Physics Simulators in the Era of Embodied AI"
            ],
            "img_path": "2505.01458/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single number represents the count of distinct prior surveys or author groups explicitly identified as having been conducted *both* before the significant emergence of LLMs and World Models (according to this paper's assessment of those specific surveys) *and* before the 2023-2025 timeframe highlighted for the notable integration of vision, language, and action in VLA models, thereby not reflecting these recent breakthroughs?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 9"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.01458/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.01468",
        "img_path": "2505.01468/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Multi-Objective Optimization for Sustainable Neural Architecture Design",
                "B. Adaptive Model Selection Strategies for Energy-Efficient Deep Learning",
                "C. One Search Fits All: Pareto-Optimal Eco-Friendly Model Selection",
                "D. Balancing Accuracy and Efficiency in Green AI Systems",
                "E. Eco-Conscious Frameworks for Scalable Machine Learning Model Evaluation"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "One Search Fits All: Pareto-Optimal Eco-Friendly Model Selection"
            ],
            "img_path": "2505.01468/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the stated objective of the GREEN approach to recommend optimal AI model configurations across diverse AI domains, what is the exact count of distinct high-level AI application domains explicitly specified as being represented by the over 1767 experiments within its foundational EcoTaskSet dataset?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 5",
                "E. 4"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "computer vision, natural language processing, and recommendation systems"
            ],
            "img_path": "2505.01468/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02099",
        "img_path": "2505.02099/x1.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents",
                "B. NeuroCache: An Extensible Framework for Optimizing LLM Data Retrieval Systems",
                "C. AgentCore: A Modular Toolkit for Integrating Knowledge Graphs into Language Models",
                "D. SyntaxNet: A Unified Platform for Enhancing Linguistic Processing in AI Agents",
                "E. CognitiveBridge: Designing Scalable Architectures for Multi-Agent Interaction in NLP"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents"
            ],
            "img_path": "2505.02099/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value is obtained by summing the count of unique, explicitly enumerated memory models integrated into MemEngine with the count of distinct interface categories specified for the implementation of these models?",
            "options": [
                "A. 11",
                "B. 12",
                "C. 13",
                "D. 14",
                "E. 15"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "14"
            ],
            "img_path": "2505.02099/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02120",
        "img_path": "2505.02120/x2.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Xiao Zhou",
                "B. Christian Herglotz",
                "C. Yan Kang",
                "D. Zhongxiang Zhao",
                "E. Hanze Guo"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Xiao Zhou"
            ],
            "img_path": "2505.02120/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the numerical difference between the total count of distinct user feedback types (K) initially considered and the resultant number of behavior categories (C) specifically within the e-commerce scenario detailed for behavior classification?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 3",
                "D. 4",
                "E. 6"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2505.02120/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02108",
        "img_path": "2505.02108/x1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. HandPoseNet: Real-Time Hand Gesture Recognition Using Deep Convolutional Networks",
                "B. GestureFlow: Modeling Dynamic Sign Language with Temporal Graph Neural Networks",
                "C. SignSplat: Rendering Sign Language via Gaussian Splatting",
                "D. VisualLex: Enhancing Sign Language Translation through Multi-Modal Visual Embeddings",
                "E. SynthSign: Generating Synthetic Sign Language Videos with Neural Rendering Techniques"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "SignSplat: Rendering Sign Language via Gaussian Splatting"
            ],
            "img_path": "2505.02108/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, to demonstrate the framework's capability in overcoming the primary challenge of limited information for complex sign language motions, what single number represents the specific quantity of camera perspectives used for the sign language dataset acquisition that featured high articulation and facial expressions, against which the method's superiority was quantitatively established?",
            "options": [
                "A. 2",
                "B. 6",
                "C. 24",
                "D. 323",
                "E. 1"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "6"
            ],
            "img_path": "2505.02108/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02182",
        "img_path": "2505.02182/fig1.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Enhanced Facial Recognition Techniques for Balanced Datasets",
                "B. Adaptive Machine Learning Models for Real-Time Object Detection",
                "C. Deep Learning Approaches to Synthetic Image Classification",
                "D. Robust AI-Generated Face Detection with Imbalanced Data",
                "E. Improving Face Verification Accuracy Using Augmented Data"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Robust AI-Generated Face Detection with Imbalanced Data"
            ],
            "img_path": "2505.02182/fig1.png"
        },
        "level2_qa": {
            "question": "In this paper, which sentence from the model architecture description most precisely identifies an optimization technique that complements the primary classification objectives (handled by Conditional Value at Risk and weighted AUC loss) by specifically targeting the enhancement of model resilience against input variations and the mitigation of tendencies to memorize training data?",
            "options": [
                "A. To enhance generalization, latent feature augmentation is applied by introducing controlled noise to extracted features using an additive transformation.",
                "B. The MLP with Batch Normalization, ReLU activation, and Dropout, refines these features, while optimization is guided by a composite loss function integrating Conditional Value at Risk (CVaR) on visual similarity and a weighted AUC loss.",
                "C. CVaR focuses on hard-to-classify samples by prioritizing worst-case performance, while AUC loss improves classification accuracy.",
                "D. This architecture effectively enhances deepfake detection by leveraging pre-trained visual features, robust augmentation techniques, and tailored loss functions.",
                "E. Additionally, the loss landscape is flattened to enhance robustness against adversarial perturbations and overfitting."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Additionally, the loss landscape is flattened to enhance robustness against adversarial perturbations and overfitting."
            ],
            "img_path": "2505.02182/fig1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02064",
        "img_path": "2505.02064/x1.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video",
                "B. Evaluating Multi-Modal Language Models for Static Image Captioning and Reasoning",
                "C. A Comparative Study of Language Models in Offline Video Analysis and Understanding",
                "D. Benchmarking Visual-Linguistic Models on Sequential Frame Interpretation and Semantic Retrieval",
                "E. Real-Time Object Detection and Language Comprehension in Multi-Layer Neural Networks"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video"
            ],
            "img_path": "2505.02064/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the approximate upper percentage of Overall Accuracy observed for the Qwen2.5-VL model when its scale was varied, according to the analysis of RTV-Bench performance findings?",
            "options": [
                "A. 31.4",
                "B. 1.4",
                "C. 32.8",
                "D. 50.0",
                "E. 3.0"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "32.8"
            ],
            "img_path": "2505.02064/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02179",
        "img_path": "2505.02179/x2.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Qi Yu",
                "B. Xinru Dong",
                "C. Shiyu Li",
                "D. Yue Liu",
                "E. Tao Zhu"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Tao Zhu"
            ],
            "img_path": "2505.02179/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value, explicitly stated as the quantity of instances selected per extreme category (highest/lowest scoring) by the Pseudo-Instance Discriminative Enhancement (PIDE) module, is justified by the module's rationale emphasizing the high signal-to-noise ratio of these specific instances and the avoidance of parameter-sensitive thresholding?",
            "options": [
                "A. 5",
                "B. 1",
                "C. 0.4",
                "D. 2",
                "E. 800"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2505.02179/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02184",
        "img_path": "2505.02184/LASSI-EE_Pipeline.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Optimizing Parallel Scientific Workflows Using Hybrid Machine Learning Models",
                "B. Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes",
                "C. Automated Code Optimization Techniques for High-Performance Computing Applications",
                "D. Energy-Efficient Scheduling Algorithms for Large-Scale Scientific Simulations",
                "E. Enhancing Computational Throughput in Parallel Systems via Adaptive Refactoring Methods"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes"
            ],
            "img_path": "2505.02184/LASSI-EE_Pipeline.png"
        },
        "level2_qa": {
            "question": "In this paper, what single numerical value represents the result of multiplying the total count of HeCBench benchmarks successfully optimized for energy reduction by LASSI-EE with the minimum performance improvement percentage reported for COpPER?",
            "options": [
                "A. 34",
                "B. 40",
                "C. 68",
                "D. 80",
                "E. 94"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "34"
            ],
            "img_path": "2505.02184/LASSI-EE_Pipeline.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02177",
        "img_path": "2505.02177/x1.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Evaluating Cross-Domain Language Models for Cantonese NLP",
                "B. Adaptive Learning Techniques for Multilingual Task Automation in Hong Kong",
                "C. Benchmarking Semantic Parsing Approaches in East Asian Languages",
                "D. Measuring Hong Kong Massive Multi-Task Language Understanding",
                "E. Contextual Representation Learning for Multitask NLP in Urban Environments"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Measuring Hong Kong Massive Multi-Task Language Understanding"
            ],
            "img_path": "2505.02177/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single number represents the total count of distinct Large Language Models on which comprehensive experiments were conducted, synthesizing the initial broad categorization of models with specific examples and their access methodologies mentioned later?",
            "options": [
                "A. 3",
                "B. 18",
                "C. 20",
                "D. 21",
                "E. 24"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "20"
            ],
            "img_path": "2505.02177/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02252",
        "img_path": "2505.02252/x1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Evaluating Cultural Influence on Sentiment Analysis in Social Media Texts",
                "B. Mitigating Algorithmic Bias in Toxic Language Classification via Transfer Learning",
                "C. Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models",
                "D. Cross-Domain Adaptation Techniques for Hate Speech Identification in Multilingual Corpora",
                "E. Incorporating Contextual Variability for Enhanced Detection of Offensive Content in Online Platforms"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models"
            ],
            "img_path": "2505.02252/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct attributes explicitly mentioned as examples of the personal information that commercial LLM memory features can retain, which are also stated as relevant to the risk of bias in hate speech detection as defined by the literature?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.02252/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02239",
        "img_path": "2505.02239/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Benjamin Appiah",
                "B. Griffith S. Klogo",
                "C. Daniel Commey",
                "D. Winful Bagyl-Bac",
                "E. James D. Gadze"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Daniel Commey"
            ],
            "img_path": "2505.02239/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of unique NIST-standardized or NIST-evaluated post-quantum cryptographic algorithms (including both Key Encapsulation Mechanisms and digital signature schemes) that were empirically benchmarked and directly compared against both RSA and ECC across all evaluated platforms, as part of the comprehensive performance analysis presented?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.02239/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02126",
        "img_path": "2505.02126/x2.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. GarmentNet: Deep Learning-Based Mesh Refinement for Accurate 3D Clothing Modeling",
                "B. Cloth3D: Multi-View Stereo Techniques for Realistic Textile Surface Reconstruction",
                "C. GarmentGS: Point-Cloud Guided Gaussian Splatting for High-Fidelity Non-Watertight 3D Garment Reconstruction",
                "D. FabricShape: Volumetric Rendering Approaches for Detailed Garment Geometry Generation",
                "E. Apparel3D: Hybrid Voxel-Point Cloud Methods for Efficient Cloth Simulation and Rendering"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "GarmentGS: Point-Cloud Guided Gaussian Splatting for High-Fidelity Non-Watertight 3D Garment Reconstruction"
            ],
            "img_path": "2505.02126/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering that previous 3D Gaussian Splatting adaptations like 2DGS and PGSR are criticized for failing to produce garments with functional openings, what single descriptive term for the final garment asset best signifies the crucial practical advantage that GarmentGS introduces, thereby addressing a significant limitation for industrial adoption?",
            "options": [
                "A. Optimized",
                "B. Detailed",
                "C. Non-watertight",
                "D. Explicit",
                "E. Wearable"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "existing methods like 2DGS(Huang et al.,2024)and PGSR(Chen et al.,2024)cannot create wearable garments with functional openings (e.g., necklines, sleeves)"
            ],
            "img_path": "2505.02126/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02135",
        "img_path": "2505.02135/x1.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Phonon Scattering Mechanisms in Cu3BiS3: Transition from Crystalline to Amorphous Phases",
                "B. Ion Hopping Effects on Electrical Conductivity in Cu3BiS3 at Elevated Temperatures",
                "C. Thermoelectric Properties of Cu-Bi-S Compounds: Influence of Structural Disorder",
                "D. Electron Transport Modulation in Cu3BiS3 under Variable Pressure Conditions",
                "E. Diffuson-Dominated Thermal Transport Crossover from Ordered to Liquid-like Cu$_3$BiS$_3$:The Negligible Role of Ion Hopping"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Diffuson-Dominated Thermal Transport Crossover from Ordered to Liquid-like Cu$_3$BiS$_3$:The Negligible Role of Ion Hopping"
            ],
            "img_path": "2505.02135/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, referencing findings from isostructural compounds and confirmed by its own ab initio molecular dynamics simulations for the high-temperature Pnma phase of Cu3BiS3, what is the specific count of distinct crystallographic sites over which Cu+ ions are described as being partially and disorderedly distributed?",
            "options": [
                "A. 3",
                "B. 4",
                "C. 5",
                "D. 8",
                "E. 204"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "5"
            ],
            "img_path": "2505.02135/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02146",
        "img_path": "2505.02146/x4.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Yuanbo Wen",
                "B. Jun Bi",
                "C. Di Huang",
                "D. Shouyang Dong",
                "E. Jiaming Guo"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Shouyang Dong"
            ],
            "img_path": "2505.02146/x4.png"
        },
        "level2_qa": {
            "question": "In this paper, what incorrect parameter value, representing tensor length, was generated by GPT-4 in an example of an instruction-related error when it attempted to replace SIMT-based scalar operations with SIMD-based tensorized instructions during transcompilation from CUDA C to BANG C code?",
            "options": [
                "A. 2309",
                "B. 1024",
                "C. 92.3",
                "D. 97.2",
                "E. 100"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1024"
            ],
            "img_path": "2505.02146/x4.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02175",
        "img_path": "2505.02175/3.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Efficient Multi-View Reconstruction Using Adaptive Mesh Refinement Techniques",
                "B. Generalizable Neural Rendering for Large-Scale 3D Scene Synthesis",
                "C. Fast 3D Model Generation via Hierarchical Point Cloud Aggregation",
                "D. Scalable Volumetric Reconstruction with Learned Radiance Fields",
                "E. SparSplat: Fast Multi-View Reconstruction with Generalizable 2D Gaussian Splatting"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "SparSplat: Fast Multi-View Reconstruction with Generalizable 2D Gaussian Splatting"
            ],
            "img_path": "2505.02175/3.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific numerical value, representing the voxel size in unspecified units, is consistently employed during the Truncated Signed Distance Function (TSDF) fusion process, both when the authors extract meshes from their method's reconstructed 2D splats and when they generate comparative mesh reconstructions for the MASt3R baseline by applying TSDF fusion to its inferred depth maps?",
            "options": [
                "A. 3.0",
                "B. 1.5",
                "C. 512",
                "D. 0.0005",
                "E. 7.14"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1.5"
            ],
            "img_path": "2505.02175/3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02275",
        "img_path": "2505.02275/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Bridging Neural Networks and Symbolic Logic for Enhanced Software Development",
                "B. Advances in Automated Code Generation Through Hybrid AI Models",
                "C. A Path Less Traveled: Reimagining Software Engineering Automation via a Neurosymbolic Paradigm",
                "D. Exploring Neuro-Symbolic Techniques for Agile Software Engineering Processes",
                "E. Integrating Cognitive Architectures in the Automation of Software Testing"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "A Path Less Traveled: Reimagining Software Engineering Automation via a Neurosymbolic Paradigm"
            ],
            "img_path": "2505.02275/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the exact number of distinctive, theory-driven benefits that the NSE paradigm claims to achieve simultaneously by integrating chaos-driven adaptability with neural and symbolic approaches, as stated in the text’s comprehensive description of NSE’s intended core advancements?",
            "options": [
                "A. Two",
                "B. Three",
                "C. Four",
                "D. Five",
                "E. Six"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Three"
            ],
            "img_path": "2505.02275/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02211",
        "img_path": "2505.02211/fig_Flow_chart.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. CSASN: A Multitask Attention-Based Framework for Heterogeneous Thyroid Carcinoma Classification in Ultrasound Images",
                "B. A Deep Learning Approach for Automated Detection of Thyroid Nodules Using MRI Scans",
                "C. Fusion of Convolutional and Recurrent Networks for Thyroid Disease Diagnosis from Ultrasound Data",
                "D. Multi-Modal Feature Extraction Techniques for Improved Carcinoma Identification in Medical Imaging",
                "E. Attention-Guided CNN Models for Differentiating Benign and Malignant Thyroid Lesions"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "CSASN: A Multitask Attention-Based Framework for Heterogeneous Thyroid Carcinoma Classification in Ultrasound Images"
            ],
            "img_path": "2505.02211/fig_Flow_chart.png"
        },
        "level2_qa": {
            "question": "In this paper, what reported percentage underscores a key limitation in conventional ultrasound image analysis for thyroid nodules, thereby motivating the development of AI-based diagnostic approaches?",
            "options": [
                "A. 31.4",
                "B. 5",
                "C. 0.98",
                "D. 3",
                "E. 20"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "20"
            ],
            "img_path": "2505.02211/fig_Flow_chart.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02180",
        "img_path": "2505.02180/x1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Clip-on Acoustic Sensors for Enhanced Ambient Sound Detection in Wearable Devices",
                "B. Real-time Analysis of Surface Vibrations for Environmental Noise Monitoring Using Piezoelectric Sensors",
                "C. Detachable Piezoelectric Modules for Monitoring Respiratory Patterns Through Facial Attachments",
                "D. Noise-Resistant Speech Recognition Using Surface Vibration Sensors Integrated into Headgear",
                "E. MaskClip: Detachable Clip-on Piezoelectric Sensing of Mask Surface Vibrations for Real-time Noise-Robust Speech Input"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "MaskClip: Detachable Clip-on Piezoelectric Sensing of Mask Surface Vibrations for Real-time Noise-Robust Speech Input"
            ],
            "img_path": "2505.02180/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the descriptions of challenges in speech communication with masks and the overview of prior or alternative solutions, what is the distinct number of specific technological categories (each differentiated by its fundamental sensing mechanism or primary operational challenge as detailed in the text) that are presented as alternatives or precursors to MaskClip's approach, excluding MaskClip itself and non-specific mentions like 'conventional microphones' or general 'existing solutions' without specific mechanism descriptions?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 7"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.02180/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02299",
        "img_path": "2505.02299/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. R. Smau",
                "B. Daisuke Yamada",
                "C. Sarben Sarkar",
                "D. Harit Vishwakarma",
                "E. Ramya Korlakai Vinayak"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Daisuke Yamada"
            ],
            "img_path": "2505.02299/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, under stationary OOD conditions, what is the user-specified tolerance parameter α that the proposed method theoretically guarantees the false positive rate (FPR) will not exceed, as exemplified in the discussion and analysis sections?",
            "options": [
                "A. 2%",
                "B. 5%",
                "C. 10%",
                "D. 0%",
                "E. 20%"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "5%"
            ],
            "img_path": "2505.02299/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02271",
        "img_path": "2505.02271/RT_Spatial_LLM_FIWARE_arch.drawio.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Adaptive Geographic Data Fusion for Enhanced Urban Planning",
                "B. Multi-Modal Sensor Integration in Dynamic City Environments",
                "C. Scalable Machine Learning Techniques for Urban Traffic Prediction",
                "D. Real-time Spatial Retrieval Augmented Generation for Urban Environments",
                "E. Context-Aware Semantic Mapping in Smart Metropolitan Areas"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Real-time Spatial Retrieval Augmented Generation for Urban Environments"
            ],
            "img_path": "2505.02271/RT_Spatial_LLM_FIWARE_arch.drawio.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct technologies or platforms are explicitly named as being integrated, utilized, or compared within the proposed real-time spatial RAG architecture or in the context of alternative RAG solutions for urban environments?",
            "options": [
                "A. Two",
                "B. Three",
                "C. Four",
                "D. Five",
                "E. Six"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Six"
            ],
            "img_path": "2505.02271/RT_Spatial_LLM_FIWARE_arch.drawio.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02255",
        "img_path": "2505.02255/shorter-titlepage.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Bartlomiej Wrzalski",
                "B. Jakub Wasala",
                "C. Kornelia Noculak",
                "D. Yuliia Tarasenko",
                "E. Oliwer Krupa"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Jakub Wasala"
            ],
            "img_path": "2505.02255/shorter-titlepage.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the maximum percentage decrease in computational cost reported for the pipeline that combines a distilled generative model with the specifically described U-Net based enhancement layer (featuring residual connections, CBAM blocks, six-layer depth, and trained with a 5e-5 learning rate on a dual-component loss function), when compared to the FLUX.1-dev baseline for generating photorealistic portraits?",
            "options": [
                "A. 5%",
                "B. 6%",
                "C. 50%",
                "D. 82%",
                "E. 95%"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "82%"
            ],
            "img_path": "2505.02255/shorter-titlepage.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02346",
        "img_path": "2505.02346/x1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. A Comparative Analysis of Python Interpreter Implementations on Computational Efficiency",
                "B. Evaluating Memory Consumption in Dynamic vs. Static Python Execution Environments",
                "C. Profiling Runtime Overheads in Python Scripts under Various Optimization Techniques",
                "D. Assessing the Impact of Just-In-Time Compilation on Python Application Scalability",
                "E. An Empirical Study on the Performance and Energy Usage of Compiled Python Code"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "An Empirical Study on the Performance and Energy Usage of Compiled Python Code"
            ],
            "img_path": "2505.02346/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, how many compiler tools, identified with specific alphanumeric version numbers in the 'Compiler Setup and Benchmarks' section, were utilized in conjunction with Python version 3.10 for the experiments?",
            "options": [
                "A. 1",
                "B. 6",
                "C. 7",
                "D. 8",
                "E. 9"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "7"
            ],
            "img_path": "2505.02346/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02279",
        "img_path": "2505.02279/security_challenges.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Comparative Analysis of Multi-Agent Coordination Techniques: Behavior, Negotiation, and Collaboration Frameworks",
                "B. Frameworks for Distributed Agent Communication: An Evaluation of Messaging and Synchronization Protocols",
                "C. A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)",
                "D. Advances in Agent Network Architectures: Designing Scalable Communication Models for Autonomous Systems",
                "E. Protocol Designs for Secure Agent Interaction: Approaches to Authentication and Data Integrity in Multi-Agent Systems"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)"
            ],
            "img_path": "2505.02279/security_challenges.png"
        },
        "level2_qa": {
            "question": "In this paper, provide a single sentence that best synthesizes the distinct primary contributions of the Client Application (Host) in MCP and the Client Agent in A2A towards achieving their respective protocols' core objectives of standardizing LLM context and enabling inter-agent collaboration, specifically highlighting their differing mechanisms of resource/service engagement.",
            "options": [
                "A. The MCP Client Application (Host) initiates JSON-RPC requests for LLM contextualization, while the A2A Client Agent utilizes REST-native messaging for asynchronous, multimodal task coordination with diverse remote systems.",
                "B. The MCP Client Application (Host) primarily ensures LLMs receive standardized context, and the A2A Client Agent primarily brokers tasks between a User and Remote Agents for collaborative execution, both operating as initiators within their respective client-server and peer-to-peer frameworks.",
                "C. Standardizing context, the MCP Client Application (Host) manages secure connections and data exchange using DIDs, whereas the A2A Client Agent enables collaboration by advertising its own capabilities via Agent Cards to other Client Agents for peer-to-peer task negotiation.",
                "D. The MCP Client Application (Host) standardizes context by requesting the four core primitives and managing asynchronous server notifications, whereas the A2A Client Agent enables collaboration by selecting Remote Agents based on Agent Cards and then passively relaying User requests and Remote Agent artifacts.",
                "E. The MCP Client Application (Host) achieves context standardization by directly requesting and processing predefined Resources, Tools, Prompts, and Sampling primitives from an MCP Server, whereas the A2A Client Agent enables collaboration by discovering and mediating task execution with Remote Agents based on dynamically advertised capabilities via Agent Cards."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "The MCP Client Application (Host) achieves context standardization by directly requesting and processing predefined Resources, Tools, Prompts, and Sampling primitives from an MCP Server, whereas the A2A Client Agent enables collaboration by discovering and mediating task execution with Remote Agents based on dynamically advertised capabilities via Agent Cards."
            ],
            "img_path": "2505.02279/security_challenges.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02284",
        "img_path": "2505.02284/x2.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Robust Query Execution Strategies Using Probabilistic Models",
                "B. Adaptive Indexing Techniques for Efficient Database Retrieval",
                "C. Conformal Prediction for Verifiable Learned Query Optimization",
                "D. Uncertainty Quantification in Machine Learning-Based Query Planning",
                "E. Semantic-Aware Optimization Methods for Large-Scale Data Systems"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Conformal Prediction for Verifiable Learned Query Optimization"
            ],
            "img_path": "2505.02284/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, when evaluating the CP-guided plan search, what specific percentage is cited as the reduction in planning time observed collectively for all test queries originating from trained LQOs?",
            "options": [
                "A. 74.4",
                "B. 9.84",
                "C. 9.96",
                "D. 3.0",
                "E. 2.0"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "9.96"
            ],
            "img_path": "2505.02284/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02306",
        "img_path": "2505.02306/safematearc.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Context-Driven Navigation Strategies for Autonomous Emergency Response Robots",
                "B. Modular Frameworks for Real-Time Hazard Detection in Disaster Management Systems",
                "C. Adaptive Agents Utilizing Retrieval-Augmented Techniques for Urban Safety Applications",
                "D. Integrating Contextual Awareness in Smart Systems for Crisis Communication and Support",
                "E. SafeMate: A Modular RAG-Based Agent for Context-Aware Emergency Guidance"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "SafeMate: A Modular RAG-Based Agent for Context-Aware Emergency Guidance"
            ],
            "img_path": "2505.02306/safematearc.png"
        },
        "level2_qa": {
            "question": "In this paper, what is identified as the core standard that enables SafeMate to integrate information from its FAISS-based static knowledge retrieval with data from dynamic external services, thereby allowing the LLM to synthesize comprehensive, context-aware multimodal responses?",
            "options": [
                "A. The FAISS engine's specific algorithm employing cosine similarity for vector-based semantic search.",
                "B. The Large Language Model's inherent advanced capabilities for natural language processing and multimodal output composition.",
                "C. The Model Context Protocol (MCP), described as an open standard providing a standardized interface for communication between the AI assistant, its knowledge sources, and external tools.",
                "D. The LangChain and LangGraph frameworks, which are components within the MCP Client layer specifically managing the interaction with and invocation of various tools and retrieval mechanisms.",
                "E. The FastAPI backend component, which primarily serves to expose the LLM agent to users and handle the routing of incoming user queries."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "To facilitate seamless integration between the client and server components of SafeMate, we adopted the MCP. MCP is an open standard that enables AI assistants to communicate with external tools and APIs through a standardized interface."
            ],
            "img_path": "2505.02306/safematearc.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02324",
        "img_path": "2505.02324/eval.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Analyzing Student Engagement Patterns Using LLMs in Higher Education",
                "B. From Course to Skill: Evaluating LLM Performance in Curricular Analytics",
                "C. Towards Adaptive Learning: Leveraging LLMs for Personalized Curriculum Design",
                "D. Assessing Knowledge Retention through Large Language Models in Educational Settings",
                "E. Integrating AI-driven Analytics for Enhancing Course Content Effectiveness"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "From Course to Skill: Evaluating LLM Performance in Curricular Analytics"
            ],
            "img_path": "2505.02324/eval.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the process detailed for building the human evaluation benchmark, what is the cumulative number of distinct curriculum documents that were assessed by the two designated annotators specifically to establish the finalized human evaluation benchmark dataset, excluding those curriculum documents used solely for the initial rubric refinement phase involving three annotators?",
            "options": [
                "A. 10",
                "B. 60",
                "C. 120",
                "D. 130",
                "E. 400"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "120"
            ],
            "img_path": "2505.02324/eval.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02257",
        "img_path": "2505.02257/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Kexun Zhang",
                "B. N. Tuning",
                "C. Christopher Rackauckas",
                "D. Yu Zhu",
                "E. Zehang Richard Li"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Yu Zhu"
            ],
            "img_path": "2505.02257/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct decomposition models for p(X|Y) explicitly mentioned as being compatible base models for the proposed BFL framework?",
            "options": [
                "A. Three",
                "B. Four",
                "C. Five",
                "D. Six",
                "E. Seven"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Five"
            ],
            "img_path": "2505.02257/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02124",
        "img_path": "2505.02124/x2.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. NEURAL: Node Embedding and Unsupervised Alignment for Robust Inference Learning",
                "B. ALIGNER: Optimized Graph Matching through Structural Feature Extraction and Neural Networks",
                "C. CODEX: Leveraging Deep Code Representations for Graph Similarity Computation",
                "D. GRAIL: Graph Edit Distance and Node Alignment Using LLM-Generated Code",
                "E. GRAPHIC: Hybrid Approaches to Graph Node Clustering and Pattern Recognition"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "GRAIL: Graph Edit Distance and Node Alignment Using LLM-Generated Code"
            ],
            "img_path": "2505.02124/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, to underscore the computational impediment overcome by GRAIL's approach, what specific maximum duration, presented in units of days, is documented for the generation of essential supervisory labels when employing conventional neural network strategies for Graph Edit Distance approximation?",
            "options": [
                "A. 1, representing the singular training pass required by the Grail-Mix variant.",
                "B. 7, corresponding to the number of distinct datasets used in GRAIL's experimental validation.",
                "C. 15, indicating the upper limit for computing NP-hard ground truth data for neural baselines.",
                "D. A quantity equivalent to the factorial complexity of graph size, indicating infeasibility rather than a fixed number of days for ground truth computation.",
                "E. An unspecified duration, as the text only characterizes the ground truth computation time as \"extensive\" without providing a concrete numerical upper bound in days."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Neural methods require NP-hard ground truth training data, which involves extensive computation times of up to 15 days."
            ],
            "img_path": "2505.02124/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02192",
        "img_path": "2505.02192/x3.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization",
                "B. MultiStream: Optimized Feature Extraction for Real-Time Video Enhancement",
                "C. SynthFace: Deep Learning Approaches for Dynamic Facial Expression Transfer",
                "D. AdaptiveFusion: Cross-Modal Integration Techniques in Video Synthesis",
                "E. MotionBlend: Temporal Consistency Models for Seamless Video Animation"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization"
            ],
            "img_path": "2505.02192/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, reflecting its success in mitigating identity degradation—a core challenge identified as stemming from the isolated customization paradigm and addressed by the proposed joint training framework—what specific, individually cited average percentage improvement does DualReal achieve for the DINO-I metric, as reported in the experimental results?",
            "options": [
                "A. 21.7",
                "B. 31.8",
                "C. 26.75",
                "D. 53.5",
                "E. 10.1"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "31.8"
            ],
            "img_path": "2505.02192/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02134",
        "img_path": "2505.02134/x1.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. HiLLIE: Human-in-the-Loop Training for Low-Light Image Enhancement",
                "B. Adaptive Neural Networks for Nighttime Image Restoration",
                "C. Interactive Frameworks for Enhancing Underexposed Photographs",
                "D. Deep Learning Approaches to Low-Light Image Denoising",
                "E. Human-Guided Optimization in Image Contrast Enhancement"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "HiLLIE: Human-in-the-Loop Training for Low-Light Image Enhancement"
            ],
            "img_path": "2505.02134/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total count of LeakyReLU activation functions explicitly mentioned as being utilized within a single processing branch of the ranker model's architecture, encompassing the initial layer, all convolutional blocks, and the connections between fully connected layers?",
            "options": [
                "A. 9",
                "B. 10",
                "C. 11",
                "D. 12",
                "E. 2"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "11"
            ],
            "img_path": "2505.02134/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02152",
        "img_path": "2505.02152/x2.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Multi-Modal Fusion for Autonomous Robot Navigation Using Image and Text Data",
                "B. Sequential Instruction Processing for Improved Robotic Grasping Tasks",
                "C. Cross-Modal Learning Strategies in Human-Robot Interaction Systems",
                "D. Interleave-VLA: Enhancing Robot Manipulation with Interleaved Image-Text Instructions",
                "E. Text-Guided Visual Perception Models for Enhanced Object Recognition in Robotics"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Interleave-VLA: Enhancing Robot Manipulation with Interleaved Image-Text Instructions"
            ],
            "img_path": "2505.02152/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the reported cropping accuracy percentage achieved for challenging objects, which initially had less than 50% accuracy with OWLv2, after the data quality verification step using Qwen2.5-VL and Segment Anything was applied?",
            "options": [
                "A. 49",
                "B. 99",
                "C. 210",
                "D. 3",
                "E. 95"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "95"
            ],
            "img_path": "2505.02152/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02314",
        "img_path": "2505.02314/neurosim_motivation.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. NeuroSim V2.0: Optimizing Algorithm Efficiency in Compute-in-Memory Architectures Under Thermal Constraints",
                "B. Benchmarking Compute-in-Memory Accelerators: A Framework for High-Level Performance Analysis and Simulation",
                "C. NeuroSim V1.5: Improved Software Backbone for Benchmarking Compute-in-Memory Accelerators with Device and Circuit-level Non-idealities",
                "D. Circuit-Level Modeling Techniques for Enhancing Reliability in Neuromorphic Computing Systems",
                "E. Evaluating Device Variability Effects on Deep Learning Accelerator Performance Using Advanced Simulation Tools"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "NeuroSim V1.5: Improved Software Backbone for Benchmarking Compute-in-Memory Accelerators with Device and Circuit-level Non-idealities"
            ],
            "img_path": "2505.02314/neurosim_motivation.png"
        },
        "level2_qa": {
            "question": "In this paper, considering NeuroSim V1.5's integration with TensorRT for transformer support alongside its current lack of detailed hardware circuit models for floating-point units in self-attention, which single sentence best synthesizes the primary challenge compelling this specific modeling approach and the simulator's stated future direction for such operations?",
            "options": [
                "A. Analog Compute-in-Memory architectures are fundamentally incompatible with the execution of any dynamic neural network operations, thus NeuroSim V1.5 defers all such complex modeling to external digital co-processing units.",
                "B. The significant area and energy overhead associated with implementing precise multi-bit digital-to-analog converters for input activations in ACIM directly prevents NeuroSim V1.5 from modeling self-attention hardware.",
                "C. The inherent properties of non-volatile memories, specifically their limited write endurance and slow programming speeds, render them ill-suited for the dynamic weight requirements of operations like self-attention, guiding NeuroSim's current computational strategy and its future plans towards integer-based hardware approximations for these components.",
                "D. TensorRT's operator replacement methodology, while enabling transformer support in NeuroSim V1.5, cannot be extended to simulate the floating-point arithmetic of self-attention within CIM hardware, forcing a reliance on current CPU/GPU execution.",
                "E. NeuroSim V1.5's behavioral modeling efforts are exclusively concentrated on analog computational elements, meaning all dynamic operations requiring digital logic, such as self-attention, are currently beyond its simulation scope until digital verification methods are incorporated."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The inherent properties of non-volatile memories, specifically their limited write endurance and slow programming speeds, render them ill-suited for the dynamic weight requirements of operations like self-attention, guiding NeuroSim's current computational strategy and its future plans towards integer-based hardware approximations for these components."
            ],
            "img_path": "2505.02314/neurosim_motivation.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02358",
        "img_path": "2505.02358/x1.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Maxim Trushin",
                "B. Xuchong Qiu",
                "C. Boris Knyazev",
                "D. Sepideh Eskandarlou",
                "E. Xiaoyan Zhang"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Maxim Trushin"
            ],
            "img_path": "2505.02358/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, under conditions where the electron drift velocity in graphene (μℰx) approaches the band velocity (v) and the electron temperature (Te) is maintained below 1000K, what is the approximate peak energy of the SPP emission spectrum resulting from electron-hole recombination, a phenomenon made detectable due to graphene's unique capability to sustain high bias and achieve high electron mobility?",
            "options": [
                "A. 0.41 eV",
                "B. 0.6 eV",
                "C. 1.58 eV",
                "D. 2.9 eV",
                "E. 9.1 eV"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "0.6 eV"
            ],
            "img_path": "2505.02358/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02376",
        "img_path": "2505.02376/x2.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Adaptive Models for Large-Scale Memory Optimization in Cloud Systems",
                "B. Automated Debugging Techniques for Resource Management in Distributed Applications",
                "C. LAMeD: LLM-generated Annotations for Memory Leak Detection",
                "D. Enhancing Software Reliability through Dynamic Resource Usage Profiling",
                "E. Towards Efficient Detection of Performance Bottlenecks Using Machine Learning"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "LAMeD: LLM-generated Annotations for Memory Leak Detection"
            ],
            "img_path": "2505.02376/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most directly states the foundational assumption regarding Large Language Model capabilities that underpins the viability of LAMeD's initial proof-of-concept implementation, which employs prompt-based generation without requiring model fine-tuning, to address complexities in code analysis?",
            "options": [
                "A. Our approach is based on the premise that LLMs trained on vast code repositories can reliably identify code segments responsible for memory allocation and deallocation even in the presence of non-standard structures or unconventional naming conventions.",
                "B. Unlike traditional formal methods, LLMs can use variable names, function names, and inline comments in their reasoning, yielding flexible and context-aware annotations.",
                "C. In this work, we present a proof of concept for this approach by focusing on prompt-based annotation generation without model fine-tuning.",
                "D. Inspired by advances in natural language processing, where human annotation is increasingly supplemented by generative models, we propose to leverage LLMs trained on public source code to generate custom, analyzer-specific annotations.",
                "E. When integrated with analyzers such as Cooddy, LAMeD significantly improves memory leak detection and reduces path explosion."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Our approach is based on the premise that LLMs trained on vast code repositories can reliably identify code segments responsible for memory allocation and deallocation even in the presence of non-standard structures or unconventional naming conventions."
            ],
            "img_path": "2505.02376/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02294",
        "img_path": "2505.02294/x2.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Adaptive Neural Networks for Enhanced Obstacle Avoidance in Autonomous Robots",
                "B. Depth-Enhanced Visual Mapping Techniques for Indoor Robotic Path Planning",
                "C. Real-Time Sensor Fusion Strategies for Safe Navigation in Dynamic Environments",
                "D. RNBF: Real-Time RGB-D Based Neural Barrier Functions for Safe Robotic Navigation",
                "E. RGB-D Data Integration with Reinforcement Learning for Efficient Robot Localization"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "RNBF: Real-Time RGB-D Based Neural Barrier Functions for Safe Robotic Navigation"
            ],
            "img_path": "2505.02294/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of 3D points generated for the training batch from a single selected frame, considering all sampled depth values along all initially selected rays?",
            "options": [
                "A. 200",
                "B. 28",
                "C. 5400",
                "D. 5800",
                "E. 5600"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "5600"
            ],
            "img_path": "2505.02294/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02226",
        "img_path": "2505.02226/x6.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Dynamics of Newtonian droplet spreading on inclined surfaces",
                "B. Coalescence of viscoelastic sessile drops: the small and large contact angle limits",
                "C. Evaporation patterns of sessile drops with varying surface tension",
                "D. Interfacial instabilities in sliding viscoelastic drops under shear flow",
                "E. Thermal effects on coalescence behavior of polymeric microdroplets"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Coalescence of viscoelastic sessile drops: the small and large contact angle limits"
            ],
            "img_path": "2505.02226/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the experimental investigations into the coalescence of sessile drops in the small contact angle regime (θ≪1), what is the specific average power-law exponent (α) determined for the temporal evolution of the bridge height (h0(t) ∝ t^α) when using 1.0 wt% PEO solutions?",
            "options": [
                "A. 1.16",
                "B. 0.67",
                "C. 0.818",
                "D. 1.00",
                "E. 1.03"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "1.03"
            ],
            "img_path": "2505.02226/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02236",
        "img_path": "2505.02236/x11.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Enhancing Semantic Understanding in Text-to-Image Synthesis Models",
                "B. Advancements in Multimodal Learning for Image Generation Tasks",
                "C. Improving Physical Object State Representation in Text-to-Image Generative Systems",
                "D. Optimizing Texture Rendering in Generative Adversarial Networks",
                "E. A Study on Contextual Embedding for Visual Content Creation"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Improving Physical Object State Representation in Text-to-Image Generative Systems"
            ],
            "img_path": "2505.02236/x11.png"
        },
        "level2_qa": {
            "question": "In this paper, what single number from the research data signifies the average percentage improvement on the evaluation benchmark specifically curated by the authors to test enhanced representation of object states, like 'empty', which their synthetic data generation pipeline was designed to primarily bolster due to common underrepresentation?",
            "options": [
                "A. 8",
                "B. 200",
                "C. 4",
                "D. 24",
                "E. 32"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "24"
            ],
            "img_path": "2505.02236/x11.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02329",
        "img_path": "2505.02329/fww-process.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Rachel Y. Kim",
                "B. Sicun Gao",
                "C. Daniel Schneider",
                "D. Jonathan Lynn",
                "E. Sachin S. Pandya"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Jonathan Lynn"
            ],
            "img_path": "2505.02329/fww-process.png"
        },
        "level2_qa": {
            "question": "In this paper, provide a single sentence that most accurately synthesizes the primary rationale for the acknowledged absence of software developers as direct interviewees and the specific approach taken to incorporate their perspectives to some extent.",
            "options": [
                "A. Software developers were not interviewed due to difficulties in recruitment, but their views were inferred from public documentation and software features.",
                "B. The study deliberately omitted software developers to maintain focus on worker and manager experiences, with their perspectives being entirely deferred to future research.",
                "C. To amplify perspectives underrepresented in prior literature, software developers were not directly interviewed; however, insights into vendor perspectives were obtained through interviews with regulators and defense attorneys who had worked with them.",
                "D. Concerns about the proprietary nature of AM software led to the exclusion of developers, whose viewpoints were then approximated by analyzing their product websites.",
                "E. The research team's lack of connections within the software development industry was the main reason for not including developers, with their input being indirectly gathered from academic literature on AM software."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "To amplify perspectives underrepresented in prior literature, software developers were not directly interviewed; however, insights into vendor perspectives were obtained through interviews with regulators and defense attorneys who had worked with them."
            ],
            "img_path": "2505.02329/fww-process.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02289",
        "img_path": "2505.02289/x8.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Assessing the Impact of Urban Development on Freshwater Ecosystems",
                "B. Lakeplace: Sensing interactions between lakes and human activities",
                "C. Modeling Hydrological Changes in Response to Climate Variability",
                "D. Evaluating Biodiversity Shifts in Lake Environments under Anthropogenic Pressure",
                "E. Integrating Remote Sensing and GIS to Monitor Aquatic Habitat Dynamics"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Lakeplace: Sensing interactions between lakes and human activities"
            ],
            "img_path": "2505.02289/x8.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the discussion on social-demographic profiling versus popularity metrics, what is the specific quantity of distinct 'lakeplace' examples explicitly enumerated and characterized by their unique socio-economic or racial composition patterns and associated built environments, which might otherwise be overlooked if assessed by popularity alone?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. Several, as the text mentions 'several meaningful outliers' but does not further enumerate a specific count of those that are detailed with socio-economic characteristics."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.02289/x8.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03096",
        "img_path": "2505.03096/x1.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. M.S. Blok",
                "B. Joshua Owotogbe",
                "C. Gustavo Polleti",
                "D. Alireza Doostan",
                "E. Fatih E. Bilgen"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Joshua Owotogbe"
            ],
            "img_path": "2505.03096/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct research contributions addressing separate subquestions (SQs) are explicitly detailed as foundational to the proposed chaos engineering framework for LLM-MAS robustness?",
            "options": [
                "A. One, focused solely on literature review and failure mode identification",
                "B. Two, each addressing a different subquestion: research gaps and framework development",
                "C. Three, covering literature review, framework development, and empirical validation",
                "D. Four, with separate emphasis on literature, tools, failure modes, and validation",
                "E. Five, integrating literature review, tools analysis, framework creation, validation, and deployment"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Two, each addressing a different subquestion: research gaps and framework development"
            ],
            "img_path": "2505.03096/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02365",
        "img_path": "2505.02365/x1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Adaptive Wavelet-Based Multi-focus Image Fusion for Color Enhancement",
                "B. Deep Learning Approaches to Multi-exposure Color Image Blending",
                "C. Sparse Representation Techniques for Multi-focus Grayscale Image Fusion",
                "D. Hybrid Transform Methods in Multi-focus Hyperspectral Image Fusion",
                "E. Quaternion Multi-focus Color Image Fusion"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Quaternion Multi-focus Color Image Fusion"
            ],
            "img_path": "2505.02365/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, describe the distinct informational inputs and rationale underpinning the generation of the two separate fused results, 𝐏˙(1) and 𝐏˙(2), within the Quaternion Base-Detail Fusion (QBDF) strategy, specifically referencing how outputs from the Quaternion Sparse Decomposition (QSD) are differentially employed.",
            "options": [
                "A. The detail-scale result (𝐏˙(1)) relies on focus measures derived solely from the gradients of QSD's detail layers to capture fine variations, while the base-scale result (𝐏˙(2)) incorporates both these gradients and QSD's coefficient matrices into its focus measure, specifically to enhance local consistency and counteract artifacts potentially introduced by the detail-scale's focus assessment in challenging regions.",
                "B. The base-scale result (𝐏˙(2)) utilizes focus measures based exclusively on QSD's coefficient matrices for structural integrity, whereas the detail-scale result (𝐏˙(1)) combines these coefficient matrices with detail layer gradients to refine texture information prior to QSSR.",
                "C. Both 𝐏˙(1) and 𝐏˙(2) are generated using identical focus measures derived from a weighted combination of QSD's detail layer gradients and coefficient matrices, with their distinction arising only from different patch selection thresholds optimized for texture versus structure.",
                "D. The QSD model directly outputs 𝐏˙(1) as its detail layer and 𝐏˙(2) as its coefficient matrix, which QBDF then simply aggregates without distinct focus measures, relying on the subsequent QSSR stage for all artifact correction.",
                "E. 𝐏˙(1) is formed using focus measures from QSD's coefficient matrices to identify broad focused areas, while 𝐏˙(2) uses QSD's detail layer gradients to correct focus inaccuracies solely within boundary regions, both contributing equally to the QSSR input."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The detail-scale result (𝐏˙(1)) relies on focus measures derived solely from the gradients of QSD's detail layers to capture fine variations, while the base-scale result (𝐏˙(2)) incorporates both these gradients and QSD's coefficient matrices into its focus measure, specifically to enhance local consistency and counteract artifacts potentially introduced by the detail-scale's focus assessment in challenging regions."
            ],
            "img_path": "2505.02365/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03066",
        "img_path": "2505.03066/figure_1_corrected.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Integrating Structural Features and Machine Learning for Substrate Specificity Analysis of Kinase Families",
                "B. Predictive Modeling of Enzyme Activity Using Amino Acid Sequence Profiles in High-Throughput Assays",
                "C. Application of Deep Learning Techniques to Functional Annotation of Adenylate Kinase Variants",
                "D. Leveraging Protein Language Model Embeddings for Catalytic Turnover Prediction of Adenylate Kinase Orthologs in a Low-Data Regime",
                "E. Exploring Evolutionary Patterns of Orthologous Enzymes through Multimodal Protein Representations"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Leveraging Protein Language Model Embeddings for Catalytic Turnover Prediction of Adenylate Kinase Orthologs in a Low-Data Regime"
            ],
            "img_path": "2505.03066/figure_1_corrected.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement most accurately synthesizes the findings on optimal strategies for $k_{cat}$ prediction using Protein Language Models with diverse ADK orthologs, encompassing PLM selection, embedding generation and fine-tuning, aggregation techniques, and dataset-specific methodological adaptations?",
            "options": [
                "A. Direct fine-tuning of Ankh-large embeddings, using simple max aggregation and embeddings from early PLM layers, was identified as the superior method, rendering complex cross-validation schemes unnecessary due to the inherent robustness of fine-tuned models.",
                "B. LoRA masked language model fine-tuning consistently improved $k_{cat}$ prediction across all tested PLMs, especially Prot-T5-XL-BFD, making the choice of specific PLM or aggregation method less critical, and suggesting that combining embeddings from all encoder layers offers peak performance.",
                "C. Nonlinear probing of ESM3-open embeddings, enhanced by direct fine-tuning, outperformed one-hot encoding and specialized models like CatPred; this success indicated that the dataset's broad sequence diversity (42% average identity) made transformer-based aggregation and lid-aware validation redundant complexities.",
                "D. The study confirmed that while ESMC 600M provides strong zero-shot embeddings, achieving optimal performance required LoRA masked language model fine-tuning, specifically with ProstT5 due to its structure-informed pre-training, thereby outperforming even transformer-based learnable aggregation on zero-shot embeddings.",
                "E. The most effective approach involved using zero-shot ESMC 600M embeddings, processed with transformer-based learnable aggregation, complemented by a lid-aware cross-validation strategy to mitigate biases from ADK structural variations."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "The most effective approach involved using zero-shot ESMC 600M embeddings, processed with transformer-based learnable aggregation, complemented by a lid-aware cross-validation strategy to mitigate biases from ADK structural variations."
            ],
            "img_path": "2505.03066/figure_1_corrected.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02304",
        "img_path": "2505.02304/x2.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Yunan Li",
                "B. Wentian Xin",
                "C. Huizhou Chen",
                "D. Xujie Liu",
                "E. Siyu Liang"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Siyu Liang"
            ],
            "img_path": "2505.02304/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the maximum size, expressed in millions of Chinese characters, that an individual document within the Generative Sign-description Prompts system's domain-specific knowledge base can reach?",
            "options": [
                "A. 1",
                "B. 15",
                "C. 50",
                "D. 1000",
                "E. 300"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "15"
            ],
            "img_path": "2505.02304/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03112",
        "img_path": "2505.03112/method.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Adaptive Modulation Techniques for Closed-Set Communication in Low-Resource Environments",
                "B. Training-Based Approaches to Open-Set Modulation Using Neural Language Models",
                "C. Plug-and-Play AMC: Context Is King in Training-Free, Open-Set Modulation with LLMs",
                "D. Context-Aware Signal Classification: Enhancing Modulation Recognition with Supervised Learning",
                "E. Evaluating the Role of Pretrained Models in Semi-Supervised Adaptive Modulation Control"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Plug-and-Play AMC: Context Is King in Training-Free, Open-Set Modulation with LLMs"
            ],
            "img_path": "2505.03112/method.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct signal representations are specifically mentioned as being used in prior CNN-based AMC approaches to improve classification accuracy through their combination?",
            "options": [
                "A. Two",
                "B. Three",
                "C. Four",
                "D. Five",
                "E. Six"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Three"
            ],
            "img_path": "2505.03112/method.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03075",
        "img_path": "2505.03075/x2.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Adaptive Knowledge Integration for Enhanced Language Model Performance",
                "B. Optimization Strategies for Multi-modal Information Retrieval in NLP",
                "C. Direct Retrieval-augmented Optimization: Synergizing Knowledge Selection and Language Models",
                "D. Balancing Contextual Embeddings and Retrieval Mechanisms in Transformer Architectures",
                "E. Frameworks for Scalable Knowledge Selection in Large-scale Language Models"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Direct Retrieval-augmented Optimization: Synergizing Knowledge Selection and Language Models"
            ],
            "img_path": "2505.03075/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the reported experimental results comparing DRO to the best baseline across five datasets, what is the lower-bound numerical value representing the percentage improvement observed in either the EM or F1 metric?",
            "options": [
                "A. 5",
                "B. 10",
                "C. 15",
                "D. 3",
                "E. 20"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "5"
            ],
            "img_path": "2505.03075/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02370",
        "img_path": "2505.02370/x5.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Xin Gu",
                "B. Fan Chen",
                "C. Xiaoying Xing",
                "D. Longyin Wen",
                "E. Ming Li"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Ming Li"
            ],
            "img_path": "2505.02370/x5.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the methodology for rectifying editing instructions, what is the specific count of distinct generation attributes derived from the observed timestep-specific prior behaviors of diffusion models, which are then used to provide a unified guide for Vision-Language Models?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 1",
                "E. 77"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.02370/x5.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03046",
        "img_path": "2505.03046/model_architecture.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Enhancing Robotic Manipulation Through Multi-Modal Sensor Fusion",
                "B. Sim2Real Transfer for Vision-Based Grasp Verification",
                "C. Deep Learning Approaches for Object Detection in Cluttered Environments",
                "D. Domain Adaptation Techniques for Autonomous Navigation in Dynamic Scenes",
                "E. Vision-Guided Control Strategies for Dexterous Robotic Handwriting"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Sim2Real Transfer for Vision-Based Grasp Verification"
            ],
            "img_path": "2505.03046/model_architecture.png"
        },
        "level2_qa": {
            "question": "In this paper, how are the comparisons of the proposed grasp verification model to Visual Question Answering methodologies differentiated in terms of their learning paradigms and roles within the overall evaluation strategy?",
            "options": [
                "A. The model is primarily benchmarked against a few-shot LLM-based VQA, with an initial exploration of zero-shot VQA deemed insufficient for comprehensive evaluation.",
                "B. Zero-shot VQA serves as the exclusive baseline for synthetic data experiments, while few-shot LLM-based VQA is used as an alternative for real-world data assessments to gauge domain adaptation.",
                "C. The model is benchmarked against Visual Question Answering used as a zero-shot baseline, while the evaluation objectives also specifically include comparing the model to an LLM-based Visual Question Answering approach employed as a few-shot alternative.",
                "D. Both zero-shot and few-shot VQA methodologies are integrated into a single, unified baseline, with the few-shot component enhancing the zero-shot VQA's capabilities for deformable objects.",
                "E. The paper dismisses VQA approaches as viable baselines due to their limitations with deformable objects, focusing instead on comparisons with geometric-based methods."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The model is benchmarked against Visual Question Answering used as a zero-shot baseline, while the evaluation objectives also specifically include comparing the model to an LLM-based Visual Question Answering approach employed as a few-shot alternative."
            ],
            "img_path": "2505.03046/model_architecture.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02417",
        "img_path": "2505.02417/method.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. TS2T: Text-Guided Series Forecasting via Diffusion Networks",
                "B. Diffusion Frameworks for Multivariate Temporal Data Reconstruction",
                "C. High-Fidelity Generation of Sequential Data Using Latent Diffusion Models",
                "D. Neural Approaches to Time Series Augmentation with Conditional Generative Models",
                "E. T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models"
            ],
            "img_path": "2505.02417/method.png"
        },
        "level2_qa": {
            "question": "In this paper, what fundamental characteristic of the TSFragment-600K dataset's caption generation pipeline is primarily responsible for its ability to produce generalizable, natural language descriptions that capture fine-grained temporal dynamics and ensure semantic coherence, thereby addressing limitations of prior domain-specific and dictionary-based captioning methods?",
            "options": [
                "A. The exclusive reliance on human experts for curating all fragment descriptions and generating final captions, ensuring maximum accuracy and nuanced natural language.",
                "B. The segmentation of time series into a variable number of overlapping fragments, followed by the application of predefined dictionaries of time-series changes to generate concise captions.",
                "C. The synergistic use of a seed-based prompting strategy with a large language model (GPT-4o-mini) for diverse caption generation, followed by an embedding-based cosine similarity selection process to ensure high semantic quality and coherence.",
                "D. The primary application of the Flow Matching framework to directly generate captions from raw time series fragments, optimizing for interpretability and reduced training costs.",
                "E. The generation of five candidate captions using solely instance-level descriptions as a basis, with a token limit applied to ensure point-level detail is captured succinctly."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The synergistic use of a seed-based prompting strategy with a large language model (GPT-4o-mini) for diverse caption generation, followed by an embedding-based cosine similarity selection process to ensure high semantic quality and coherence."
            ],
            "img_path": "2505.02417/method.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03054",
        "img_path": "2505.03054/x1.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. SLAB: Scalable Learning for Audio Benchmarking",
                "B. BLAB: Brutally Long Audio Bench",
                "C. BLAB+: Balanced Audio Length Analysis Benchmark",
                "D. LARGE-SOUND: Extended Duration Audio Dataset for Evaluation",
                "E. DEEP-AUD: Deep Learning Approaches for Variable-length Audio"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "BLAB: Brutally Long Audio Bench"
            ],
            "img_path": "2505.03054/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single number, expressed in minutes, represents the upper limit of audio sample duration included in the BLAB benchmark, according to its specified range?",
            "options": [
                "A. 15",
                "B. 5",
                "C. 51",
                "D. 2",
                "E. 120"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "120"
            ],
            "img_path": "2505.03054/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02325",
        "img_path": "2505.02325/x2.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Yang Zhou",
                "B. Jinhai Xiang",
                "C. Yulong Wang",
                "D. Xinwei He",
                "E. Zhichuan Wang"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Zhichuan Wang"
            ],
            "img_path": "2505.02325/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, when TeDA's framework was extended to point clouds using depth map projections for zero-shot experiments on the Objaverse-LVIS dataset, what is the total number of distinct LVIS categories reported for this dataset?",
            "options": [
                "A. 46832",
                "B. 8798",
                "C. 1156",
                "D. 10",
                "E. 4"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "1156"
            ],
            "img_path": "2505.02325/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03030",
        "img_path": "2505.03030/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Enhancing Contextual Understanding in Large Language Models for Improved Text Generation",
                "B. Optimization of Prompt Engineering Techniques for Bias Mitigation in LLM Outputs",
                "C. UCSC Approaches to Semantic Analysis and Model Adaptation in Large-Scale NLP Tasks",
                "D. Evaluating Model Robustness and Contextual Relevance in Automated Text Summarization Systems",
                "E. UCSC at SemEval-2025 Task 3: Context, Models and Prompt Optimization for Automated Hallucination Detection in LLM Output"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "UCSC at SemEval-2025 Task 3: Context, Models and Prompt Optimization for Automated Hallucination Detection in LLM Output"
            ],
            "img_path": "2505.03030/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the 14 languages of the Mu-SHROOM task, for how many of these languages did the UCSC system *not* secure a top-two ranking based on the character-level Intersection-of-Union metric used for hard label evaluation?",
            "options": [
                "A. 1",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 11"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.03030/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03113",
        "img_path": "2505.03113/x1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. A Comparative Study of Offline Deep Convolutional Networks for Image Classification",
                "B. Enhancing Object Detection Efficiency Using Hybrid CNN-RNN Architectures",
                "C. Survey of Lightweight Neural Networks for Real-Time Video Analysis",
                "D. Image Recognition with Online Lightweight Vision Transformer: A Survey",
                "E. Advancements in Transfer Learning Techniques for Visual Scene Understanding"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Image Recognition with Online Lightweight Vision Transformer: A Survey"
            ],
            "img_path": "2505.03113/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most accurately synthesizes the defining characteristics of the surveyed online lightweighting strategies for Vision Transformers, encompassing their operational timing, primary technical approaches, differentiation from other optimization paradigms, and their fundamental objective concerning model structure and capability?",
            "options": [
                "A. Online strategies primarily involve post-training architectural modifications like pruning and quantization, aiming to drastically reduce model size without considering training-time optimizations or expressive capacity.",
                "B. The surveyed online strategies, executed exclusively after model training, focus on aggressive model compression through component removal and parameter reduction, serving as alternatives to knowledge distillation or dynamic network adjustments.",
                "C. This paper details online lightweighting techniques such as efficient component design, dynamic networks, and knowledge distillation, which are applied during the training phase to achieve a \"soft\" lightweighting by enhancing efficiency while fundamentally preserving the model's architecture and expressive capacity, distinguishing them from subsequent, more aggressive offline methods.",
                "D. The core of the surveyed strategies is to replace ViT components with simpler CNN-based modules during inference, thereby achieving lightweighting by fundamentally altering the model architecture post-training, unlike dynamic network adjustments which occur pre-training.",
                "E. Online lightweighting, as discussed, prioritizes minimizing computational cost through aggressive, irreversible structural changes before training begins, acting as a foundational step that often negates the need for efficient component design or knowledge distillation."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "This paper details online lightweighting techniques such as efficient component design, dynamic networks, and knowledge distillation, which are applied during the training phase to achieve a \"soft\" lightweighting by enhancing efficiency while fundamentally preserving the model's architecture and expressive capacity, distinguishing them from subsequent, more aggressive offline methods."
            ],
            "img_path": "2505.03113/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03120",
        "img_path": "2505.03120/x6.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Muhammad Talha Khan",
                "B. Muhammad Azmi Umer",
                "C. Abdul Mustafa",
                "D. Zaki Masood",
                "E. Chuadhry Mujeeb Ahmed"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Abdul Mustafa"
            ],
            "img_path": "2505.03120/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement most accurately describes the central research outcome stemming from the application of Jacobian Saliency Map Attack (JSMA) generated samples within the context of the SWaT testbed and its binary classification problem?",
            "options": [
                "A. The study primarily demonstrated that JSMA can achieve a high adversarial success rate by modifying a minimal percentage of input features, similar to prior findings where only 4.02% of features were altered.",
                "B. The research conclusively identified Gradient Boosting Classifier (GBC) as the superior algorithm for detecting intrusions in the SWaT environment, irrespective of adversarial sample integration, due to its inherent robustness.",
                "C. The core achievement was the successful generation of adversarial samples using JSMA that effectively bypassed various IDS models deployed on the SWaT testbed, requiring complete knowledge of their design and parameters for effective attack crafting.",
                "D. The application of a specific pre-processing sequence, involving label encoding of nominal attack/normal values followed by min-max normalization of all features to a 0-1 range, was proven to be the definitive factor for achieving 95% detection accuracy on new SWaT dataset attacks.",
                "E. The study successfully validated that training an IDS model with JSMA-generated adversarial samples significantly enhances its ability to detect previously unseen real-world attacks within the SWaT system, achieving 95% accuracy on such data."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "The study successfully validated that training an IDS model with JSMA-generated adversarial samples significantly enhances its ability to detect previously unseen real-world attacks within the SWaT system, achieving 95% accuracy on such data."
            ],
            "img_path": "2505.03120/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03153",
        "img_path": "2505.03153/Research_Figure.pptx-7.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Adaptive Multimodal Representation Learning for Radiological Image Classification",
                "B. Robust Fairness Vision-Language Learning for Medical Image Analysis",
                "C. Enhancing Interpretability in Vision-Language Models for Healthcare Diagnostics",
                "D. Cross-Modal Deep Learning Approaches for Medical Image Segmentation",
                "E. Bias Mitigation Techniques in Clinical NLP and Imaging Integration"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Robust Fairness Vision-Language Learning for Medical Image Analysis"
            ],
            "img_path": "2505.03153/Research_Figure.pptx-7.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the described issues where VLMs like CLIP exhibit inherent biases (e.g., associating 'felon' with specific races) and face robustness challenges exacerbated by errors introduced when LLMs summarize extensive medical notes due to VLM token limitations (e.g., CLIP's effective 20-token length, distinct from its nominal maximum), what is the specific maximum percentage improvement in equity-scaled AUC reported as a direct outcome of the experimental testing of the proposed framework?",
            "options": [
                "A. 20%",
                "B. 8.6%",
                "C. 55%",
                "D. 67%",
                "E. 77%"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "8.6%"
            ],
            "img_path": "2505.03153/Research_Figure.pptx-7.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03147",
        "img_path": "2505.03147/x1.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Enhancing Cyber Threat Detection through Behavioral Analysis of Malicious Actors",
                "B. Leveraging Machine Learning for Automated Classification of Network Intrusion Patterns",
                "C. A Framework for Real-time Anomaly Detection in Cybersecurity Using Deep Neural Networks",
                "D. Towards Effective Identification of Attack Techniques in Cyber Threat Intelligence Reports using Large Language Models",
                "E. Improving Malware Identification Accuracy via Hybrid Feature Extraction Techniques"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Towards Effective Identification of Attack Techniques in Cyber Threat Intelligence Reports using Large Language Models"
            ],
            "img_path": "2505.03147/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, subsequent to the application of the comprehensive CTI extraction improvement strategy—which integrates LLM-based report summarization with a retrained SciBERT model operating on a dataset specifically rebalanced and augmented using LLM-generated data—what F1-score benchmark was surpassed by several attack techniques?",
            "options": [
                "A. 0.40",
                "B. 0.50",
                "C. 0.75",
                "D. 0.90",
                "E. 0.45"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "0.90"
            ],
            "img_path": "2505.03147/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03102",
        "img_path": "2505.03102/x2.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Optimizing Memory Hierarchies for Vortex RISC-V GPU Architectures",
                "B. Hardware vs. Software Implementation of Warp-Level Features in Vortex RISC-V GPU",
                "C. Software-Driven Parallelism Models for RISC-V Based Graphics Processors",
                "D. Energy-Efficient Scheduling Techniques in Warp-Level GPU Computation",
                "E. Comparative Analysis of Cache Coherence Protocols in RISC-V GPU Systems"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Hardware vs. Software Implementation of Warp-Level Features in Vortex RISC-V GPU"
            ],
            "img_path": "2505.03102/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific percentage increase in logic area attributed to the architectural modifications within the Vortex GPU core—namely changes to the ALU and decoder to support new instructions like vx_vote and vx_shfl—when implementing hardware support for warp-level functions as an alternative to software-only approaches?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 6"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2505.03102/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03163",
        "img_path": "2505.03163/Methodology.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Evaluating Teacher Adoption of AI Tools in Urban Indian Classrooms: A Mixed Methods Study",
                "B. The Role of Digital Literacy in Enhancing STEM Education in Rural Schools of India",
                "C. The Impact of Large Language Models on K-12 Education in Rural India: A Thematic Analysis of Student Volunteer's Perspectives",
                "D. Assessing Mobile Learning Applications for Secondary Education Accessibility in Remote Indian Regions",
                "E. Exploring Parental Attitudes Toward Technology Integration in K-12 Education Across India"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The Impact of Large Language Models on K-12 Education in Rural India: A Thematic Analysis of Student Volunteer's Perspectives"
            ],
            "img_path": "2505.03163/Methodology.png"
        },
        "level2_qa": {
            "question": "In this paper, provide the single sentence that best encapsulates the critical prerequisite, synthesizing volunteer educators' core perspective with the study's findings on systemic challenges, for LLMs to positively contribute to rural K-12 education.",
            "options": [
                "A. The primary prerequisite is the immediate eradication of all infrastructural deficits and achievement of universal digital literacy before any LLM deployment.",
                "B. LLMs will positively contribute if volunteer educators are mandated to exclusively use AI tools, thereby maximizing exposure and overcoming resistance.",
                "C. Positive contribution from LLMs fundamentally depends on their deployment as replacements for traditional methods in areas with severe teacher shortages.",
                "D. The critical prerequisite for LLMs' positive contribution is ensuring they are perceived and implemented as complementary pedagogical aids, supported by context-specific strategies that address both resource limitations and stakeholder concerns.",
                "E. Successful LLM integration hinges primarily on developing advanced AI that requires minimal teacher oversight and operates independently of local connectivity issues."
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "The critical prerequisite for LLMs' positive contribution is ensuring they are perceived and implemented as complementary pedagogical aids, supported by context-specific strategies that address both resource limitations and stakeholder concerns."
            ],
            "img_path": "2505.03163/Methodology.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03088",
        "img_path": "2505.03088/x2.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Global Task-aware Fault Detection, Identification For On-Orbit Multi-Spacecraft Collaborative Inspection",
                "B. Adaptive Scheduling Strategies for Multi-Spacecraft Communication in Space Missions",
                "C. Decentralized Control Algorithms for Collaborative Satellite Formation Flying",
                "D. Fault Tolerance Mechanisms in Distributed Spacecraft Systems with Autonomous Navigation",
                "E. Real-Time Anomaly Prediction for On-Orbit Satellite Networks Using Machine Learning"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Global Task-aware Fault Detection, Identification For On-Orbit Multi-Spacecraft Collaborative Inspection"
            ],
            "img_path": "2505.03088/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct categories of *agent-level* faults are explicitly stated as being identified using the new metric derived from higher-order cost gradients of $\\mathcal{H}$?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 0",
                "E. 4"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2505.03088/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03077",
        "img_path": "2505.03077/data_regeneration_concept.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Optimizing Trajectory Prediction for Robotic Manipulation",
                "B. Hierarchical Reinforcement Learning for Multi-Agent Coordination",
                "C. Latent Adaptive Planner for Dynamic Manipulation",
                "D. Deep Neural Networks for Static Object Recognition",
                "E. Adaptive Control Strategies in Autonomous Navigation Systems"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Latent Adaptive Planner for Dynamic Manipulation"
            ],
            "img_path": "2505.03077/data_regeneration_concept.png"
        },
        "level2_qa": {
            "question": "In this paper, which of the following best describes the core operational principle of the Latent Adaptive Planner (LAP) that enables its synthesis of real-time adaptability and computational efficiency for dynamic nonprehensile manipulation using human demonstrations on diverse robotic platforms?",
            "options": [
                "A. LAP primarily relies on a highly optimized open-loop planning strategy inferred once from comprehensive scene state estimation, which minimizes computational load for dynamic tasks.",
                "B. The system employs a full closed-loop planning approach, resampling the entire latent plan from all historical observations (𝐱0:t) at each time step, ensuring maximal adaptability regardless of computational cost.",
                "C. LAP's core principle is the incremental refinement of latent plans through Bayesian updating, where previous plan distributions serve as priors for new observations, thereby achieving adaptive benefits similar to closed-loop methods while maintaining computational tractability.",
                "D. The primary innovation enabling LAP's performance lies in its advanced object-robot proportional mapping, which directly translates human kinematic-dynamic states into efficient, pre-compiled robot trajectories suitable for any platform.",
                "E. LAP achieves its balance by exclusively employing a sophisticated form of behavior cloning derived from human demonstrations, which then fine-tunes pre-defined joint torques in real-time using only the most current ZED2 stereo camera input."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Our approach incrementally updates the latent plan through Bayesian inference, treating previous distributions as prior beliefs. This maintains the adaptive benefits of closed-loop planning while preserving computational efficiency, essentially performing online learning of the latent plan as new observations arrive."
            ],
            "img_path": "2505.03077/data_regeneration_concept.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.02418",
        "img_path": "2505.02418/x1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Collaborative Reasoning in Large Language Models for Improved Text Summarization",
                "B. Integrating Human Feedback in Neural Networks for Advanced Document Analysis",
                "C. Adaptive Knowledge Retrieval Techniques in Human-AI Interactive Systems",
                "D. Optimizing Multi-Agent Communication in Language Models for Enhanced Information Extraction",
                "E. SymbioticRAG: Enhancing Document Intelligence Through Human-LLM Symbiotic Collaboration"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "SymbioticRAG: Enhancing Document Intelligence Through Human-LLM Symbiotic Collaboration"
            ],
            "img_path": "2505.02418/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the explicitly stated implementation scope and the defined set of key characteristics that constitute a SymbioticRAG system, how many of these distinct key characteristics are described as being the primary focus of implementation within the work presented?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 3",
                "E. 4"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2505.02418/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03186",
        "img_path": "2505.03186/arch.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Detao Bai",
                "B. Dongbin Xiu",
                "C. Zhiheng Ma",
                "D. Xihan Wei",
                "E. Liefeng Bo"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Detao Bai"
            ],
            "img_path": "2505.03186/arch.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value represents the quantity of distinct frequency bands captured in the initial Mel-spectrogram representation of raw audio input to the Audio Encoder?",
            "options": [
                "A. 4",
                "B. 2",
                "C. 80",
                "D. 3",
                "E. 223"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "80"
            ],
            "img_path": "2505.03186/arch.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03134",
        "img_path": "2505.03134/diagram_paper.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Nicola Tosi",
                "B. Sangmo Cheon",
                "C. Sajjad Rezvani Boroujeni",
                "D. Hossein Abedi",
                "E. Tom Bush"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Sajjad Rezvani Boroujeni"
            ],
            "img_path": "2505.03134/diagram_paper.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value represents the percentage point increase in the defective class's proportion of the total dataset, an outcome achieved through the application of Denoising Diffusion Probabilistic Models for synthetic data generation, which was subsequently employed in training Convolutional Neural Network architectures including one specifically identified as having approximately 25.6 million parameters?",
            "options": [
                "A. 15",
                "B. 13.8",
                "C. 60",
                "D. 23.2",
                "E. 37.0"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "13.8"
            ],
            "img_path": "2505.03134/diagram_paper.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03165",
        "img_path": "2505.03165/x2.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Meng Yee",
                "B. Abhinav Goel",
                "C. James C. Davis",
                "D. George K. Thiruvathukal",
                "E. Nikita Ravi"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Nikita Ravi"
            ],
            "img_path": "2505.03165/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, by what numerical factor does the number of trainable parameters in the contemporary GPT-4 model, as cited, exceed that of the earlier AlexNet model, a disparity that inherently supports the authors' decision to use a less resource-intensive model like TRUNK for their reproducibility case study?",
            "options": [
                "A. 5",
                "B. 1,000",
                "C. 10,000",
                "D. 100,000",
                "E. 1,000,000"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "100000"
            ],
            "img_path": "2505.03165/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03159",
        "img_path": "2505.03159/framework.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Comparative Analysis of Adaptive Control Strategies for Mobile Robot Navigation",
                "B. Optimization Techniques for PID Controller Design in Autonomous Systems",
                "C. Framework for Real-Time Tuning of Exploration Algorithms in Robotic Path Planning",
                "D. Impact of Initial Conditions on Reinforcement Learning Approaches in Mobile Robotics",
                "E. Systematic Evaluation of Initial States and Exploration-Exploitation Strategies in PID Auto-Tuning: A Framework-Driven Approach Applied on Mobile Robots"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Systematic Evaluation of Initial States and Exploration-Exploitation Strategies in PID Auto-Tuning: A Framework-Driven Approach Applied on Mobile Robots"
            ],
            "img_path": "2505.03159/framework.png"
        },
        "level2_qa": {
            "question": "In this paper, what was the best settling time, in milliseconds, achieved by Bayesian Optimization for the differential drive robot using Initial State 1 and a Balanced exploration-exploitation level, where settling time was the primary minimization objective contingent on meeting overshoot and rise time constraints?",
            "options": [
                "A. 1406",
                "B. 24",
                "C. 90",
                "D. 1181",
                "E. 1118"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "1118"
            ],
            "img_path": "2505.03159/framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03214",
        "img_path": "2505.03214/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Sirui Li",
                "B. Qiang Sun",
                "C. Tingting Bi",
                "D. Du Huynh",
                "E. Mark Reynolds"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Qiang Sun"
            ],
            "img_path": "2505.03214/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific number of iterative cycles, detailed in the experimental validation, through which the 'Progressive Models' were developed and demonstrated consistent performance gains, thereby validating the core 'Human-in-the-Spiral' methodology?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 41",
                "E. 75"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.03214/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03117",
        "img_path": "2505.03117/miro_study1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Evaluating Human Factors in AI-Based Conflict Resolution Advisory Systems for Air Traffic Control",
                "B. Do ATCOs Need Explanations, and Why? Towards ATCO-Centered Explainable AI for Conflict Resolution Advisories",
                "C. Improving Conflict Detection Algorithms through User-Centered Design in Air Traffic Management",
                "D. Towards Adaptive AI Models for Enhancing Decision Support in Air Traffic Control Operations",
                "E. The Role of Transparent Algorithms in Enhancing Situational Awareness for Air Traffic Controllers"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Do ATCOs Need Explanations, and Why? Towards ATCO-Centered Explainable AI for Conflict Resolution Advisories"
            ],
            "img_path": "2505.03117/miro_study1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the number of ATCO participants who indicated a need for explanations for the operational goal that garnered the highest level of agreement for this necessity?",
            "options": [
                "A. 6",
                "B. 7",
                "C. 8",
                "D. 11",
                "E. 3"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "8"
            ],
            "img_path": "2505.03117/miro_study1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03250",
        "img_path": "2505.03250/x1.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Parul R. Raghuvanshi",
                "B. John D. Budai",
                "C. Dipanshu Bansal",
                "D. Lars Bocklage",
                "E. George Yumnam"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "George Yumnam"
            ],
            "img_path": "2505.03250/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value, in μB, represents the magnetic moment per Ru atom initially estimated from early single-crystal neutron diffraction data that indicated a magnetic reflection, a finding that subsequently contributed to the debate over RuO2's magnetic properties before being challenged by later reinterpretations and the current study's findings?",
            "options": [
                "A. 0.00",
                "B. 0.05",
                "C. 0.23",
                "D. 0.7",
                "E. <0.001"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "0.05"
            ],
            "img_path": "2505.03250/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03185",
        "img_path": "2505.03185/closed-loop_overview.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Adaptive Monitoring Systems for Dietary Assessment: An Overview of Real-Time Feedback Mechanisms",
                "B. Integrating Wearable Technologies and Machine Learning for Enhanced Nutritional Behavior Analysis",
                "C. Exploring Open-Loop Frameworks in Eating Habit Modification through Sensor Data Fusion",
                "D. Behavioral Sensing and Intervention Paradigm: A Review of Closed-Loop Approaches for Ingestion Health",
                "E. Advances in Smart Intervention Strategies for Metabolic Health Using Continuous Behavioral Tracking"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Behavioral Sensing and Intervention Paradigm: A Review of Closed-Loop Approaches for Ingestion Health"
            ],
            "img_path": "2505.03185/closed-loop_overview.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific quantity of studies, focused on leveraging sensor-enabled or interaction-mediated approaches to influence eating behavior, that were systematically reviewed to identify prevailing patterns, evaluate methods, and uncover critical gaps, thereby informing the proposed behavioral closed-loop paradigm and design insights for future interventions?",
            "options": [
                "A. 3",
                "B. 2",
                "C. 5",
                "D. 136",
                "E. 1"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "136"
            ],
            "img_path": "2505.03185/closed-loop_overview.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03019",
        "img_path": "2505.03019/x3.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Evaluating Language Model Generalization via Output Variation Metrics",
                "B. Analyzing Input Sensitivity in Large Language Models for Robustness Assessment",
                "C. Assessing Neural Network Overfitting through Gradient Perturbation Techniques",
                "D. Disentangling Generalization and Overfitting in LLMs Using Data Augmentation Strategies",
                "E. Memorization or Interpolation ? Detecting LLM Memorization through Input Perturbation Analysis"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Memorization or Interpolation ? Detecting LLM Memorization through Input Perturbation Analysis"
            ],
            "img_path": "2505.03019/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence best describes the fundamental condition under which the PEARL framework, by implementing the Perturbation Sensitivity Hypothesis (PSH), infers that an input has been memorized by an LLM, considering its reliance on performance differentials between perturbed and reference outputs and its aim for statistically significant results?",
            "options": [
                "A. An input is judged as memorized if the LLM's output for that input is an exact verbatim reproduction of a known sequence from its training dataset, a phenomenon PEARL is specifically designed to identify without needing perturbations.",
                "B. PEARL infers memorization when an LLM shows an unusually high internal confidence score for an output derived from an unperturbed input, aligning with the PSH's tenet that memorized items are processed with greater certainty.",
                "C. The PEARL framework infers memorization when systematic input perturbations lead to a statistically significant degradation in the LLM's task performance relative to a reference output, thereby validating the PSH.",
                "D. Memorization is determined primarily by the LLM's inability to process inputs subjected to bit-flip perturbations, indicating a failure to generalize beyond the exact binary representation seen during training.",
                "E. PEARL concludes an input is memorized if prompting the LLM multiple times with slightly varied, perturbed versions of the input consistently produces identical, albeit potentially degraded, outputs, demonstrating robust recall."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The PEARL framework infers memorization when systematic input perturbations lead to a statistically significant degradation in the LLM's task performance relative to a reference output, thereby validating the PSH."
            ],
            "img_path": "2505.03019/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03136",
        "img_path": "2505.03136/x1.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Zikang Leng",
                "B. Dana McKay",
                "C. Jiaman He",
                "D. Johanne R. Trippas",
                "E. Damiano Spina"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Jiaman He"
            ],
            "img_path": "2505.03136/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what synthesized characteristic defines the eye-tracking data analysis phase aimed at inferring topic familiarity and query specificity, considering both the temporal window of data collection relative to task components and the type of user input processed?",
            "options": [
                "A. The analysis relies on eye-tracking data captured exclusively during the query formulation phase after the backstory, using both written and voice inputs.",
                "B. The core inference is based on eye-tracking data (pupil size and gaze) collected *before* the backstory presentation, and the study ensures data consistency by exclusively analyzing *written* queries.",
                "C. The study uses comprehensive eye-tracking data, including fixations during the backstory phase, and integrates contextual information from voice queries to enhance prediction accuracy.",
                "D. Topic familiarity and query specificity are inferred using eye gaze fixations from all experimental phases, including the period when participants rated familiarity with topic titles using a 5-point scale.",
                "E. The primary analysis focuses on pupil dilation patterns during the interaction with query suggestions, leveraging the InformationNeeds dataset to provide contextual cues for both written and spoken queries."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The core inference is based on eye-tracking data (pupil size and gaze) collected *before* the backstory presentation, and the study ensures data consistency by exclusively analyzing *written* queries."
            ],
            "img_path": "2505.03136/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03139",
        "img_path": "2505.03139/x2.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Distributed Neural Networks for Real-Time Sensor Data Processing",
                "B. Adaptive Machine Learning Frameworks for Smart City Infrastructure",
                "C. Scalable Cloud-Based Models for Intelligent IoT Systems",
                "D. Federated Learning Approaches in Autonomous Edge Computing",
                "E. Edge Large AI Models: Collaborative Deployment and IoT Applications"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Edge Large AI Models: Collaborative Deployment and IoT Applications"
            ],
            "img_path": "2505.03139/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement most accurately synthesizes the core operational distinctions of the proposed Federated Unlearning (FU) framework for edge LAMs concerning update management and knowledge preservation, particularly when contrasted with both conventional unlearning methods and typical federated learning aggregation strategies?",
            "options": [
                "A. The FU framework exclusively processes gradients from opting-out devices, projecting them orthogonally to ensure removal, and then broadcasts a revised global model to all devices, similar to conventional FL but with an added unlearning step.",
                "B. The FU framework reverts edge LAMs to a historical state for opting-out devices while using unicast personalized updates derived from all devices to maintain the global model's utility, thereby combining conventional unlearning with advanced FL communication.",
                "C. The FU framework achieves unlearning by projecting all participating devices' gradients onto an orthogonal subspace to nullify unwanted data influence and then aggregates these modified gradients to form personalized unicast updates, focusing solely on data removal without explicit mechanisms for preserving retained knowledge.",
                "D. The FU framework decouples unlearning from knowledge preservation by orthogonally projecting gradients before dissemination, utilizes information from all devices to generate personalized unicast updates for efficient adaptation, and avoids broadcasting a single global model unlike conventional FL.",
                "E. The FU framework primarily relies on a bounded loss function and differential privacy to remove data influence, using orthogonal projection merely as a secondary mechanism to refine personalized unicast updates derived only from opting-out devices."
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "The FU framework decouples unlearning from knowledge preservation by orthogonally projecting gradients before dissemination, utilizes information from all devices to generate personalized unicast updates for efficient adaptation, and avoids broadcasting a single global model unlike conventional FL."
            ],
            "img_path": "2505.03139/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03149",
        "img_path": "2505.03149/x1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Adaptive Filtering Techniques for Enhanced Cardiac MRI Reconstruction",
                "B. Spatiotemporal Analysis of Cardiac Motion Using Deep Learning Methods",
                "C. Motion-compensated cardiac MRI using low-rank diffeomorphic flow (DMoCo)",
                "D. Non-rigid Registration Approaches for Dynamic Heart Imaging",
                "E. Low-rank Matrix Completion for Accelerated Cardiac MRI Acquisition"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Motion-compensated cardiac MRI using low-rank diffeomorphic flow (DMoCo)"
            ],
            "img_path": "2505.03149/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what percentage of the Field of View (FOV) represented the decrease in the inner circle's radius within the 2D annulus phantom simulation used for comparing low-rank approximations?",
            "options": [
                "A. 5",
                "B. 10",
                "C. 14",
                "D. 24",
                "E. 60"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "14"
            ],
            "img_path": "2505.03149/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03174",
        "img_path": "2505.03174/Screenshot.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Sensor Fusion Techniques for Enhancing Autonomous Vehicle Path Planning through Vision-Language Models",
                "B. Leveraging Natural Language Processing to Improve Human-Machine Interaction in Autonomous Driving Systems",
                "C. A Framework for Real-Time Traffic Data Analysis Using GPS and Computer Vision in Urban Environments",
                "D. Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets",
                "E. Optimizing Autonomous Vehicle Navigation with Multimodal Data Integration and Reinforcement Learning Approaches"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets"
            ],
            "img_path": "2505.03174/Screenshot.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct combinations of navigational application sources and characterized GPS voice instruction classifications demonstrated as manageable by the ADVLAT-Engine during its described pilot data collection?",
            "options": [
                "A. 3",
                "B. 8",
                "C. 11",
                "D. 24",
                "E. 2"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "24"
            ],
            "img_path": "2505.03174/Screenshot.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03141",
        "img_path": "2505.03141/figure_09a.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Ajit Singh",
                "B. Alaxender Panchal",
                "C. Yogesh Chandra Joshi",
                "D. Vishal Joshi",
                "E. Abhijit Chakraborty"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Alaxender Panchal"
            ],
            "img_path": "2505.03141/figure_09a.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the reported relative temperature of the spot on J1433's primary component, used in the light curve model that addressed the observation of its secondary maxima being slightly brighter than its primary maxima?",
            "options": [
                "A. 1.15",
                "B. 0.81",
                "C. 1.10",
                "D. 0.88",
                "E. 1.13"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "0.88"
            ],
            "img_path": "2505.03141/figure_09a.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03181",
        "img_path": "2505.03181/VLMQ_Fig_1_PNG.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Multimodal Reinforcement Learning for Autonomous Visual Navigation",
                "B. Optimizing Cross-Modal Embeddings in Language-Driven Robotics",
                "C. VLM Q-Learning: Aligning Vision-Language Models for Interactive Decision-Making",
                "D. Deep Policy Networks for Visual Question Answering Agents",
                "E. Hierarchical Decision Processes in Vision-Guided Interactive Systems"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "VLM Q-Learning: Aligning Vision-Language Models for Interactive Decision-Making"
            ],
            "img_path": "2505.03181/VLMQ_Fig_1_PNG.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct multi-modal agent domains were used to evaluate the off-policy reinforcement learning technique applied to open-weight vision-language models?",
            "options": [
                "A. One",
                "B. Two",
                "C. Three",
                "D. Four",
                "E. Five"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "three"
            ],
            "img_path": "2505.03181/VLMQ_Fig_1_PNG.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03146",
        "img_path": "2505.03146/figure2_explosion.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Fei Han",
                "B. Pengming Guo",
                "C. Hao Chen",
                "D. Weikun Li",
                "E. Jingbo Ren"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Fei Han"
            ],
            "img_path": "2505.03146/figure2_explosion.png"
        },
        "level2_qa": {
            "question": "In this paper, a single number, show the research data for the percentage improvement in positional accuracy achieved by the FED-LSTM model over the EF model in the straight-line movement task.",
            "options": [
                "A. 8.7",
                "B. 47.1",
                "C. 47.6",
                "D. 0.17",
                "E. 0.09"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "47.1"
            ],
            "img_path": "2505.03146/figure2_explosion.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03257",
        "img_path": "2505.03257/x7.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Adaptive Neural Network Strategies for Autonomous Navigation in Disaster Response Robots",
                "B. Decentralized Reinforcement Learning Frameworks for Urban Search-and-Rescue Operations",
                "C. Hierarchical Swarm Intelligence Approaches for Cooperative Environmental Monitoring",
                "D. Fuzzy Logic-Based Path Planning Techniques for Autonomous Underwater Vehicles",
                "E. Model Predictive Fuzzy Control: A Hierarchical Multi-Agent Control Architecture for Outdoor Search-and-Rescue Robots"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Model Predictive Fuzzy Control: A Hierarchical Multi-Agent Control Architecture for Outdoor Search-and-Rescue Robots"
            ],
            "img_path": "2505.03257/x7.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the exact sampling time (in discrete time framework) associated with the higher layer (MPC) controller that determines when parameter tuning for the local FLC controllers is performed within the MPFC architecture?",
            "options": [
                "A. T^{rob}",
                "B. T^{ctrl}",
                "C. k^{rob}",
                "D. k^{ctrl}",
                "E. T^{init}"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "MPFC (see Figure5) operates based on a discrete time framework, with a sampling time T^{ctrl} and the corresponding control time step counter k^{ctrl}."
            ],
            "img_path": "2505.03257/x7.png",
            "question_type": "generated_hard_inferential_v2"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03220",
        "img_path": "2505.03220/x1.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Cross-Domain Contrastive Learning for Hyperspectral Image Segmentation Using Spatial and Spectral Features",
                "B. Frequency-Based Augmentation Techniques for Enhanced Self-Supervised Hyperspectral Image Classification",
                "C. Spatial and Temporal Domain Fusion for Robust Pretraining of Hyperspectral Sensors",
                "D. Unsupervised Feature Extraction from Hyperspectral Data via Multi-Domain Attention Mechanisms",
                "E. Dual-Domain Masked Image Modeling: A Self-Supervised Pretraining Strategy Using Spatial and Frequency Domain Masking for Hyperspectral Data"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Dual-Domain Masked Image Modeling: A Self-Supervised Pretraining Strategy Using Spatial and Frequency Domain Masking for Hyperspectral Data"
            ],
            "img_path": "2505.03220/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence accurately describes the complete sequence of transformations applied to an individual spatial patch, once defined from the HSI cube, to prepare it as an input token for the Vision Transformer's multi-head self-attention mechanism, including its dimensional characteristics and embedding processes?",
            "options": [
                "A. An individual spatial patch, defined as a B-dimensional complete spectral vector (y_i ∈ ℝ^B) derived from a non-overlapping spatial division, is linearly projected into a d-dimensional embedding space by a matrix E, and subsequently summed with a d-dimensional positional embedding vector (e_i) before this composite representation is processed by the transformer's self-attention.",
                "B. An S×S spatial region from the input HSI cube, representing a patch with B spectral bands, is directly passed to the multi-head self-attention mechanism after only the addition of a B-dimensional positional embedding to signify its original spatial coordinates.",
                "C. A spectral vector patch, initially B-dimensional, is first enhanced by adding a d-dimensional positional embedding, and then this combined B+d dimensional vector is projected by a linear layer E into the transformer's required input dimensionality for self-attention.",
                "D. Multiple B-dimensional spectral vectors from adjacent spatial locations are first averaged into a single d-dimensional representative patch, which then has a positional embedding added before being input to the transformer network's self-attention layers.",
                "E. The input HSI cube is treated as a flat sequence of B-dimensional spectral pixels (without spatial patching), each of which is independently projected to a d-dimensional embedding and then combined with a corresponding d-dimensional positional vector for transformer processing."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "An individual spatial patch, defined as a B-dimensional complete spectral vector (y_i ∈ ℝ^B) derived from a non-overlapping spatial division, is linearly projected into a d-dimensional embedding space by a matrix E, and subsequently summed with a d-dimensional positional embedding vector (e_i) before this composite representation is processed by the transformer's self-attention."
            ],
            "img_path": "2505.03220/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03265",
        "img_path": "2505.03265/Synthline.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Synthline: Leveraging Machine Learning for Automated Requirements Validation in Software Engineering",
                "B. A Framework for Generating Synthetic User Stories in Agile Development Environments",
                "C. Applying Large Language Models to Enhance Traceability in Requirements Engineering Processes",
                "D. Product Line Strategies for Automated Test Case Generation Using Natural Language Processing",
                "E. Synthline: A Product Line Approach for Synthetic Requirements Engineering Data Generation using Large Language Models"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Synthline: A Product Line Approach for Synthetic Requirements Engineering Data Generation using Large Language Models"
            ],
            "img_path": "2505.03265/Synthline.png"
        },
        "level2_qa": {
            "question": "In this paper, by quantifying the performance enhancement specifically for precision, what numerical value represents the peak improvement achieved when the limitations of relying solely on authentic datasets are mitigated by incorporating outputs from Synthline's LLM-driven generation process aimed at classification use cases?",
            "options": [
                "A. 2",
                "B. 4",
                "C. 85",
                "D. 100",
                "E. 50"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "85"
            ],
            "img_path": "2505.03265/Synthline.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03242",
        "img_path": "2505.03242/x1.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Interpreting Visual Inputs: Enhancing Vision Models with Abstract Concepts",
                "B. Bridging Modalities: Mapping Abstract Linguistic Representations to Visual Data",
                "C. Seeing the Abstract: Translating the Abstract Language for Vision Language Models",
                "D. Towards Unified Understanding: Integrating Abstract Semantics into Vision-Language Systems",
                "E. Decoding Abstract Descriptions for Improved Multimodal Model Performance"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Seeing the Abstract: Translating the Abstract Language for Vision Language Models"
            ],
            "img_path": "2505.03242/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what initial transformation is applied to an abstract-oriented query during ACT's inference phase to make it more amenable to VLM processing, prior to the application of learned latent space directional shifts?",
            "options": [
                "A. Dimensionality-reduction of the query representation",
                "B. Direct latent-space-alignment with pre-computed concrete centroids",
                "C. LLM-based-rephrasing into a more concrete-oriented expression",
                "D. Abstract-attribute-quantification using fashion lexicon statistics",
                "E. Concrete-caption-generation via an image captioning model"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "LLM-based-rephrasing into a more concrete-oriented expression"
            ],
            "img_path": "2505.03242/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03273",
        "img_path": "2505.03273/x2.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Enhancing Speech Recognition with Multimodal Audio-Language Fusion Models",
                "B. SepALM: Audio Language Models Are Error Correctors for Robust Speech Separation",
                "C. Robust Speaker Identification Using Joint Audio and Text Embeddings",
                "D. Adaptive Noise Suppression Techniques for Improved Audio Language Processing",
                "E. Leveraging Language Models for Context-Aware Audio Signal Enhancement"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "SepALM: Audio Language Models Are Error Correctors for Robust Speech Separation"
            ],
            "img_path": "2505.03273/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the identified failing of cascaded ASR-LLM systems to produce contextually accurate outputs despite grammatical coherence due to the LLM's informational constraints, which aspect of SepALM's corrector and synthesizer pipeline is most critical for surmounting this specific deficiency?",
            "options": [
                "A. The synthesizer's independent ability to infer original speech context from the corrected textual transcriptions alone, effectively compensating for any residual inaccuracies from the correction phase.",
                "B. The ALM's capacity, augmented by CoT prompting and knowledge distillation, to perform more profound contextual reasoning and error correction on the textual representation before re-synthesis.",
                "C. The choice of the text domain for error correction, whose inherent low resolution systematically filters out complex acoustic cues that typically lead to contextual misinterpretations by LLMs in cascaded systems.",
                "D. The complete exclusion of ASR-generated N-best lists as input to the ALM, which instead directly processes time-frequency representations of the separated speech to derive corrected transcriptions.",
                "E. The aligner component's function of retroactively adjusting the synthesized speech to match the contextual nuances of the original mixed signal, thereby correcting any text-based contextual errors."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The ALM's capacity, augmented by CoT prompting and knowledge distillation, to perform more profound contextual reasoning and error correction on the textual representation before re-synthesis."
            ],
            "img_path": "2505.03273/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03285",
        "img_path": "2505.03285/x1.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Hard Inference Models for Knowledge Graph Expansion",
                "B. Soft Reasoning Paths for Knowledge Graph Completion",
                "C. Probabilistic Approaches to Semantic Network Completion",
                "D. Structured Reasoning Techniques in Ontology Alignment",
                "E. Neural Methods for Entity Resolution in Knowledge Bases"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Soft Reasoning Paths for Knowledge Graph Completion"
            ],
            "img_path": "2505.03285/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, describe the specific mechanism through which 'soft reasoning paths' are designed to ensure model stability and predictive accuracy when computationally affordable reasoning paths are absent, particularly differentiating this mechanism from the broader generalization benefits leveraged from prompt tuning.",
            "options": [
                "A. They facilitate the direct generation of alternative, complete reasoning paths by leveraging general data patterns learned through prompt tuning, effectively replacing any missing connections.",
                "B. They enable the hierarchical ranking strategy to assign higher confidence to entities for which prompt tuning has identified strong general relational patterns, even if direct paths are missing.",
                "C. By consisting of a learnable latent path embedding concatenated to each relation, which, through alignment with actual reasoning paths, learns a generalized path representation for that relation, thereby offering a reliable predictive signal for the relation itself when direct entity-to-entity paths are unavailable.",
                "D. They primarily function by augmenting the multi-type positive samples used in contrastive learning, thereby training the model to better infer relationships from incomplete path information, supported by prompt tuning's general representational power.",
                "E. They act as a specialized form of prompt, integrated into the input for the pre-trained language model, to guide its attention towards learning robust relational features that are independent of explicit path structures."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The paper introduces soft reasoning paths to make the proposed algorithm more stable against missing path circumstances; these are formed by a specific learnable latent path embedding concatenated to each relation, and by aligning these soft paths with reasoning paths, the learnable embedding is guided to learn a generalized path representation of the corresponding relation."
            ],
            "img_path": "2505.03285/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03228",
        "img_path": "2505.03228/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Hierarchical Feature Integration Using TDNN for Robust Speaker Identification",
                "B. Depth-Wise Separable Convolutions in Neural Networks for Acoustic Scene Classification",
                "C. Multi-Level Feature Extraction and Fusion in Temporal Neural Models for Voice Authentication",
                "D. Improving Speech Recognition Accuracy with Multi-Granularity Temporal Convolutional Networks",
                "E. MGFF-TDNN: A Multi-Granularity Feature Fusion TDNN Model with Depth-Wise Separable Module for Speaker Verification"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "MGFF-TDNN: A Multi-Granularity Feature Fusion TDNN Model with Depth-Wise Separable Module for Speaker Verification"
            ],
            "img_path": "2505.03228/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific numerical value is explicitly designated for the expansion factor `t` within the Inverted Residual Blocks of the front-end two-dimensional depthwise separable convolution module, a factor critical for enabling initial high-dimensional feature extraction by increasing channel dimensionality before a subsequent reduction step ensures parameter and computational efficiency?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 6",
                "D. 5",
                "E. 10"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "6"
            ],
            "img_path": "2505.03228/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03229",
        "img_path": "2505.03229/x2.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Advances in Semantic Parsing: Techniques and Applications",
                "B. A Comprehensive Review of Neural Language Representations",
                "C. Exploring Graph-Based Models for Natural Language Understanding",
                "D. Trends and Challenges in Computational Semantic Analysis",
                "E. Survey of Abstract Meaning Representation: Then, Now, Future"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Survey of Abstract Meaning Representation: Then, Now, Future"
            ],
            "img_path": "2505.03229/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which evaluation metric, despite its derivation from an established scoring methodology, was demonstrated by Opitz et al. (2020) to contravene core evaluation tenets, such as the principle of symmetry, that are upheld by SMatch?",
            "options": [
                "A. SMatch, as its widespread adoption establishes it as the primary metric whose core tenets are sometimes challenged by newer, specialized metrics.",
                "B. WWLK, because its initial formulation by Opitz et al. (2021) did not account for edge labels, thereby contravening the tenet of complete graph representation.",
                "C. GrAPES, because its granular approach, while detailed, was shown by Opitz et al. (2020) to potentially misrepresent overall semantic equivalence compared to SMatch.",
                "D. AMRSim, as its GNN-based approach using BERT, while advanced, has not yet been benchmarked against the core evaluation tenets upheld by traditional metrics like SMatch.",
                "E. SemBleu, as its foundation on BLEU led to linearization that Opitz et al. (2020) identified as violating key evaluation principles, including symmetry, which SMatch respects."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "SemBleu"
            ],
            "img_path": "2505.03229/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03315",
        "img_path": "2505.03315/x6.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Jehwan Choi",
                "B. Kwanho Kim",
                "C. Seongmin Kim",
                "D. Kanghyun Jo",
                "E. Duy-Linh Nguyen"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Kanghyun Jo"
            ],
            "img_path": "2505.03315/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the research team's focus on developing intelligent lightweight models for efficient, real-time inference to address key Artificial Behavior Intelligence (ABI) deployment challenges, what specific performance figure, associated with a system exemplifying progress in model efficiency for a core ABI component, is cited as operating effectively on a CPU?",
            "options": [
                "A. 22",
                "B. 20",
                "C. 76",
                "D. 3",
                "E. 8"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "76"
            ],
            "img_path": "2505.03315/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03359",
        "img_path": "2505.03359/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Neural Network Approaches for Reducing Cultural Bias in Text-based Emotion Recognition",
                "B. Enhancing Mental Health Assessment through Multimodal Speech and Facial Expression Analysis",
                "C. Transfer Learning Strategies for Cross-lingual Speech Emotion Classification",
                "D. Domain Adversarial Training for Mitigating Gender Bias in Speech-based Mental Health Detection",
                "E. Evaluating the Impact of Speaker Age on Automated Stress Detection Systems"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Domain Adversarial Training for Mitigating Gender Bias in Speech-based Mental Health Detection"
            ],
            "img_path": "2505.03359/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the initial numerical value assigned to the hyperparameter that directly governs the strength of the domain adaptation mechanism, which is specifically introduced to address demographic disparities in AI-driven mental health assessment, during the model's learning phase?",
            "options": [
                "A. 13.29",
                "B. 0.5",
                "C. 50",
                "D. 0.0096",
                "E. 200"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "0.0096"
            ],
            "img_path": "2505.03359/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03310",
        "img_path": "2505.03310/x1.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Adaptive 3D Mesh Reconstruction Using Hybrid Splatting Techniques",
                "B. Efficient Volumetric Rendering with Hierarchical Gaussian Models",
                "C. 3D Gaussian Splatting Data Compression with Mixture of Priors",
                "D. Probabilistic Priors for Enhanced Point Cloud Denoising in 3D Scans",
                "E. Multi-Scale Surface Approximation via Mixture-Based Point Distribution"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3D Gaussian Splatting Data Compression with Mixture of Priors"
            ],
            "img_path": "2505.03310/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of benchmark datasets across which the proposed 3DGS data compression framework is demonstrated to achieve state-of-the-art performance?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2505.03310/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03387",
        "img_path": "2505.03387/bootstrap_analysis_schema.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Enhancing Biomarker Discovery through Multi-Omics Data Integration and Dimensionality Reduction",
                "B. Evaluating Machine Learning Models for Predictive Analysis in Genomic Data",
                "C. Improving Omics-Based Classification: The Role of Feature Selection and Synthetic Data Generation",
                "D. Advances in Synthetic Data Methods for High-Dimensional Biological Datasets",
                "E. The Impact of Data Augmentation on Cancer Subtype Prediction Using Transcriptomics"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Improving Omics-Based Classification: The Role of Feature Selection and Synthetic Data Generation"
            ],
            "img_path": "2505.03387/bootstrap_analysis_schema.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the description of the E-MTAB-8026 dataset, if the samples not classified as Lung Cancer (LCa) were equally distributed among the other three explicitly mentioned patient categories (non-tumor lung diseases, other diseases, and healthy controls), what would be the approximate number of samples per each of these non-LCa categories?",
            "options": [
                "A. 606",
                "B. 2534",
                "C. 845",
                "D. 1047",
                "E. 785"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "845"
            ],
            "img_path": "2505.03387/bootstrap_analysis_schema.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03203",
        "img_path": "2505.03203/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Optimizing Visual-Semantic Embeddings through Adaptive Noise Scheduling in Generative Models",
                "B. Fine-Grained Control of Masking Techniques for Enhanced Image Generation in Diffusion Frameworks",
                "C. Noise Reduction Strategies for Improved Text-to-Image Synthesis Using Diffusion-Based Architectures",
                "D. PiCo: Enhancing Text-Image Alignment with Improved Noise Selection and Precise Mask Control in Diffusion Models",
                "E. A Novel Approach to Cross-Modal Representation Learning with Dynamic Mask Application in Diffusion Models"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "PiCo: Enhancing Text-Image Alignment with Improved Noise Selection and Precise Mask Control in Diffusion Models"
            ],
            "img_path": "2505.03203/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence identifies the specific emergent problem that persists and undermines the reliability of the controlling mask when the referring mask control module employs only the concept mask for its primary function of enhancing concept binding, even after suitable initial noise has been selected?",
            "options": [
                "A. In column 2, the use of the concept mask significantly improves the binding, presenting desired concepts.",
                "B. However, the image can be observed with a small green cup on the left side, which can be caused by unexpected noise activations on the cross-attention maps.",
                "C. Relying solely on the ITM score is inaccurate in measuring the existence of fine-grained visual concepts, while using only the concept score leads to the problem of quality degradation (e.g., split objects).",
                "D. In column 3, the sole use of the exclusive mask shows limited improvement in the generated image, indicating the importance of the concept mask in guiding the cross-attention interaction.",
                "E. With conflict elimination in the top row, two masks of concepts do not overlap and produce a more reasonable generation result."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "However, the image can be observed with a small green cup on the left side, which can be caused by unexpected noise activations on the cross-attention maps."
            ],
            "img_path": "2505.03203/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03284",
        "img_path": "2505.03284/x1.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Julie Stephany Berrio",
                "B. Mao Shan",
                "C. Yaoqi Huang",
                "D. Zhenxing Ming",
                "E. Hongyu Lyu"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Zhenxing Ming"
            ],
            "img_path": "2505.03284/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single word encapsulates the type of environmental characteristic whose enhanced preservation is a primary research result of employing cylindrical coordinates in the OccCylindrical framework?",
            "options": [
                "A. Density",
                "B. Consistency",
                "C. Detail",
                "D. Modality",
                "E. Sparsity"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "detail"
            ],
            "img_path": "2505.03284/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03209",
        "img_path": "2505.03209/x3.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. DYSTIL: Dynamic Strategy Induction with Large Language Models for Reinforcement Learning",
                "B. Adaptive Policy Synthesis Using Multi-Modal Neural Networks in Reinforcement Learning",
                "C. Hierarchical Task Decomposition with Deep Neural Architectures for Autonomous Agents",
                "D. Contextual Reward Shaping Through Transformer-Based Models in Sequential Decision Making",
                "E. Meta-Learning Multi-Agent Coordination Strategies via Large-Scale Language Model Integration"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "DYSTIL: Dynamic Strategy Induction with Large Language Models for Reinforcement Learning"
            ],
            "img_path": "2505.03209/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, when evaluating DYSTIL's performance in challenging RL environments like Minigrid and BabyAI, what precise numerical figure represents its outperformance over state-of-the-art baseline methods specifically concerning the average success rate, distinct from other benefits like improved sample efficiency?",
            "options": [
                "A. 17.75, representing the boost in sample efficiency compared to methods relying solely on behavioral cloning.",
                "B. A value derived from the reduction in training iterations due to the core reasoning LLM, approximately 15-20%.",
                "C. 17.75, indicating the percentage increase in average success rate over state-of-the-art baseline methods.",
                "D. No explicit percentage for average success rate is provided; the paper emphasizes a qualitative improvement in model interpretability and generalization primarily.",
                "E. Approximately 8.0, reflecting the parameter size advantage (in billions) of the strategy-generating LLM over the core reasoning LLM, correlated to performance gains."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "17.75"
            ],
            "img_path": "2505.03209/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03425",
        "img_path": "2505.03425/x3.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Optimizing Blackbox Fuzzing with Reinforcement Learning Techniques",
                "B. Automated Vulnerability Detection Using Symbolic Execution and Neural Networks",
                "C. Hybrid Static and Dynamic Analysis for Efficient Software Testing",
                "D. Enhancing Security Testing through Probabilistic Model Generation",
                "E. Directed Greybox Fuzzing via Large Language Model"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Directed Greybox Fuzzing via Large Language Model"
            ],
            "img_path": "2505.03425/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, what single number represents the total count of distinct vulnerabilities on which HGFuzzer demonstrated positive results, encompassing both those successfully triggered from the initial evaluation set of known vulnerabilities and those newly discovered as previously unknown?",
            "options": [
                "A. 17",
                "B. 9",
                "C. 20",
                "D. 26",
                "E. 29"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "26"
            ],
            "img_path": "2505.03425/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03385",
        "img_path": "2505.03385/flowchart1.2.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Solar Flare Forecast: A Comparative Analysis of Machine Learning Algorithms for Solar Flare Class Prediction",
                "B. Evaluating Deep Learning Techniques for Sunspot Activity Recognition",
                "C. Predictive Modelling of Coronal Mass Ejections Using Statistical Methods",
                "D. Comparative Study of Neural Networks for Space Weather Event Detection",
                "E. Machine Learning Approaches to Solar Wind Parameter Estimation"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Solar Flare Forecast: A Comparative Analysis of Machine Learning Algorithms for Solar Flare Class Prediction"
            ],
            "img_path": "2505.03385/flowchart1.2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the methodology for constructing each of the 100 balanced multiclass classification datasets, what is the specific quantity of C-class active region samples from the original imbalanced pool that was necessarily excluded during the creation of any *one* such balanced dataset?",
            "options": [
                "A. 142",
                "B. 552",
                "C. 23",
                "D. 330",
                "E. 410"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "410"
            ],
            "img_path": "2505.03385/flowchart1.2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03452",
        "img_path": "2505.03452/flow.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Evaluating Model Architectures for Enhanced Text Generation",
                "B. An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation",
                "C. A Comparative Study of Fine-Tuning Techniques in Language Models",
                "D. Optimizing Neural Network Structures for Information Retrieval Tasks",
                "E. Investigating Data Augmentation Strategies in Generative Systems"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation"
            ],
            "img_path": "2505.03452/flow.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value is obtained by performing the multiplication explicitly defined within the parentheses that are presented alongside the stated total of 18 configurations for data indexing?",
            "options": [
                "A. 12",
                "B. 18",
                "C. 6",
                "D. 4",
                "E. 7"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "12"
            ],
            "img_path": "2505.03452/flow.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03374",
        "img_path": "2505.03374/x1.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Benjamin Maylor",
                "B. Xiaofang Chen",
                "C. Abram Schonfeldt",
                "D. Ronald Clark",
                "E. Aiden Doherty"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Abram Schonfeldt"
            ],
            "img_path": "2505.03374/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the mapping convention where an activity with a MET value of 3.3 was categorized as LIPA despite technically being MVPA—a convention originating from the Oxfordshire study and subsequently applied to relevant labels in the Sichuan study—what is the combined number of participants from both studies whose data was subject to this mapping rule?",
            "options": [
                "A. 3.3",
                "B. 50",
                "C. 161",
                "D. 111",
                "E. 272"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "272"
            ],
            "img_path": "2505.03374/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03406",
        "img_path": "2505.03406/system_architecture.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Mohd Sohail Ali Khan",
                "B. Shubham Revankar",
                "C. Aditya Varma",
                "D. Anil S. Mokhade",
                "E. Mohammad Shoaib Ansari"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Mohammad Shoaib Ansari"
            ],
            "img_path": "2505.03406/system_architecture.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the challenge of deploying advanced AI systems in resource-constrained healthcare environments while maintaining high performance with specialized medical data, which single sentence accurately describes the core mechanism enabling the described LLM system to address this specific challenge?",
            "options": [
                "A. The system primarily relies on generalized medical knowledge from the Llama 3.2-3B-Instruct model to ensure broad applicability across various medical conditions.",
                "B. Enhanced disease prediction accuracy is solely achieved through the Retrieval-Augmented Generation (RAG) component's access to extensive, de-identified Electronic Health Record (EHR) databases.",
                "C. The utilization of Quantized Low-Rank Adaptation (QLoRA) for sophisticated quantization techniques directly facilitates scalable deployment in low-resource settings by creating efficient, lightweight models capable of processing hospital-specific information effectively.",
                "D. Rigorous clinical validation and ethical considerations, such as patient privacy and data security, are the foremost technical innovations ensuring the system's deployability and trustworthiness.",
                "E. The system's improved performance on diverse medical benchmarks is primarily attributed to its advanced document segmentation strategy that optimizes retrieval granularity for all types of complex medical reports."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The utilization of QLoRA for sophisticated quantization techniques directly facilitates scalable deployment in low-resource settings by creating efficient, lightweight models capable of processing hospital-specific information effectively."
            ],
            "img_path": "2505.03406/system_architecture.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03319",
        "img_path": "2505.03319/sdvsum.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Temporal Attention Networks for Enhanced Video Captioning",
                "B. Multi-Modal Approaches to Interactive Script Analysis in Video Content",
                "C. Dataset and Framework for Scene-Based Video Retrieval Using Textual Metadata",
                "D. SD-VSum: A Method and Dataset for Script-Driven Video Summarization",
                "E. Learning Video Highlights through Contextual Audio-Visual Embeddings"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "SD-VSum: A Method and Dataset for Script-Driven Video Summarization"
            ],
            "img_path": "2505.03319/sdvsum.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the effective number of testing samples available for SD-VSum evaluation, considering the S-VideoXum dataset's specific testing video allocation and the explicitly mentioned tenfold augmentation factor applied to these videos when multiple ground-truth summaries are used as individual samples?",
            "options": [
                "A. 1,707",
                "B. 11,908",
                "C. 14,000",
                "D. 119,080",
                "E. 17,070"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "17070"
            ],
            "img_path": "2505.03319/sdvsum.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03334",
        "img_path": "2505.03334/x2.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Towards Fine-Grained Object Localization in Urban Aerial Imagery Using Deep Learning",
                "B. A Benchmark Dataset for Multi-Class Object Segmentation in Satellite Imagery",
                "C. Cross-Modal Fusion Techniques for Enhancing Remote Sensing Object Recognition",
                "D. From Word to Sentence: A Large-Scale Multi-Instance Dataset for Open-Set Aerial Detection",
                "E. Hierarchical Modeling of Spatial Context for Improved Target Detection in Aerial Scenes"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "From Word to Sentence: A Large-Scale Multi-Instance Dataset for Open-Set Aerial Detection"
            ],
            "img_path": "2505.03334/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific numerical value represents the reported improvement in Recall@10 for sentence-level inputs under zero-shot transfer conditions, achieved by a state-of-the-art open-set method when trained on the newly proposed MI-OAD dataset?",
            "options": [
                "A. 29.5",
                "B. 33.7",
                "C. 40",
                "D. 163,023",
                "E. 2,000,000"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "33.7"
            ],
            "img_path": "2505.03334/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03378",
        "img_path": "2505.03378/x2.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Rishabh Yadav",
                "B. Tasnim Ahmed",
                "C. Alberto Marchisio",
                "D. Muhammad Kashif",
                "E. Muhammad Shafique"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Tasnim Ahmed"
            ],
            "img_path": "2505.03378/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the reported findings regarding the QuanNN algorithm's noise resilience, what is the lowest specific noise probability value explicitly provided for which this model demonstrates robust performance specifically against bit flip noise, especially when contrasted with its performance degradation under other noise types within comparable high-probability ranges?",
            "options": [
                "A. 0.1",
                "B. 0.4",
                "C. 0.5",
                "D. 0.9",
                "E. 1.0"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "0.9"
            ],
            "img_path": "2505.03378/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03362",
        "img_path": "2505.03362/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Yiqun Wang",
                "B. Cunjian Chen",
                "C. Shikun Zhang",
                "D. Yong Li",
                "E. Qiuhong Ke"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Shikun Zhang"
            ],
            "img_path": "2505.03362/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, using the mean Chamfer distance data for the DTU dataset as presented in Table 3, what is the numerical result of subtracting the performance improvement achieved by applying only the high-frequency guided ray sampling strategy to the baseline (relative to the baseline itself) from the performance improvement achieved by the complete FreNeuS method (relative to the baseline itself)?",
            "options": [
                "A. 0.09",
                "B. 0.11",
                "C. 0.02",
                "D. -0.02",
                "E. 0.20"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "0.02"
            ],
            "img_path": "2505.03362/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03333",
        "img_path": "2505.03333/Fig1.jpg",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Topological edge modes in asymmetric photonic lattices",
                "B. Nonlinear localized states in disordered photonic waveguides",
                "C. Quantum interference effects in metamaterial resonators",
                "D. Symmetry-protected resonances in two-dimensional photonic structures",
                "E. Janus bound states in the continuum in structurally symmetric photonic crystals"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Janus bound states in the continuum in structurally symmetric photonic crystals"
            ],
            "img_path": "2505.03333/Fig1.jpg"
        },
        "level2_qa": {
            "question": "In this paper, which statement most precisely describes the mechanism by which the distinct upward q = -1 and downward q = +1 topological charges of Janus BICs are ultimately formed following the introduction of optical asymmetry?",
            "options": [
                "A. Janus BICs are characterized by an upward topological charge of q = +1, formed by C points shifting away from the Gamma point, and a downward charge of q = -1, directly resulting from the transformation of the initial Friedrich-Wintgen BIC's q = +1 state.",
                "B. The upward q = -1 charge of Janus BICs is inherited from the symmetry-protected BIC due to its robustness against optical asymmetry, while the downward q = +1 charge represents the Friedrich-Wintgen BIC's original topological charge, which is redirected downwards.",
                "C. Optical asymmetry causes the Friedrich-Wintgen BIC, initially with a q = +1 charge, to directly invert its topological charge to q = -1 for upward emission and maintain q = +1 for downward emission, a process independent of C point dynamics or their shifts in momentum space.",
                "D. The emergence of Janus BICs is primarily marked by the Friedrich-Wintgen BIC's polarization vortex splitting into two q = 1/2 circularly polarized states; these states then combine to form identical topological charges for both upward and downward radiation channels.",
                "E. Janus BICs are established through the shift of upward-radiating C points shift towards the Gamma point, accumulating a total topological charge of q = -1, while the downward-radiating counterpart contributes q = +1, leading to a net topological charge reversal between the two radiation channels."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Janus BICs are established through the shift of upward-radiating C points shift towards the Gamma point, accumulating a total topological charge of q = -1, while the downward-radiating counterpart contributes q = +1, leading to a net topological charge reversal between the two radiation channels."
            ],
            "img_path": "2505.03333/Fig1.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03392",
        "img_path": "2505.03392/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Adaptive Defense Mechanisms against Membership Inference in Neural Language Models",
                "B. Automatic Calibration for Membership Inference Attack on Large Language Models",
                "C. Evaluating Privacy Risks in Large Language Models through Differential Calibration",
                "D. Optimizing Model Robustness for Text Generation under Membership Attacks",
                "E. Semi-Supervised Techniques for Mitigating Privacy Leakage in Transformer Architectures"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Automatic Calibration for Membership Inference Attack on Large Language Models"
            ],
            "img_path": "2505.03392/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the core calibration technique introduced by ACMIA that simultaneously aims to reduce false positives in membership inference and alleviate the practical limitations associated with the dependency on additional reference models seen in prior calibration efforts?",
            "options": [
                "A. Multi-model result averaging.",
                "B. Tunable temperature.",
                "C. Intrinsic complexity quantification via loss values.",
                "D. Score normalization using pre-defined complexity benchmarks.",
                "E. Theoretical insights into maximum likelihood estimation."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Tunable temperature"
            ],
            "img_path": "2505.03392/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03336",
        "img_path": "2505.03336/x2.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Enhancing In-Domain Recommendations through Hierarchical User Modeling with Large Language Models",
                "B. Adaptive Filtering Techniques for Personalized Recommendations Using Generative AI",
                "C. Cross-Domain Recommendation Strategies Leveraging Constraint-Based Neural Networks",
                "D. Avoid Recommending Out-of-Domain Items: Constrained Generative Recommendation with LLMs",
                "E. Improving Recommendation Accuracy via Multi-Modal Data Integration and LLMs"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Avoid Recommending Out-of-Domain Items: Constrained Generative Recommendation with LLMs"
            ],
            "img_path": "2505.03336/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence best describes the pivotal role of the unified framework, with its specialized token-driven phase differentiation, in establishing the comparative advantages of RecLM-cgen over RecLM-ret for reliable in-domain recommendations?",
            "options": [
                "A. The unified framework primarily serves to introduce RecLM-ret and RecLM-cgen as independent solutions for OOD problems, with special tokens merely signaling item boundaries without impacting the comparative evaluation process.",
                "B. By employing <SOI> and <EOI> tokens to demarcate item generation, the framework allows RecLM-ret to leverage contextual embeddings for retrieval and RecLM-cgen to use prefix trees, thereby enabling a direct assessment where RecLM-cgen is found superior due to its better accuracy and complete OOD elimination without a trade-off.",
                "C. The framework's main contribution is to demonstrate that both RecLM-ret and RecLM-cgen, through token-based phase separation, achieve comparable performance in OOD elimination, with RecLM-cgen offering only marginal gains in generalist capabilities and integration ease.",
                "D. Specialized tokens within the unified framework are designed principally to enhance the backbone LLM's general text generation flexibility, with the item generation phase being a secondary benefit that incidentally allows RecLM-cgen to show slightly better OOD avoidance than RecLM-ret.",
                "E. The unified framework's token-driven phase differentiation is crucial primarily for enabling minimal modifications to the backbone LLM when implementing RecLM-ret, while RecLM-cgen's superior performance and practical benefits are established independently of this specific comparative framework."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "By employing <SOI> and <EOI> tokens to demarcate item generation, the framework allows RecLM-ret to leverage contextual embeddings for retrieval and RecLM-cgen to use prefix trees, thereby enabling a direct assessment where RecLM-cgen is found superior due to its better accuracy and complete OOD elimination without a trade-off."
            ],
            "img_path": "2505.03336/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03388",
        "img_path": "2505.03388/x1.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. L. Hao",
                "B. K. Wresilo",
                "C. Alon Helvitz",
                "D. Nir Shlezinger",
                "E. Natalie Lang"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Natalie Lang"
            ],
            "img_path": "2505.03388/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, to address the server's need to retain individual user updates for potential unlearning, what is the first explicitly detailed step in MEDU's hierarchical encoder designed to primarily reduce the memory overhead associated with the number of users (U), and what technique underpins this step?",
            "options": [
                "A. Differential thresholding, applied initially to all user updates to discard low-impact weights before considering user-specific storage.",
                "B. Random lattice coding, employed as the foundational compression layer for all incoming user updates to minimize raw data volume before any user-level selection.",
                "C. User Selection, which involves storing updates for only a randomly chosen subset of users (U¯ < U) in each round, thereby implementing a form of user sparsification.",
                "D. Entropy coding, utilized as a preliminary lossless compression stage on raw user updates to reduce their size before lossy techniques are applied.",
                "E. Round-based update summarization, where updates from all users within a round are condensed into a single representative vector before any user-specific pruning."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "User Selection, which involves storing updates for only a randomly chosen subset of users (U¯ < U) in each round, thereby implementing a form of user sparsification."
            ],
            "img_path": "2505.03388/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03435",
        "img_path": "2505.03435/x2.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Robustness in AI-Generated Detection: Enhancing Resistance to Adversarial Attacks",
                "B. Improving Accuracy in AI-Driven Classification Systems",
                "C. Evaluating Performance Metrics for Machine Learning Models",
                "D. Adaptive Algorithms for Noise Reduction in Data Processing",
                "E. Optimizing Neural Networks for Faster Image Recognition"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Robustness in AI-Generated Detection: Enhancing Resistance to Adversarial Attacks"
            ],
            "img_path": "2505.03435/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the cited literature, what is the most recent year associated with a referenced work that specifically addresses either the improvement of model robustness in facial recognition or advanced methods in AI-generated content detection?",
            "options": [
                "A. 2022",
                "B. 2023",
                "C. 2024",
                "D. 2025",
                "E. 2019"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "2025"
            ],
            "img_path": "2505.03435/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03481",
        "img_path": "2505.03481/usp-system-diagram-bw.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Jakob N. Foerster",
                "B. Christoph Börgers",
                "C. Maciej Zembrzuski",
                "D. Zhekai Chen",
                "E. Saad Mahamood"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Maciej Zembrzuski"
            ],
            "img_path": "2505.03481/usp-system-diagram-bw.png"
        },
        "level2_qa": {
            "question": "In this paper, concerning the USEsum system's extractive content selection mechanism as detailed in the 'Additional Context Sections', what single number represents the count of distinct, sequential operations where sentence embedding representations are actively generated or utilized to determine the relevance of input sentences, before these sentences are passed to the abstractive model?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.03481/usp-system-diagram-bw.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03445",
        "img_path": "2505.03445/Overview.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Cartesian Coordinate Framework for 3D Human Pose Estimation Using Neural Networks",
                "B. Polar Coordinate-Based 2D Pose Prior with Neural Distance Field",
                "C. Neural Field Approaches to Temporal 2D Pose Tracking in Video Sequences",
                "D. Distance Geometry Methods for Shape Reconstruction in Polar Coordinate Systems",
                "E. Deep Learning Models for Articulated Pose Recognition Based on Vector Fields"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Polar Coordinate-Based 2D Pose Prior with Neural Distance Field"
            ],
            "img_path": "2505.03445/Overview.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the exact number of vectors J used to represent the skeleton in the 2D pose prior-guided refinement method, and how does this specific number influence the dimensionality of the embedded feature space in the encoder network?",
            "options": [
                "A. J = 17 vectors, resulting in a feature space of 17 × L dimensions.",
                "B. J = 13 vectors, resulting in a feature space of 13 × L dimensions.",
                "C. J = 15 vectors, resulting in a feature space of 15 × L dimensions.",
                "D. J = 18 vectors, resulting in a feature space of 18 × L dimensions.",
                "E. J = 16 vectors, resulting in a feature space of 16 × L dimensions."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "15"
            ],
            "img_path": "2505.03445/Overview.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03422",
        "img_path": "2505.03422/motivation.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. GeoMatchNet: Robust 2D Feature Extraction for Image Alignment",
                "B. DeepShape: Learning Global Descriptors for 3D Object Recognition",
                "C. LiftFeat: 3D Geometry-Aware Local Feature Matching",
                "D. SurfaceTrack: Real-Time Local Feature Tracking in 3D Environments",
                "E. MultiViewFeat: Cross-View Feature Aggregation for Scene Reconstruction"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "LiftFeat: 3D Geometry-Aware Local Feature Matching"
            ],
            "img_path": "2505.03422/motivation.png"
        },
        "level2_qa": {
            "question": "In this paper, the specific manner in which LiftFeat integrates 3D geometric priors, originating from a pre-trained depth model, into its 2D feature enhancement pipeline is a critical aspect of its design. Which single sentence best describes the complete pathway and justification for how LiftFeat processes these initial 3D cues to generate its own task-specific 3D geometric features for fusion?",
            "options": [
                "A. LiftFeat directly incorporates pseudo surface normal labels, obtained from a pre-trained depth model, into its 3D-GFL module for immediate fusion with 2D descriptors, thereby efficiently leveraging 3D information without the overhead of learning new 3D representations.",
                "B. To ensure accuracy, LiftFeat first generates initial surface normal predictions using a pre-trained depth model, then refines these predictions through its own network before fusing them, primarily to overcome scale ambiguities inherent in raw depth data.",
                "C. LiftFeat employs a pre-trained model to predict depth maps, which are then converted into suitable 3D geometric cues by LiftFeat's internal modules; these processed cues are subsequently fused with 2D features to improve matching, mainly because direct depth is too costly to acquire.",
                "D. The core of LiftFeat's 3D integration strategy involves using a pre-trained depth model to directly provide robust surface normal features, which are then passed to the 3D-GFL module for combination with 2D descriptors, thus avoiding the complexities of de novo 3D feature learning.",
                "E. LiftFeat utilizes pseudo surface normal labels, derived from a pre-trained depth model's predictions, to supervise its dedicated surface normal estimation head, enabling it to learn its own translation and scale-invariant 3D geometric features which are then fused with 2D descriptors via the 3D-GFL module to enhance robustness without direct depth map use or new annotation costs."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "LiftFeat utilizes pseudo surface normal labels, derived from a pre-trained depth model's predictions, to supervise its dedicated surface normal estimation head, enabling it to learn its own translation and scale-invariant 3D geometric features which are then fused with 2D descriptors via the 3D-GFL module to enhance robustness without direct depth map use or new annotation costs."
            ],
            "img_path": "2505.03422/motivation.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03472",
        "img_path": "2505.03472/x6.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Frameworks for Vehicle-to-Everything Communication in Urban Environments",
                "B. Design and Evaluation of Sensor Fusion Algorithms for Autonomous Driving",
                "C. Cybersecurity Challenges in Connected Vehicle Networks: Protocols and Solutions",
                "D. Energy-Efficient Control Strategies for Electric Automated Vehicles",
                "E. Simulation to Reality: Testbeds and Architectures for Connected and Automated Vehicles"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Simulation to Reality: Testbeds and Architectures for Connected and Automated Vehicles"
            ],
            "img_path": "2505.03472/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, by first identifying the numerical quantity of the eight overarching requirements that are explicitly stated to 'arise specifically from the use of small-scale testbeds', and then identifying the total count of distinct testing environment types (e.g., simulation, small-scale, full-scale) at which portions of the complete set of eight overarching requirements are described as either 'arising specifically' or 'applying primarily', what is the sum of these two identified numerical values?",
            "options": [
                "A. 4",
                "B. 5",
                "C. 6",
                "D. 7",
                "E. 8"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "6"
            ],
            "img_path": "2505.03472/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03484",
        "img_path": "2505.03484/x1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Adaptive Models for Handling Sequence Length Variability in Recommendation Systems",
                "B. STAR-Rec: Making Peace with Length Variance and Pattern Diversity in Sequential Recommendation",
                "C. Towards Robust Pattern Recognition in Sequential User Behavior Analysis",
                "D. Evaluating the Impact of Sequence Diversity on Recommendation Accuracy",
                "E. Long-Short Sequence Encoding Techniques for Enhanced Recommendation Performance"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "STAR-Rec: Making Peace with Length Variance and Pattern Diversity in Sequential Recommendation"
            ],
            "img_path": "2505.03484/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence from the provided text most comprehensively and directly articulates STAR-Rec's tripartite architectural approach to resolving the explicitly identified fundamental limitations of prior models, specifically their difficulties with sequence length variance and diverse interaction pattern capture?",
            "options": [
                "A. Recent deep sequential recommendation models often struggle to effectively model key characteristics of user behaviors, particularly in handling sequence length variations and capturing diverse interaction patterns.",
                "B. We propose STAR-Rec, a novel architecture that synergistically combines preference-aware attention and state-space modeling through a sequence-level mixture-of-experts framework.",
                "C. STAR-Rec addresses these challenges by: (1) employing preference-aware attention to capture both inherently similar item relationships and diverse preferences, (2) utilizing state-space modeling to efficiently process variable-length sequences with linear complexity, and (3) incorporating a mixture-of-experts component that adaptively routes different behavioral patterns to specialized experts, handling both focused category-specific browsing and diverse category exploration patterns.",
                "D. We theoretically demonstrate how the state space model and attention mechanisms can be naturally unified in recommendation scenarios, where SSM captures temporal dynamics through state compression while attention models both similar and diverse item relationships.",
                "E. This unified framework effectively leverages both similarity-based and temporal information while maintaining computational efficiency through selective computation paths."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "STAR-Rec addresses these challenges by: (1) employing preference-aware attention to capture both inherently similar item relationships and diverse preferences, (2) utilizing state-space modeling to efficiently process variable-length sequences with linear complexity, and (3) incorporating a mixture-of-experts component that adaptively routes different behavioral patterns to specialized experts, handling both focused category-specific browsing and diverse category exploration patterns."
            ],
            "img_path": "2505.03484/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03380",
        "img_path": "2505.03380/x7.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Jiaji Mao",
                "B. Lehan Wang",
                "C. Haonan Wang",
                "D. Qixiang Zhang",
                "E. Marawan Elbatel"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Haonan Wang"
            ],
            "img_path": "2505.03380/x7.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the calculated average number of annotated regions per image-mask-description triplet within the primary training corpus used for RCMed?",
            "options": [
                "A. 7.5",
                "B. 20.5",
                "C. 20",
                "D. 410",
                "E. 0.049"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "20.5"
            ],
            "img_path": "2505.03380/x7.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03335",
        "img_path": "2505.03335/x3.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Towards Zero-Shot Learning: Enhanced Self-Play Strategies for Adaptive Reasoning",
                "B. Absolute Zero: Reinforced Self-play Reasoning with Zero Data",
                "C. Reinforced Multi-Agent Systems: Learning Reasoning without Pretrained Data",
                "D. Data-Efficient Self-Play: A Novel Approach to Reinforcement-Based Reasoning",
                "E. Zero-Data Reinforcement Learning: Advancements in Autonomous Self-Play Frameworks"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Absolute Zero: Reinforced Self-play Reasoning with Zero Data"
            ],
            "img_path": "2505.03335/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the stated limitations of prior zero RLVR methods and the timeline of cited works, in what year was the scalability bottleneck for LLM pretraining identified, which motivated the development of the Absolute Zero paradigm?",
            "options": [
                "A. 2023",
                "B. 2024",
                "C. 2025",
                "D. 2019",
                "E. 2018"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2024"
            ],
            "img_path": "2505.03335/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03443",
        "img_path": "2505.03443/x2.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Norihisa Ikoma",
                "B. S. Tosi",
                "C. Simona Paiano",
                "D. Valerio Bellandi",
                "E. V. Wakelam"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Valerio Bellandi"
            ],
            "img_path": "2505.03443/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, within the described hierarchical system, if a user from a given district requests information about an entity exclusively mentioned in documents of a separate district, while concurrently the top-level Entity Registry (EReg) is ingesting an updated attribute for a different entity from yet another local district which might create a conflict with an identifier already defined within the top-level EReg's metamodel, which sentence accurately describes the primary authority for determining the user's viewable entity details and the system level where the initial check for the attribute's potential inconsistency is designed to occur?",
            "options": [
                "A. The owning district's Privacy-Permission table dictates the user's viewable details for the cross-district entity, mediated by the top-level EReg, and the top-level EReg itself performs the initial inconsistency check for the ingested attribute against its own metamodel.",
                "B. The top-level EReg's globally stored permission tables solely determine the user's viewable details, and the local district originating the attribute update is primarily responsible for initial inconsistency detection before ingestion into the top-level system.",
                "C. The user's own district's permission settings combined with broadly defined top-level EReg anonymization policies define the viewable entity details, and inconsistency checks are a distributed responsibility, primarily flagged by the local district that owns the EReg metamodel relevant to the updated attribute.",
                "D. Anonymization rules dynamically applied by NLP components, based on the sensitivity of the entity type as defined in the top-level EReg, determine the entity details, and inconsistencies are primarily detected by comparing the ingested attribute against all local EReg instances simultaneously.",
                "E. Both the determination of viewable entity details for cross-district queries and the initial inconsistency check for attributes ingested at the top-level are exclusively performed by the respective originating local districts' ERegs, with the top-level EReg acting only as a passive data conduit and conflict logger."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The owning district's Privacy-Permission table dictates the user's viewable details for the cross-district entity, mediated by the top-level EReg, and the top-level EReg itself performs the initial inconsistency check for the ingested attribute against its own metamodel."
            ],
            "img_path": "2505.03443/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2505.03401",
        "img_path": "2505.03401/x1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation",
                "B. Temporal Convolutional Networks for Cross-sectional Medical Image Analysis",
                "C. Adaptive Residual Models for Real-time Radiology Image Segmentation",
                "D. Difference-aware Deep Learning Approaches for Diagnostic Text Summarization",
                "E. Longitudinal Analysis of Radiology Data Using Static Temporal Features"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation"
            ],
            "img_path": "2505.03401/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, by synthesizing the description of DDaTR's novel components, what is the total count of explicitly named, distinct architectural innovations (module types or network mechanisms) introduced by DDaTR to specifically enhance (i) multi-level spatial correlation capture within the visual encoder and (ii) temporal correlation modelling?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 1",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2505.03401/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2501.00398",
        "img_path": "2501.00398/main_diagram.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Marieke M. van Buchem",
                "B. Ashish Seth",
                "C. Ramani Duraiswami",
                "D. Nishit Anand",
                "E. Dinesh Manocha"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Nishit Anand"
            ],
            "img_path": "2501.00398/main_diagram.png"
        },
        "level2_qa": {
            "question": "In this paper, considering TSPE's demonstrated efficacy across diverse audio classification datasets without requiring additional training or fine-tuning, and its specific advantage in out-of-distribution scenarios where training-intensive methods falter, what is the minimum quantified absolute improvement TSPE provides over vanilla zero-shot evaluation, reflecting its baseline enhancement capability?",
            "options": [
                "A. 12",
                "B. 1.23",
                "C. 16.36",
                "D. 0",
                "E. 8.795"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1.23"
            ],
            "img_path": "2501.00398/main_diagram.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00379",
        "img_path": "2501.00379/x1.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Adaptive Aggregation Strategies in Federated Learning Systems",
                "B. Resource Optimization Techniques for Distributed Neural Networks",
                "C. Federated Dropout: Convergence Analysis and Resource Allocation",
                "D. Convergence Properties of Sparse Model Updates in Decentralized Training",
                "E. Efficient Communication Protocols for Collaborative Machine Learning"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Federated Dropout: Convergence Analysis and Resource Allocation"
            ],
            "img_path": "2501.00379/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, identify the single sentence that most precisely articulates the pivotal theoretical insight which transitions from establishing the detrimental effect of increased dropout on convergence speed to providing the conceptual basis for a strategic approach aimed at optimizing overall learning time, by explicitly framing this relationship as a manageable trade-off between per-iteration efficiency and the total number of iterations required for convergence.",
            "options": [
                "A. However, the theoretical convergence analysis for Federated Dropout is still lacking in the literature, particularly regarding the quantitative influence of dropout rate on convergence.",
                "B. Specifically, it is shown that a larger dropout rate of each device leads to a slower convergence rate.",
                "C. This provides a theoretical foundation for reducing the convergence latency by making a tradeoff between the per-round latency and the overall rounds till convergence.",
                "D. Moreover, a low-complexity algorithm is proposed to jointly optimize the dropout rate and the bandwidth allocation for minimizing the loss function in all rounds under a given per-round latency and limited network resources.",
                "E. To address this issue, by using the Taylor expansion method, we mathematically show that the gradient variance increases with a scaling factor of $\\gamma/(1-\\gamma)$, with $\\gamma \\in [0, \\theta)$ denoting the dropout rate and $\\theta$ being the maximum dropout rate ensuring the loss function reduction."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "This provides a theoretical foundation for reducing the convergence latency by making a tradeoff between the per-round latency and the overall rounds till convergence."
            ],
            "img_path": "2501.00379/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00177",
        "img_path": "2501.00177/x1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Experimental Analysis of Charge Transport Mechanisms in Phosphorus-Doped Diamond Films",
                "B. Computational Study of Vacancy Formation Energies in Boron-Modified Carbon Nanostructures",
                "C. Theoretical Investigation of Yield-Enhancing Equilibrium Negatively Ionized Tin-Vacancy Center Preparation Pathways in N-Doped Diamond",
                "D. Investigation of Luminescence Properties in Silicon-Vacancy Centers of High-Purity Diamond",
                "E. Optimization Strategies for Enhanced Electron Spin Coherence in Diamond Defect Centers"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Theoretical Investigation of Yield-Enhancing Equilibrium Negatively Ionized Tin-Vacancy Center Preparation Pathways in N-Doped Diamond"
            ],
            "img_path": "2501.00177/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the upper bound of the chemical potential range for Sn (in eV/atom) considered in the calculations to model conditions that might reflect high defect concentrations achievable, for example, through ion implantation?",
            "options": [
                "A. -4.60",
                "B. 6.58",
                "C. -7.59",
                "D. 11.45",
                "E. -11.39"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "6.58"
            ],
            "img_path": "2501.00177/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00343",
        "img_path": "2501.00343/x3.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Segmented Encoding for Efficient Text Generation",
                "B. Hierarchical Compression Techniques in Neural Language Models",
                "C. Chunk-Distilled Language Modeling",
                "D. Adaptive Tokenization Strategies for Improved Language Understanding",
                "E. Context-Aware Pruning Methods in Deep Language Representations"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Chunk-Distilled Language Modeling"
            ],
            "img_path": "2501.00343/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the formal description of the chunk-integrated generative process, where `l_t` denotes the sequence length after `t` generation steps and the property `l_t >= t` must hold: if, at the commencement of generation step `t=3` (a step where `t>1`), the accumulated sequence length `l_2` is precisely `2`, and at this step `t=3` the chunk proposal model `G` offers an empty chunk (characterised by a chunk length `\\tau_n = 0`), what is the exact numerical value of tokens that will be appended to the sequence during this specific generation step `t=3`?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 3",
                "E. Impossible to determine from the provided text."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2501.00343/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00303",
        "img_path": "2501.00303/x1.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Multi-Modal Graph Embedding Techniques for Enhanced Few-Shot Classification",
                "B. Domain-Adaptive Graph Neural Networks for Semantic Segmentation Under Limited Data",
                "C. SAM-Aware Graph Prompt Reasoning Network for Cross-Domain Few-Shot Segmentation",
                "D. Hierarchical Prompt Learning Strategies in Cross-Domain Image Analysis",
                "E. Attention-Guided Feature Fusion Networks for Multi-Domain Few-Shot Recognition"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "SAM-Aware Graph Prompt Reasoning Network for Cross-Domain Few-Shot Segmentation"
            ],
            "img_path": "2501.00303/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which details the GPRN framework utilizing SAM to address domain disparity in cross-domain few-shot segmentation by enhancing feature representation learning through modules like SPI and GPR, and refining predictions with APS, what is the single numerical value representing the percentage performance boost specifically provided by the 'fine-tuning phase', according to the supplementary analysis that contrasts this with the zero performance improvement from training GPRN on PASCAL VOC?",
            "options": [
                "A. 0.0",
                "B. 0.5",
                "C. 4.0",
                "D. 3.5",
                "E. 4.5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4.0"
            ],
            "img_path": "2501.00303/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00318",
        "img_path": "2501.00318/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Andrey Kravtsov",
                "B. Boseung Jeong",
                "C. Dongwon Kim",
                "D. Suha Kwak",
                "E. Jicheol Park"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Jicheol Park"
            ],
            "img_path": "2501.00318/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, during the process of quantifying the commonality of each fine embedding for the proposed commonality-based margin ranking (CMR) loss, what is the minimum number of unique identities required in the dataset such that the normalization denominator log(c) in the entropy calculation is strictly greater than one, and what is the exact value of c at this threshold?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 5",
                "D. 10",
                "E. 4"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2501.00318/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00217",
        "img_path": "2501.00217/x1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Evaluating LLMs for Adaptive Code Optimization in Software Development",
                "B. Integrating Large Language Models into Continuous Integration Pipelines",
                "C. The Role of AI in Enhancing User Experience Testing Methodologies",
                "D. The Potential of LLMs in Automating Software Testing: From Generation to Reporting",
                "E. Automated Bug Detection and Fixing Using Machine Learning Techniques"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "The Potential of LLMs in Automating Software Testing: From Generation to Reporting"
            ],
            "img_path": "2501.00217/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct software applications were utilized to directly evaluate the performance of the main proposed automated software testing system?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 83",
                "E. 102"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2501.00217/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00279",
        "img_path": "2501.00279/vmem.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Performant Automatic BLAS Offloading on Unified Memory Architecture with OpenMP First-Touch Style Data Movement",
                "B. Efficient GPU-Accelerated Matrix Computations Using OpenMP and Distributed Memory Systems",
                "C. Optimizing Parallel Linear Algebra Routines with Hierarchical Memory Models and CUDA Integration",
                "D. Scalable Sparse BLAS Implementations on NUMA Architectures via OpenMP Task Scheduling",
                "E. Adaptive Data Placement Strategies for High-Performance Computing on Hybrid Memory Nodes"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Performant Automatic BLAS Offloading on Unified Memory Architecture with OpenMP First-Touch Style Data Movement"
            ],
            "img_path": "2501.00279/vmem.png"
        },
        "level2_qa": {
            "question": "In this paper, reflecting SCILIB-Accel's core design philosophy for ease of adoption and its technical implementation using dynamic binary instrumentation for symbol interception, what essential characteristic must an application's existing, compiled CPU binary possess to be eligible for automatic BLAS offload to GPUs via SCILIB-Accel, thereby distinguishing its integration from methods that necessitate developer intervention in the source or build system?",
            "options": [
                "A. Recompiled",
                "B. Instrumented",
                "C. Unmodified",
                "D. Self-contained",
                "E. Source-linked"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Unmodified"
            ],
            "img_path": "2501.00279/vmem.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00332",
        "img_path": "2501.00332/x1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Distributed Knowledge Extraction via Collaborative Retrieval Networks",
                "B. MAIN-RAG: Multi-Agent Filtering Retrieval-Augmented Generation",
                "C. Adaptive Multi-Agent Systems for Enhanced Data Summarization",
                "D. Hierarchical Filtering Techniques in Neural Text Generation",
                "E. Cross-Agent Communication Models for Contextual Information Retrieval"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "MAIN-RAG: Multi-Agent Filtering Retrieval-Augmented Generation"
            ],
            "img_path": "2501.00332/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific integer value representing the lower bound of the percentage point improvement range in answer accuracy that MAIN-RAG is documented to achieve over traditional RAG systems, based on its evaluation across the full set of QA benchmarks discussed?",
            "options": [
                "A. 2",
                "B. 4",
                "C. 9",
                "D. 11",
                "E. 1"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.00332/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00457",
        "img_path": "2501.00457/x4.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Optimizing Multimodal Representations via Gradient-Free Prompt Tuning",
                "B. Hierarchical Attention Mechanisms for Cross-Modal Image Captioning",
                "C. Differentiable Prompt Learning for Vision Language Models",
                "D. Meta-Learning Strategies for Text-to-Image Generation Models",
                "E. Contrastive Pretraining Approaches in Vision and Language Integration"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Differentiable Prompt Learning for Vision Language Models"
            ],
            "img_path": "2501.00457/x4.png"
        },
        "level2_qa": {
            "question": "In this paper, despite the Differentiable Prompt Learning (DPL) method exhibiting dataset-dependent behavior in its α-matrix and variable confidence in the search phase across text and image branches for its optimal heterogeneous prompt configurations, what single numerical value quantifies the consolidated average percentage improvement in test accuracy over baseline methods, reported across all 11 downstream tasks evaluated?",
            "options": [
                "A. 1.10",
                "B. 11.00",
                "C. 16.00",
                "D. 2.60",
                "E. 2.16"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "2.60"
            ],
            "img_path": "2501.00457/x4.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00430",
        "img_path": "2501.00430/figure3.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Chengbo He",
                "B. Bochao Zou",
                "C. Xin Li",
                "D. Jiansheng Chen",
                "E. Junliang Xing"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Chengbo He"
            ],
            "img_path": "2501.00430/figure3.png"
        },
        "level2_qa": {
            "question": "In this paper, which of the following sentences precisely articulates the specific mechanism within an individual reasoning path of the RR-MP framework designed to counteract the Degeneration-of-Thought phenomenon where an agent becomes prematurely entrenched in its initial, potentially flawed, reasoning?",
            "options": [
                "A. Our approach improves scientific reasoning accuracy by employing a multi-path reasoning mechanism where each path consists of a reactive agent and a reflection agent that collaborate to prevent degeneration of thought inherent in single-agent reliance.",
                "B. Although error detection is a prerequisite for self-correction, effectively implementing it remains a challenge.",
                "C. Once the reflection agent retrieves the preliminary answer s′ from the reactive agent, it undergoes multi-step reasoning and, with the assistance of relevant tools and external knowledge, formulates the reasoning strategy π.",
                "D. Furthermore, we theoretically prove that as the number of agents increases, the generated multi-path reasoning significantly enhances decision quality.",
                "E. The framework integrates reactive agents and reflection agents working collaboratively; the reflection agents stimulate reactive agents to perform self-correction."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "The framework integrates reactive agents and reflection agents working collaboratively; the reflection agents stimulate reactive agents to perform self-correction."
            ],
            "img_path": "2501.00430/figure3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00237",
        "img_path": "2501.00237/x3.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Leveraging Catastrophic Forgetting to Enhance Domain Adaptation in Incremental Learning",
                "B. Make Domain Shift a Catastrophic Forgetting Alleviator in Class-Incremental Learning",
                "C. Mitigating Domain Shift Effects Through Continual Learning Strategies",
                "D. A Novel Framework for Domain Adaptation in Class-Incremental Neural Networks",
                "E. Exploring Domain Generalization Techniques for Improved Class-Incremental Learning"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Make Domain Shift a Catastrophic Forgetting Alleviator in Class-Incremental Learning"
            ],
            "img_path": "2501.00237/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, drawing from the analysis of Parameter Interference Value (PIV) across various continual learning methods when comparing standard Class-Incremental Learning (CIL) with Class-Incremental Learning with Domain shift (CILD), which single sentence accurately synthesizes the contrasting PIV outcomes and their attributed causes for general methods, prompt-based methods like L2P, and architecture-based methods like DER?",
            "options": [
                "A. Domain shifts in CILD uniformly increase PIV, exemplified by L2P's 100% PIV and subsequent poor performance, fundamentally challenging the paper's overall positive stance on domain shift benefits for CIL.",
                "B. All continual learning methods, including prompt-based L2P and architecture-based DER, consistently exhibit significantly lower PIV in CILD settings because the domain shift inherently reduces parameter interference across the board, leading to improved performance for all.",
                "C. Architecture-based methods like DER demonstrate high PIV in CILD due to the complexity of new layers, while prompt-based L2P uniquely benefits from domain shifts with substantially reduced PIV, showcasing its superiority in CILD.",
                "D. The primary finding regarding PIV is that only architecture-based methods like DER can effectively manage interference in CILD, as both general methods and prompt-based methods like L2P invariably suffer from increased PIV and performance degradation when domain shifts are introduced.",
                "E. While domain shifts in CILD settings generally lower PIV for most methods, prompt-based methods like L2P show a 100% PIV due to constrained updatable parameters leading to high interference and worse CILD performance, whereas architecture-based methods like DER achieve low PIV due to dedicated layers for each task."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "While domain shifts in CILD settings generally lower PIV for most methods, prompt-based methods like L2P show a 100% PIV due to constrained updatable parameters leading to high interference and worse CILD performance, whereas architecture-based methods like DER achieve low PIV due to dedicated layers for each task."
            ],
            "img_path": "2501.00237/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00322",
        "img_path": "2501.00322/x2.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Multidimensional Persistence via Bifiltration Analysis",
                "B. Stability Conditions in Zigzag Homology Computations",
                "C. Bipath Persistence as Zigzag Persistence",
                "D. Algorithmic Approaches to Persistent Cohomology in Networks",
                "E. Generalized Persistence Modules over Directed Graphs"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Bipath Persistence as Zigzag Persistence"
            ],
            "img_path": "2501.00322/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which sentence most accurately synthesizes the specific pathway and the types of intermediate module constructions through which algorithmic improvements for standard single-parameter persistence are asserted to recursively enhance the decomposability of bipath persistence modules?",
            "options": [
                "A. Algorithmic enhancements for standard persistence improve the Dey and Hou zigzag decomposition algorithm, which in turn is applied to a \"related (finite) zigzag module\" derived from the bipath module, thereby improving bipath module decomposition.",
                "B. Improvements in standard persistence are leveraged through the infinite zigzag module R(M), whose periodic barcode properties, when combined with Dey and Hou's algorithm, directly facilitate bipath module decomposition.",
                "C. Bipath module decomposition benefits from standard persistence algorithm improvements primarily because the restriction functor R allows direct application of standard persistence algorithms to the infinite zigzag module R(M), bypassing intermediate zigzag steps.",
                "D. The matrix-based algorithm by Aoki, Escolar, and Tada for bipath modules is the primary conduit through which standard persistence improvements enhance bipath decomposition, by incorporating advancements from Dey and Hou's work on the infinite zigzag module R(M).",
                "E. Enhancements in standard persistence algorithms are directly applied to decompose bipath modules once they are transformed into a \"related (finite) zigzag module,\" without necessarily relying on the specifics of the Dey and Hou algorithm as the intermediary."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Here, among other consequences detailed below, we show that a bipath module can be decomposed by directly decomposing a related (finite) zigzag module. This allows us to use the zigzag decomposition algorithm, in the case of the modules being the homology of a simplex-wise filtration, of Dey and Hou[17], which works by decomposing a related standard single-parameter persistence module. Thus, any improvement to the decomposition of standard persistence transfers to zigzag persistence and then to bipath persistence."
            ],
            "img_path": "2501.00322/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00296",
        "img_path": "2501.00296/pix2pred_overview2.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Unsupervised Object Segmentation Using Vision-Language Frameworks",
                "B. Multimodal Representation Learning for Scene Understanding",
                "C. Enhancing Image Captioning with Knowledge Graph Embeddings",
                "D. Predicate Invention from Pixels via Pretrained Vision-Language Models",
                "E. Zero-Shot Visual Reasoning through Cross-Modal Alignment"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Predicate Invention from Pixels via Pretrained Vision-Language Models"
            ],
            "img_path": "2501.00296/pix2pred_overview2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering `pix2pred`'s dual reliance on VLMs for both proposing a candidate pool of visual predicates and subsequently determining their truth values directly from images, if VLM-induced errors were to predominantly and severely compromise the accuracy of *atom labelling* (truth value determination) while the VLM's initial *predicate proposal* capabilities based on demonstration data remained largely effective, which of the following describes the most critical and direct cascading consequence that fundamentally obstructs the system's core objective of achieving robust generalization in long-horizon tasks?",
            "options": [
                "A. The accurate conversion of image inputs into abstract states becomes unreliable, leading to the formulation of ineffective abstract plans by the classical planner, thereby critically impeding generalization.",
                "B. The hill-climbing predicate invention process would become intractably slow due to an implicit increase in the perceived complexity of the demonstration data, even if the initial predicate pool size remains manageable.",
                "C. The system would fail to effectively lift the well-proposed ground atoms into syntactically correct and semantically meaningful visual predicates, leading to a degenerate predicate pool prior to the compromised labelling phase.",
                "D. The inability to accurately label atoms would prevent the learning of meaningful symbolic operators, as the relationships between pre-conditions, post-conditions, and actions could not be reliably established from the noisy labelled demonstrations.",
                "E. The generation of syntactically incorrect visual predicates during the VLM proposal stage, which cannot be parsed or utilized by the downstream planning components."
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "VLM hallucinations adversely impact predicate proposal and atom labelling – especially with small amounts of demonstration data – which can inhibit our approach’s ability to learn useful predicates and operators."
            ],
            "img_path": "2501.00296/pix2pred_overview2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00190",
        "img_path": "2501.00190/x3.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Dynamic Temporal Graphs for Monitoring Postoperative Infection Risks",
                "B. Integrating Clinical Scores for Predicting Organ Failure in Critical Care",
                "C. Sepsis Prediction Using Static Graph Analysis and Machine Learning Techniques",
                "D. Real-Time Clinical Calculator Framework for Managing Intensive Care Unit Patients",
                "E. SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction"
            ],
            "img_path": "2501.00190/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most accurately describes the consequence of prior graph-based models' failure to incorporate both clinical event interactions and established clinical calculators, a failure that persisted despite their superiority over sequence-based models in managing data sparsity?",
            "options": [
                "A. The models need to completely observe a list of variables (including vital signs and lab tests), while many variables are missing in real-world data.",
                "B. These limitations make these models unconvincing to clinicians, hindering their application in real-world clinical scenarios.",
                "C. To bridge the gap, we propose to mimic clinicians' workflow with a novel framework SepsisCalc to integrate clinical calculators into the predictive model, yielding a clinically transparent and precise model for utilization in clinical settings.",
                "D. However, most existing graph-based models are designed to model longitudinal sparse EHRs for chronic disease prediction, the studies on dense float-value variables for acute diseases like sepsis are still limited.",
                "E. Such a gap in the workflows makes the AI models less convincing and hinders their application to real-world clinical scenarios."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "These limitations make these models unconvincing to clinicians, hindering their application in real-world clinical scenarios."
            ],
            "img_path": "2501.00190/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00444",
        "img_path": "2501.00444/general_scheme.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Automated Symbolic Regression through Contextual Data Integration",
                "B. Knowledge-aware equation discovery with automated background knowledge extraction",
                "C. Background-driven Machine Learning for Scientific Formula Generation",
                "D. Contextualized Neural Networks for Enhanced Equation Modeling",
                "E. Data-informed Discovery of Mathematical Relationships using Knowledge Graphs"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Knowledge-aware equation discovery with automated background knowledge extraction"
            ],
            "img_path": "2501.00444/general_scheme.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the algorithm's demonstrated advantages in discovering unknown equations like Burgers, wave, and Korteweg–De Vries, what single key characteristic of its search process, beyond mere coefficient recovery, is explicitly stated as superior when benchmarked against the SINDy algorithm?",
            "options": [
                "A. Convergence",
                "B. Parsimony",
                "C. Stability",
                "D. Fidelity",
                "E. Interpretability"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The paper shows that the extraction and use of knowledge allows it to outperform the SINDy algorithm in terms of search stability and robustness."
            ],
            "img_path": "2501.00444/general_scheme.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00742",
        "img_path": "2501.00742/x1.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Development of Analog Neural Networks for Solving Partial Differential Equations in Photonic Systems",
                "B. Simulation of Optical Neural Networks for Efficient PDE Approximation Using Integrated Photonics",
                "C. On-Chip Training of Hybrid Neural Models for Enhanced Optical Computation of Differential Equations",
                "D. Experimental Analysis of Photonic Architectures for Machine Learning-Based PDE Solutions",
                "E. Experimental Demonstration of an Optical Neural PDE Solver via On-Chip PINN Training"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Experimental Demonstration of an Optical Neural PDE Solver via On-Chip PINN Training"
            ],
            "img_path": "2501.00742/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific ℓ2 error value was achieved after 1000 update iterations in the experimental on-chip training of a Physics-Informed Neural Network for the one-dimensional heat equation, where the training leveraged a back-propagation-free algorithm implemented on a 1×4 micro-ring resonator weight bank?",
            "options": [
                "A. 1000",
                "B. 8",
                "C. 5E-3",
                "D. 1",
                "E. 4"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "5E-3"
            ],
            "img_path": "2501.00742/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00874",
        "img_path": "2501.00874/x1.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. MULTIVERSE: Multilingual Vector Space Embedding through Contextual Alignment",
                "B. GLUON: Global Language Understanding Optimization Networks for Cross-Lingual Tasks",
                "C. LUSIFER: Language Universal Space Integration for Enhanced Multilingual Embeddings with Large Language Models",
                "D. POLARIS: Phonetic and Orthographic Language Representation in Semantic Indexing",
                "E. NEXUS: Neural Cross-Lingual Embedding Fusion for Enhanced Semantic Transfer"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "LUSIFER: Language Universal Space Integration for Enhanced Multilingual Embeddings with Large Language Models"
            ],
            "img_path": "2501.00874/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what average point improvement does LUSIFER achieve in cross-lingual scenarios covering over 100 languages, as distinct from its average improvement across the five fundamental tasks within its 123-dataset benchmark?",
            "options": [
                "A. 3.19",
                "B. 5.75",
                "C. 14.00",
                "D. 22.15",
                "E. 123.00"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "5.75"
            ],
            "img_path": "2501.00874/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00380",
        "img_path": "2501.00380/x3.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. A supervised deep learning framework for star formation rate prediction using Transformer architectures",
                "B. Multi-modal feature fusion for enhanced galaxy cluster detection in deep sky surveys",
                "C. Semi-supervised segmentation of cosmic structures with graph neural networks and attention mechanisms",
                "D. Optimization of photometric redshift estimation through hybrid convolutional and recurrent neural networks",
                "E. An efficient unsupervised classification model for galaxy morphology: Voting clustering based on coding from ConvNeXt large model"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "An efficient unsupervised classification model for galaxy morphology: Voting clustering based on coding from ConvNeXt large model"
            ],
            "img_path": "2501.00380/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the sum of the number of channels in the final block layer of the ConvNeXt model and the reduction in dimensionality achieved by the subsequent PCA step?",
            "options": [
                "A. 2048",
                "B. 548",
                "C. 3548",
                "D. 804",
                "E. 2596"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "2596"
            ],
            "img_path": "2501.00380/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2505.03470",
        "img_path": "2505.03470/x1.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Blending 3D Geometry and Machine Learning for Multi-View Stereopsis",
                "B. Integrating Deep Neural Networks with Point Cloud Analysis for Object Reconstruction",
                "C. Enhancing Image Segmentation through Hybrid Geometric and Statistical Models",
                "D. A Comparative Study of Multi-View Photometric Approaches in 3D Scene Understanding",
                "E. Leveraging Geometric Priors and Machine Learning for Autonomous Depth Estimation"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Blending 3D Geometry and Machine Learning for Multi-View Stereopsis"
            ],
            "img_path": "2505.03470/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, the Dense-CostRegNet's approach to cost volume regularization is distinguished by its foundational inspiration, its specific U-Net structural adaptation, and a nuanced design philosophy for its distinct block types in different network stages. Which single sentence best synthesizes these defining architectural characteristics?",
            "options": [
                "A. The Dense-CostRegNet uniquely adapts DenseNet's principles into a U-Net structure, employing a simple dense block in the encoding phase to maintain fidelity to original DenseNet design, while its bottleneck and decoder stages use a feature-dense block specifically to generate new features and leverage dense connections for enhanced cost volume smoothness.",
                "B. Dense-CostRegNet primarily utilizes the multi-scale 3D-UNet architecture common in MVSNet, with slight modifications incorporating DenseNet's skip-connections uniformly across all layers to improve information flow similar to ResNet.",
                "C. The innovation of Dense-CostRegNet lies in its direct application of the DenseNet architecture for cost volume regularization, where all layers from encoding to decoding are identically structured dense blocks to maximize feature reuse from preceding layers.",
                "D. Dense-CostRegNet enhances cost regularization by using feature-dense blocks throughout its encoding phase for aggressive feature extraction, and simple dense blocks in the decoding phase to mirror ResNet's efficiency in reconstructing the cost volume.",
                "E. The Dense-CostRegNet is an evolution of CasMVSNet's stage-specific networks, primarily replacing its simple encoder-decoder structures with a recurrent GRU model enhanced by DenseNet-style connections for temporal cost volume refinement."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The Dense-CostRegNet uniquely adapts DenseNet's principles into a U-Net structure, employing a simple dense block in the encoding phase to maintain fidelity to original DenseNet design, while its bottleneck and decoder stages use a feature-dense block specifically to generate new features and leverage dense connections for enhanced cost volume smoothness."
            ],
            "img_path": "2505.03470/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-05"
    },
    {
        "id": "2501.00254",
        "img_path": "2501.00254/pdf3.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Analyzing the Impact of Distributed Architectures on Language Model Efficiency",
                "B. Adaptive Scheduling Techniques for Scalable Neural Network Training",
                "C. Resource Allocation Methods for Enhanced Performance in Transformer Models",
                "D. Automatically Planning Optimal Parallel Strategy for Large Language Models",
                "E. Evaluating Load Balancing Strategies in Multi-GPU Language Model Deployments"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Automatically Planning Optimal Parallel Strategy for Large Language Models"
            ],
            "img_path": "2501.00254/pdf3.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific percentage quantifies the average accuracy of the training duration simulation model—a model crucial for enabling the subsequent search space pruning of over 99%—when evaluated in multi-node experiments?",
            "options": [
                "A. 1",
                "B. 99",
                "C. 96",
                "D. 100",
                "E. 2"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "96"
            ],
            "img_path": "2501.00254/pdf3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00158",
        "img_path": "2501.00158/5dmasBufferAll.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Predictive Modeling of Urban Energy Demand Through Machine Learning and Spatial Analysis",
                "B. Analyzing District-Level Water Quality Variations Using Neural Networks",
                "C. Urban Water Consumption Forecasting Using Deep Learning and Correlated District Metered Areas",
                "D. Deep Learning Approaches for Urban Traffic Flow Prediction in Correlated Metered Zones",
                "E. Utilizing Correlated Sensor Networks for Environmental Pollution Forecasting in Urban Areas"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Urban Water Consumption Forecasting Using Deep Learning and Correlated District Metered Areas"
            ],
            "img_path": "2501.00158/5dmasBufferAll.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the approximate number of households, explicitly defined as the number of installed water meters, served by the Water Board of Limassol's water supply network?",
            "options": [
                "A. 17,000,000",
                "B. 180,000",
                "C. 5",
                "D. 110,000",
                "E. 3"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "110,000"
            ],
            "img_path": "2501.00158/5dmasBufferAll.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00057",
        "img_path": "2501.00057/vistabnet_architecture.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. VisTabNet: Adapting Vision Transformers for Tabular Data",
                "B. Analyzing Transformer Architectures for Text-Based Data Classification",
                "C. TabTransNet: Integrating Transformer Models with Time Series Analysis",
                "D. Enhancing Tabular Data Predictions Using Convolutional Neural Networks",
                "E. A Comparative Study of Deep Learning Models for Structured Data Processing"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "VisTabNet: Adapting Vision Transformers for Tabular Data"
            ],
            "img_path": "2501.00057/vistabnet_architecture.png"
        },
        "level2_qa": {
            "question": "In this paper, concerning the debate on deep learning versus ensemble methods for tabular data, what is the count of distinct cited experimental studies that are presented as evidence for the continued superior performance of carefully tuned ensemble methods over recent deep learning models?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 0",
                "D. 4",
                "E. 3"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.00057/vistabnet_architecture.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00039",
        "img_path": "2501.00039/llm_asr_rlhf.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Subhashini Venugopalan",
                "B. Jimmy Tobin",
                "C. Marilyn Ladewig",
                "D. Katherine Heller",
                "E. Chirag Nagpal"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Chirag Nagpal"
            ],
            "img_path": "2501.00039/llm_asr_rlhf.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence best describes the specific contribution of employing reinforcement learning with rewards based on syntactic and semantic accuracy to the LLM, following its initial adaptation for speech recognition through vocabulary repurposing and supervised fine-tuning?",
            "options": [
                "A. It enables the LLM to initially process speech inputs by replacing low-frequency text tokens with audio tokens, forming the foundational step for ASR capabilities.",
                "B. It allows the LLM to achieve state-of-the-art performance in general speech recognition, surpassing existing specialized ASR systems across all domains.",
                "C. It primarily serves to refine the LLM's syntactic accuracy on standard speech, matching the performance of direct supervised fine-tuning without needing semantic measures.",
                "D. It further generalizes the LLM's capabilities to more effectively recognize disordered speech, demonstrating superior adaptation compared to supervised fine-tuning alone in such challenging settings.",
                "E. It expands the LLM's vocabulary with new audio tokens derived from human preference data, leading to improved semantic understanding in common speech scenarios."
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "It further generalizes the LLM's capabilities to more effectively recognize disordered speech, demonstrating superior adaptation compared to supervised fine-tuning alone in such challenging settings."
            ],
            "img_path": "2501.00039/llm_asr_rlhf.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00987",
        "img_path": "2501.00987/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Cate Duncan",
                "B. Shiran Dudy",
                "C. Leheng Sheng",
                "D. Wuttikorn Ponwitayarat",
                "E. Yanhong Zeng"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Shiran Dudy"
            ],
            "img_path": "2501.00987/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence articulates the resultant critical weakness of prevailing search engine prioritization, according to Phillips' analysis, stemming directly from their practice of ranking items despite the acknowledged non-comparability of different relevance dimensions?",
            "options": [
                "A. The author further acknowledges the complexity of relevance, highlighting its multi-dimensional nature, which renders these dimensions non-comparable.",
                "B. Despite this non-comparability, search engines still assign priorities to items, suggesting a semblance of comparability, albeit not on a relevance scale.",
                "C. Consequently, such prioritization is susceptible to influence from non-epistemic agendas.",
                "D. Furthermore, as outlined in Phillips[6], the enforced ranking and hierarchical structuring of items within search results introduces platform bias, which is influenced by factorsother than relevance.",
                "E. We posit that the concept of prioritization warrants scrutiny, along with the consistent hierarchical ordering that underlies this lack of neutrality."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Consequently, such prioritization is susceptible to influence from non-epistemic agendas."
            ],
            "img_path": "2501.00987/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00406",
        "img_path": "2501.00406/Fig4.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Nonlinear Dynamics and Mode Coupling in Photonic Crystal Microcavities",
                "B. Quantum Interference Effects in Multi-Mode Semiconductor Lasers",
                "C. Phase Transition Mechanisms in Whispering Gallery Mode Resonators",
                "D. Mode Locking and Stability Analysis in Coupled Optical Fiber Cavities",
                "E. Topological Switching via Exceptional Point Pairs in an Optical Microcavity Laser"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Topological Switching via Exceptional Point Pairs in an Optical Microcavity Laser"
            ],
            "img_path": "2501.00406/Fig4.png"
        },
        "level2_qa": {
            "question": "In this paper, which specific numerical value, identified as an approximate critical threshold for a key parameter, signifies the point at which the system transitions between distinct classes of avoided crossings, characterized by a reversal in whether the real or the imaginary part of the eigenvalues undergoes an avoided crossing versus a direct crossing, thereby fundamentally altering the system's response near exceptional points?",
            "options": [
                "A. 0.6001",
                "B. 0.765",
                "C. 2.0",
                "D. 1.0",
                "E. 0.5372"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "0.765"
            ],
            "img_path": "2501.00406/Fig4.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00751",
        "img_path": "2501.00751/MISM.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. HCMA-UNet: A Hybrid CNN-Mamba UNet with Axial Self-Attention for Efficient Breast Cancer Segmentation",
                "B. Deep Residual Networks with Spatial Attention for Prostate Cancer Detection",
                "C. Multi-Scale Feature Fusion in CNN Models for Lung Nodule Classification",
                "D. Transformer-Based Framework for Automated Skin Lesion Analysis",
                "E. Dual-Path CNN with Channel-Wise Attention for Brain Tumor Segmentation"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "HCMA-UNet: A Hybrid CNN-Mamba UNet with Axial Self-Attention for Efficient Breast Cancer Segmentation"
            ],
            "img_path": "2501.00751/MISM.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the precise numerical value reported as a measure of the computational operations per second, indicative of the proposed lightweight model's workload, explicitly distinguished from the model's size in terms of parameters?",
            "options": [
                "A. 2.87",
                "B. 3.00",
                "C. 126.44",
                "D. 1.00",
                "E. 9.00"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "126.44"
            ],
            "img_path": "2501.00751/MISM.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00673",
        "img_path": "2501.00673/Combined-Controlled-Hallucinations.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Akash Kumar Panda",
                "B. Bill Wu",
                "C. V. Velan",
                "D. Andrew Svesko",
                "E. Bart Kosko"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Akash Kumar Panda"
            ],
            "img_path": "2501.00673/Combined-Controlled-Hallucinations.png"
        },
        "level2_qa": {
            "question": "In this paper, in a single sentence, describe the critical challenge inherent in relying solely on individual expert FCMs with supervised learning for phantom node estimation that the subsequent convex combination of these FCMs is designed to overcome when modeling systems with multiple unacknowledged causal variables.",
            "options": [
                "A. The fundamental difficulty is that individual expert FCMs, even with supervised learning, cannot initiate the process of causal hallucination necessary for phantom node detection, a role exclusively fulfilled by the convex combination.",
                "B. The critical issue is the inherent inability of supervised learning within individual FCMs to achieve even partial control over causal hallucinations, necessitating the mixing stage to introduce this control and stabilize equilibrium approximations.",
                "C. The main challenge is that while individual expert FCMs can estimate single phantom nodes, this process is computationally intensive and not inherently scalable to practically identify and integrate the effects of multiple distinct phantom nodes for a comprehensive equilibrium approximation, a limitation the mixing stage mitigates.",
                "D. The significant problem is that convex combination, while useful for averaging, cannot by itself determine the specific edge weights for phantom nodes, requiring the prior, computationally lighter, supervised learning stage in individual FCMs to define these weights accurately.",
                "E. The core limitation is that acyclic DAG models, initially considered by experts, lack the feedback mechanisms to represent dynamic equilibria, forcing a shift to FCMs whose mixing is then primarily aimed at reducing the dimensionality introduced by multiple experts rather than phantom node complexity."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The main challenge is that while individual expert FCMs can estimate single phantom nodes, this process is computationally intensive and not inherently scalable to practically identify and integrate the effects of multiple distinct phantom nodes for a comprehensive equilibrium approximation, a limitation the mixing stage mitigates."
            ],
            "img_path": "2501.00673/Combined-Controlled-Hallucinations.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00602",
        "img_path": "2501.00602/x7.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. LUMEN: Light-Based Urban Mapping for Environmental Navigation",
                "B. TRANSCAPE: Temporal Analysis of Changing Urban Phenomena in Outdoor Environments",
                "C. VISTA: Visual Integration System for Tracking Architectural Developments",
                "D. STORM: Spatio-Temporal Reconstruction Model for Large-Scale Outdoor Scenes",
                "E. GEOFRAME: Geospatial Framework for Analyzing Dynamic Outdoor Landscapes"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "STORM: Spatio-Temporal Reconstruction Model for Large-Scale Outdoor Scenes"
            ],
            "img_path": "2501.00602/x7.png"
        },
        "level2_qa": {
            "question": "In this paper, given that a 3D Gaussian is defined with parameters for center (ℝ³), orientation (represented by a 4D quaternion), scale (ℝ³), opacity (ℝ⁺), and color (ℝ³), what is the numerical dimensionality of the output vector per pixel-aligned Gaussian that the model directly predicts from the ViT feature map using a linear layer?",
            "options": [
                "A. 14",
                "B. 10",
                "C. 16",
                "D. 12",
                "E. 5"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "12"
            ],
            "img_path": "2501.00602/x7.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01282",
        "img_path": "2501.01282/x1.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. CultureVLM: Characterizing and Improving Cultural Understanding of Vision-Language Models for over 100 Countries",
                "B. Cross-Cultural Adaptation of Vision-Language Models for Multinational Image Interpretation",
                "C. Enhancing Multimodal Model Performance through Regional Cultural Context Integration",
                "D. Evaluating Vision-Language Systems in Diverse Socio-Cultural Environments Across Continents",
                "E. Toward Inclusive Vision-Language Understanding: Addressing Cultural Bias in Global Datasets"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "CultureVLM: Characterizing and Improving Cultural Understanding of Vision-Language Models for over 100 Countries"
            ],
            "img_path": "2501.01282/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value is explicitly provided as the threshold which the correct annotation percentage of evaluation set samples by the automated process exceeded, thereby supporting the conclusion of the pipeline's high effectiveness?",
            "options": [
                "A. 19682",
                "B. 16",
                "C. 40",
                "D. 98989898",
                "E. 188"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "98989898"
            ],
            "img_path": "2501.01282/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01395",
        "img_path": "2501.01395/x1.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Effects of intra-city mobility on epidemic thresholds",
                "B. Modeling the role of social networks in infectious disease transmission",
                "C. Impact of inter-city interactions on disease scaling",
                "D. Urban population density and its influence on pandemic spread",
                "E. Analyzing environmental factors in disease outbreak dynamics"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Impact of inter-city interactions on disease scaling"
            ],
            "img_path": "2501.01395/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, provide a single sentence that most accurately and comprehensively synthesizes the findings regarding the elasticity of scale (ε) for infectious disease incidence in response to proportional changes in city population and commuter numbers, the conditions influencing different scaling regimes, and the comparative impact of these two demographic factors.",
            "options": [
                "A. Disease incidence consistently exhibits increasing returns to scale (ε > 1) in large urban areas due to overcrowding, while smaller cities always show negative scaling (ε < 0) because initial growth improves healthcare, and population changes are always less impactful than an equivalent proportional change in commuters.",
                "B. The study primarily concludes that most Brazilian cities demonstrate decreasing returns to scale (0 < ε < 1) for all seven diseases, meaning increased population and commuters invariably lead to a proportionally smaller rise in cases, with commuter numbers having a significantly stronger effect than population size.",
                "C. Across all diseases, a generalized scaling framework reveals that while most cities experience sublinear responses (0 < ε < 1) to combined increases in population and commuters, a notable proportion also sees superlinear responses (ε > 1), and a few small, isolated cities can even experience reduced disease incidence (ε < 0) with initial growth due to hypothesized improvements in conditions; however, changes in population size generally exert a greater influence on disease cases than proportional changes in commuter numbers.",
                "D. The translog model exclusively shows that for diseases like pertussis, negative elasticity of scale (ε < 0) is the dominant regime, indicating that increased connectivity through commuters always reduces disease burden irrespective of population changes, which play a secondary, often negligible, role.",
                "E. Inter-city interactions, proxied by commuters, are the sole determinant of disease scaling, with the traditional urban scaling model (population-only) being entirely invalidated; all cities transition from negative to sublinear to superlinear scaling for every disease type as they grow."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Across all diseases, a generalized scaling framework reveals that while most cities experience sublinear responses (0 < ε < 1) to combined increases in population and commuters, a notable proportion also sees superlinear responses (ε > 1), and a few small, isolated cities can even experience reduced disease incidence (ε < 0) with initial growth due to hypothesized improvements in conditions; however, changes in population size generally exert a greater influence on disease cases than proportional changes in commuter numbers."
            ],
            "img_path": "2501.01395/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01138",
        "img_path": "2501.01138/x6.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Graph-Based Attention Mechanisms for Robust Channel Estimation in Wireless Networks",
                "B. Semantics-Guided Diffusion for Deep Joint Source-Channel Coding in Wireless Image Transmission",
                "C. Optimization of Source Coding Techniques for High-Speed Image Compression in 5G Systems",
                "D. Deep Reinforcement Learning Approaches to Adaptive Modulation in Wireless Image Communication",
                "E. Multi-Modal Feature Fusion for Enhanced Error Correction in Wireless Video Transmission"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Semantics-Guided Diffusion for Deep Joint Source-Channel Coding in Wireless Image Transmission"
            ],
            "img_path": "2501.01138/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific issue introduced by the original step matching method for initiating the diffusion denoising process from the channel output in the context of DeepJSCC, and what exact modification do the authors propose to address this problem?",
            "options": [
                "A. The step matching error arises from mapping the SNR to a discrete timestep; the authors address it by using the noise level as a continuous input instead of the discrete timestep.",
                "B. The step matching error is due to incorrect semantic guidance integration; the authors resolve it by pre-training the DM with side information.",
                "C. The step matching error comes from channel estimation inaccuracies; the authors address it by introducing additional pilot transmissions.",
                "D. The step matching error results from noise variance quantization; the authors solve it by averaging over all possible SNR values.",
                "E. The step matching error is caused by non-linear denoising functions; the authors resolve it by linearizing the denoising function."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The step matching error arises from mapping the SNR to a discrete timestep; the authors address it by using the noise level as a continuous input instead of the discrete timestep."
            ],
            "img_path": "2501.01138/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01509",
        "img_path": "2501.01509/x1.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Deep Learning Techniques for Anomaly Detection in Particle Accelerator Systems",
                "B. AI-Enabled Operations at Fermi Complex: Multivariate Time Series Prediction for Outage Prediction and Diagnosis",
                "C. Optimization of Maintenance Schedules Using Predictive Analytics at Large Hadron Facilities",
                "D. Multimodal Sensor Fusion for Real-Time Fault Identification in High-Energy Physics Experiments",
                "E. Leveraging Reinforcement Learning for Adaptive Control in Complex Scientific Infrastructures"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "AI-Enabled Operations at Fermi Complex: Multivariate Time Series Prediction for Outage Prediction and Diagnosis"
            ],
            "img_path": "2501.01509/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what value, presented as an approximate daily figure, represents a key challenge related to operator cognitive load and response timeliness that the proposed AI framework's predictive and analytical capabilities are intended to alleviate?",
            "options": [
                "A. 80",
                "B. 400",
                "C. 2703",
                "D. 4000",
                "E. 15000"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "15000"
            ],
            "img_path": "2501.01509/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01108",
        "img_path": "2501.01108/x3.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. WaveFormNet: Unsupervised Audio Feature Extraction Using Temporal Convolutional Networks",
                "B. Harmony2Vec: Contextual Embedding for Music Genre Classification with Deep Autoencoders",
                "C. MuQ: Self-Supervised Music Representation Learning with Mel Residual Vector Quantization",
                "D. RhythmGAN: Generative Adversarial Networks for Beat Pattern Synthesis in Music",
                "E. SpectraNet: Multi-Scale Spectral Analysis for Instrument Recognition in Polyphonic Audio"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "MuQ: Self-Supervised Music Representation Learning with Mel Residual Vector Quantization"
            ],
            "img_path": "2501.01108/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, using how many thousands of hours of open-source pre-training data did the MuQ model, which predicts tokens from a Mel-RVQ composed of a single-layer linear encoder and a single-layer linear decoder, initially surpass previous self-supervised music representation models?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 0.9",
                "D. 160",
                "E. N"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "0.9"
            ],
            "img_path": "2501.01108/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01013",
        "img_path": "2501.01013/conditional_generation.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Incomplete Data Multi-Source Static Computed Tomography Reconstruction with Diffusion Priors and Implicit Neural Representation",
                "B. Dynamic Reconstruction of Multi-Modal CT Images Using Graph-Based Diffusion Models",
                "C. Neural Implicit Representations for Complete Data Fusion in Multi-Source Static Tomography",
                "D. Advanced Diffusion Priors for Enhanced MRI Reconstruction from Sparse Measurements",
                "E. Multi-View Computed Tomography Reconstruction via Deep Learning and Temporal Priors"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Incomplete Data Multi-Source Static Computed Tomography Reconstruction with Diffusion Priors and Implicit Neural Representation"
            ],
            "img_path": "2501.01013/conditional_generation.png"
        },
        "level2_qa": {
            "question": "In this paper, regarding the proposed 'new approximate posterior sampling strategy' for MSCT volume reconstruction, what is the implied relationship to the broader class of 'approximated posterior samplers' discussed in the context of their theoretical guarantees?",
            "options": [
                "A. The proposed strategy is presented as a theoretically guaranteed alternative that overcomes the polynomial time convergence limitations of prior samplers.",
                "B. The proposed strategy is acknowledged as being one instance of such 'approximated posterior samplers', relying on numerical performance despite lacking theoretical convergence guarantees in polynomial time.",
                "C. The paper claims its 'new approximate posterior sampling strategy' achieves theoretical convergence by modifying the Stochastic Differential Equation (SDE) formulation, unlike other 'approximated posterior samplers'.",
                "D. The 'new approximate posterior sampling strategy' is designed to entirely avoid the issues of theoretical guarantees by focusing solely on self-supervised learning for convergence within the measurement subspace.",
                "E. The paper distinguishes its strategy by proving polynomial time convergence for the specific case of Multi-Source Static CT (MSCT), unlike general 'approximated posterior samplers'."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The proposed strategy is acknowledged as being one instance of such 'approximated posterior samplers', relying on numerical performance despite lacking theoretical convergence guarantees in polynomial time."
            ],
            "img_path": "2501.01013/conditional_generation.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01103",
        "img_path": "2501.01103/x1.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Enhancing speech emotion classification through attention-based recurrent neural networks",
                "B. Exploring convolutional autoencoders for robust speech feature extraction",
                "C. learning discriminative features from spectrograms using center loss for speech emotion recognition",
                "D. A comparative study of feature normalization techniques in speech emotion analysis",
                "E. Utilizing generative adversarial networks for data augmentation in speech emotion recognition"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "learning discriminative features from spectrograms using center loss for speech emotion recognition"
            ],
            "img_path": "2501.01103/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the calculated difference, in percentage points, between the specific integer benchmark percentages that the accuracy improvements are stated to exceed for Short Time Fourier Transform spectrograms versus Mel-spectrograms, respectively, due to the introduction of center loss?",
            "options": [
                "A. 0.5",
                "B. 1",
                "C. 3.5",
                "D. 7",
                "E. 0"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2501.01103/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01398",
        "img_path": "2501.01398/OAI-testbed.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Optimizing Network Latency for Virtual Reality Streaming in 5G Environments",
                "B. A Framework for Energy-Efficient Data Processing in Mobile Augmented Reality",
                "C. Adaptive Bandwidth Allocation Strategies for Mixed Reality Devices in Next-Gen Networks",
                "D. Enhancing User Experience through Dynamic Load Balancing in 5G-based Immersive Applications",
                "E. A Proof of Concept Resource Management Scheme for Augmented Reality Applications in 5G Systems"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "A Proof of Concept Resource Management Scheme for Augmented Reality Applications in 5G Systems"
            ],
            "img_path": "2501.01398/OAI-testbed.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the discussion of splitting the roundtrip delay budget into hop delay budgets, how many distinct primary negative consequences or complex operational responsibilities for the Mobile Network Operator (MNO) are explicitly identified as directly resulting from choosing and implementing this hop decomposition strategy?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.01398/OAI-testbed.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01473",
        "img_path": "2501.01473/inf2.jpg",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Unraveling Indirect In-Context Learning Using Influence Functions",
                "B. Exploring Direct Context Adaptation Through Gradient-Based Methods",
                "C. Analyzing the Role of Attention Mechanisms in Contextual Learning",
                "D. Evaluating Transfer Learning Techniques in Natural Language Processing",
                "E. Investigating Model Robustness via Sensitivity Analysis"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Unraveling Indirect In-Context Learning Using Influence Functions"
            ],
            "img_path": "2501.01473/inf2.jpg"
        },
        "level2_qa": {
            "question": "In this paper, what is the maximum reported average accuracy improvement, in percentage points, obtained by enhancing a conventional In-Context Learning demonstration selection method with Influence Function-based reweighting when tested on datasets specifically designed to include mislabeled examples?",
            "options": [
                "A. 0.37",
                "B. 1.45",
                "C. 2.90",
                "D. 2.92",
                "E. 2.94"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "2.94"
            ],
            "img_path": "2501.01473/inf2.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01172",
        "img_path": "2501.01172/x5.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Kequan Zhou",
                "B. Guangyi Zhang",
                "C. Yunlong Cai",
                "D. Qiyu Hu",
                "E. Guanding Yu"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Kequan Zhou"
            ],
            "img_path": "2501.01172/x5.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific sequence of operations within the Perturbation Anticipation Module (PAM) enables the Adjustable Perturbation Generator (APG) to proactively incorporate the power constraint `ϵ` for generating jamming signals across a spectrum of power levels, prior to the final power constraining step?",
            "options": [
                "A. The power constraint `ϵ` is applied directly to the final output of the APG's residual blocks to ensure the generated jamming signals do not exceed the specified power, with PAMs only monitoring this process and adjusting parameters if `ϵ` is violated.",
                "B. The power constraint `ϵ` is determined by the ROME framework's Multi-level Perturbation Detection (MPD) module based on channel conditions and fed back to the APG's PAMs to dynamically adjust the generated jamming signal strength for testing ROME's adaptive robustness.",
                "C. `ϵ` is appended as side information to the global feature vector `𝐚` to create an extended vector `𝐚̂`; `𝐚̂` is then processed by fully-connected layers to produce a calibration vector `𝐚̃` which, after normalization, calibrates the intermediate features `𝐟`, thereby informing the generator about the power constraint ahead of final constraining.",
                "D. Within PAMs, `ϵ` serves primarily as a direct scaling factor for the global average pooled vector `𝐚` before `𝐚` is immediately used to calibrate the features `𝐟`, bypassing the need for fully-connected layers or the creation of an extended vector `𝐚̂` for efficiency.",
                "E. The PAMs utilize `ϵ` to select an appropriate pre-generated perturbation signal from a stored library corresponding to that power level, with end-to-end training optimizing this selection mechanism rather than influencing the perturbation generation process itself."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "`ϵ` is appended as side information to the global feature vector `𝐚` to create an extended vector `𝐚̂`; `𝐚̂` is then processed by fully-connected layers to produce a calibration vector `𝐚̃` which, after normalization, calibrates the intermediate features `𝐟`, thereby informing the generator about the power constraint ahead of final constraining."
            ],
            "img_path": "2501.01172/x5.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01409",
        "img_path": "2501.01409/x2.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. JOG3R: Enhancing 2D Video Synthesis with Temporal Coherence",
                "B. Towards Real-Time 3D Reconstruction from Single-View Videos",
                "C. JOG3R: A Framework for Multimodal Video Generation using GANs",
                "D. Investigating High-Resolution Video Generation through Depth Estimation",
                "E. JOG3R: Towards 3D-Consistent Video Generators"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "JOG3R: Towards 3D-Consistent Video Generators"
            ],
            "img_path": "2501.01409/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific numerical citation index associated with the research that validates the strategy of utilizing features from diffusion time steps where t is small, based on the principle that such features are richer in low-level details and thus more effective for building inter-frame geometric correspondences?",
            "options": [
                "A. 39",
                "B. 59",
                "C. 70",
                "D. 79",
                "E. 83"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "70"
            ],
            "img_path": "2501.01409/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01329",
        "img_path": "2501.01329/x1.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Chaozheng Wang",
                "B. Cuiyun Gao",
                "C. Xiaoqian Jiao",
                "D. Shuzheng Gao",
                "E. Chun Yong Chong"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Shuzheng Gao"
            ],
            "img_path": "2501.01329/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific numerical value represents the minimum line coverage improvement percentage of MAPS over baseline methods when configured with the highest number of iterations discussed in its performance evaluation?",
            "options": [
                "A. 27.0",
                "B. 9.3",
                "C. 7.94",
                "D. 3",
                "E. 2"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "7.94"
            ],
            "img_path": "2501.01329/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01149",
        "img_path": "2501.01149/pipeline.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Yuxiang Chai",
                "B. Hanhao Li",
                "C. Jiayu Zhang",
                "D. Liang Liu",
                "E. Guangyi Liu"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Yuxiang Chai"
            ],
            "img_path": "2501.01149/pipeline.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct action types in A3's extended action space, formed by combining the actions common to AitW, AitZ, and AMEX with all distinct actions explicitly listed as additions from AndroidControl?",
            "options": [
                "A. 8",
                "B. 10",
                "C. 11",
                "D. 3",
                "E. 9"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "11"
            ],
            "img_path": "2501.01149/pipeline.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01204",
        "img_path": "2501.01204/fig1_setup_v8.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. High-Power Terahertz Emission from Doped Lithium Niobate Using Fiber Laser Sources",
                "B. Enhanced Mid-Infrared Generation in Lithium Niobate via Resonant Optical Cavities",
                "C. Passive Resonator Design for Efficient Ultrafast Laser Frequency Conversion in Nonlinear Crystals",
                "D. Investigation of Terahertz Waveforms in Lithium Niobate under Continuous-Wave Solid-State Laser Irradiation",
                "E. Ytterbium-laser-driven THz generation in thin lithium niobate at 1.9 kW average power in a passive enhancement cavity"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Ytterbium-laser-driven THz generation in thin lithium niobate at 1.9 kW average power in a passive enhancement cavity"
            ],
            "img_path": "2501.01204/fig1_setup_v8.png"
        },
        "level2_qa": {
            "question": "In this paper, by what amount, in femtoseconds, is the FWHM pulse duration estimated to increase from the characterized laser output pulse immediately prior to entering the enhancement cavity to the actual driving pulse within the enhancement cavity used for optical rectification?",
            "options": [
                "A. 0 fs",
                "B. 40 fs",
                "C. 60 fs",
                "D. 85 fs",
                "E. 100 fs"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "60"
            ],
            "img_path": "2501.01204/fig1_setup_v8.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01090",
        "img_path": "2501.01090/x2.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. TrapSet: Defending Neural Networks Against Model Stealing",
                "B. Poisoned Data: Exploring Backdoor Vulnerabilities in Deep Learning Models",
                "C. SecureNet: Robustness of Models under Adversarial Extraction Attacks",
                "D. Invisible Triggers: Detecting Backdoors in Machine Learning Systems",
                "E. HoneypotNet: Backdoor Attacks Against Model Extraction"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "HoneypotNet: Backdoor Attacks Against Model Extraction"
            ],
            "img_path": "2501.01090/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what single integer quantifies the number of distinct benchmark datasets utilized for the empirical demonstration of HoneypotNet's success in injecting backdoors into substitute models, a success specifically substantiated by achieved attack rates documented to be between 56.99% and 92.35%?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 8"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2501.01090/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01095",
        "img_path": "2501.01095/mc-framework.jpg",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Guofu Cao",
                "B. Yan Fan",
                "C. Lei Cao",
                "D. Zhilong Hou",
                "E. Yongsheng Huang"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Lei Cao"
            ],
            "img_path": "2501.01095/mc-framework.jpg"
        },
        "level2_qa": {
            "question": "In this paper, considering the specific methodologies detailed for constructing the Monte Carlo framework, what is the sum of: the number of distinct models stated as *used* for electron transport in liquids (based on a specified theory), and the number of distinct techniques identified that *can be used* to mitigate collision frequency selection issues in an electric field?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 1"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2501.01095/mc-framework.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00944",
        "img_path": "2501.00944/teaser_2.jpg",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Gradient Spectrum: Improving Texture and Color Fidelity in Image Synthesis",
                "B. Morphology-Aware Networks for Semantic Segmentation in Image Generation",
                "C. Enhancing Structural Coherence in Masked Image Reconstruction Using Adversarial Learning",
                "D. Diffusion Prism: Enhancing Diversity and Morphology Consistency in Mask-to-Image Diffusion",
                "E. Diversity-Driven Latent Space Exploration for Conditional Image Generation"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Diffusion Prism: Enhancing Diversity and Morphology Consistency in Mask-to-Image Diffusion"
            ],
            "img_path": "2501.00944/teaser_2.jpg"
        },
        "level2_qa": {
            "question": "In this paper, given Diffusion Prism's successful application to diverse biological patterns (such as nano-dendritic, retina fundus, fingerprint, and Purkinje neuron samples) as a 'training-free framework', which single sentence most directly points to the fundamental analytical understanding that underpins its core image generation techniques, thereby implying their inherent generalizability across different sparse binary inputs without necessitating pattern-specific retraining?",
            "options": [
                "A. Diffusion Prism, a training-free framework that efficiently transforms binary masks into realistic and diverse samples while preserving morphological features.",
                "B. The experimental results on dendritic patterns demonstrated that our method significantly improves the diversity of generated images, outperforming baseline and other methods in both quantitative evaluations and visual comparisons.",
                "C. After comprehensively analyzing the signal transmission in image-to-image diffusion, we proposed an effective combination of controlled noise and chromatic aberration to enhance diversity without sacrificing the structural integrity of the input masks.",
                "D. The generated samples present realistic styles and diverse backgrounds while maintaining consistent morphology aligned with the input binary masks, which proved the adaptability and effectiveness in other domains.",
                "E. Notably, the inclusion of chromatic aberration allows for a more effective use of noise, leading to better results compared to the noise-only approach, as shown in Figure11(a)."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "After comprehensively analyzing the signal transmission in image-to-image diffusion, we proposed an effective combination of controlled noise and chromatic aberration to enhance diversity without sacrificing the structural integrity of the input masks."
            ],
            "img_path": "2501.00944/teaser_2.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01281",
        "img_path": "2501.01281/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Optimal Beamforming Strategies for Cooperative ISAC Networks Using Reinforcement Learning",
                "B. Towards Intelligent Antenna Positioning: Leveraging DRL for FAS-Aided ISAC Systems",
                "C. Enhancing Signal Detection in MIMO Systems Through Adaptive Antenna Arrays",
                "D. Deep Learning Approaches for Resource Allocation in Full-Duplex ISAC Environments",
                "E. Robust Channel Estimation Techniques for FAS-Enabled Wireless Communication Systems"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Towards Intelligent Antenna Positioning: Leveraging DRL for FAS-Aided ISAC Systems"
            ],
            "img_path": "2501.01281/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the detailed description of the reward function and the composition of the state vector input to the Actor network, how many of the explicitly defined penalty terms within the reward function are primarily and directly determined by the 'antenna positions' portion of the state vector, as distinct from its 'beamforming features' portion?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 3",
                "E. 4"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.01281/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01235",
        "img_path": "2501.01235/x2.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Xu Chen",
                "B. Chengming Xu",
                "C. Zhiyao Wang",
                "D. Junwei Zhu",
                "E. Xiaobin Hu"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Zhiyao Wang"
            ],
            "img_path": "2501.01235/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence best describes the foundational insight, empirically supported by the pilot experiment, that underpins the SVFR framework's core strategy of integrating Blind Face Restoration (BFR), inpainting, and colorization for Generalized Video Face Restoration (GVFR)?",
            "options": [
                "A. The inherent temporal modeling capabilities of Stable Video Diffusion are the primary factor enabling effective integration of diverse restoration tasks within the SVFR framework.",
                "B. Blind Face Restoration, inpainting, and colorization operate on fundamentally distinct data distributions, necessitating their isolated processing even within a generalized video restoration context.",
                "C. The three subtasks of BFR, inpainting, and colorization within GVFR possess shared, mutually beneficial prior knowledge, the leveraging of which is confirmed by superior transfer learning outcomes when compared to training from scratch.",
                "D. Enhanced computational efficiency gained from a unified architecture is the principal motivation for combining BFR, inpainting, and colorization, rather than any inherent synergy in their underlying learnable representations.",
                "E. The primary challenge in GVFR is the scarcity of high-quality video data, which the pilot experiment demonstrates can be entirely overcome by transfer learning from image-based BFR models."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The results are presented in Tab.1, from which we can find that the transfer learning setting consistently outperforms the training-from-scratch setting in all tasks, thus indicating that these three subtasks in the GVFR indeed share similar prior knowledge that can benefit each other."
            ],
            "img_path": "2501.01235/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01458",
        "img_path": "2501.01458/figure1.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Integrating Protein Interaction Networks and Deep Learning for Drug Target Prioritization",
                "B. A Graph-Based Approach to Predicting Druggable Genes Using Molecular Interaction Data",
                "C. Network-Centric Models for Identifying Therapeutic Targets in Complex Diseases",
                "D. GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification",
                "E. Computational Frameworks for Mapping Gene-Drug Interactions via Protein Networks"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification"
            ],
            "img_path": "2501.01458/figure1.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value is obtained by multiplying the number of SAGEConv layers in the ImGAGN encoder by the ratio of discriminator training epochs (per generator epoch) to the number of SAGEConv layers in the ImGAGN discriminator, and then adding the product of the number of fully connected layers in the ImGAGN generator and the number of distinct Pharos label sets used for evaluating GAN-TAT configurations?",
            "options": [
                "A. 29",
                "B. 38",
                "C. 49",
                "D. 69",
                "E. 100"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "49"
            ],
            "img_path": "2501.01458/figure1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01377",
        "img_path": "2501.01377/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Enhancing Medical Vision-Language Models via Contextual Symptom Analysis",
                "B. Developing Multimodal Clinical AI Systems Using Patient Data Integration",
                "C. Training Medical Large Vision-Language Models with Abnormal-Aware Feedback",
                "D. Optimizing Diagnostic Imaging Interpretation through Deep Learning Feedback Loops",
                "E. Adaptive Training Strategies for Large-Scale Medical Language-Vision Models"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Training Medical Large Vision-Language Models with Abnormal-Aware Feedback"
            ],
            "img_path": "2501.01377/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the Abnormal-Aware Rewarding stage, what constitutes the direct computational basis for the Vision Relevance Reward (VRR) by quantifying the relationship between two specific information elements?",
            "options": [
                "A. Quantification of spatial overlap between predicted and ground truth abnormal bounding boxes.",
                "B. Summation of attention scores reflecting the relevance of textual tokens (representing abnormal categories) to specific image patches (identified as abnormal regions).",
                "C. An evaluation by an LLM relevance reward model of the generated textual diagnosis against the visual input.",
                "D. The degree of alignment between diagnoses generated using identified abnormal areas by GPT-4V and the model's own generated diagnoses.",
                "E. The improvement in understanding medical abnormal regions and generating diagnoses, achieved through instruction tuning."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Summation of attention scores reflecting the relevance of textual tokens (representing abnormal categories) to specific image patches (identified as abnormal regions)."
            ],
            "img_path": "2501.01377/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01184",
        "img_path": "2501.01184/x2.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Vulnerability-Aware Spatio-Temporal Learning for Generalizable and Interpretable Deepfake Video Detection",
                "B. Robust Multi-Modal Analysis for Cross-Domain Deepfake Image Classification",
                "C. Adaptive Temporal Feature Extraction for Enhanced Real-Time Video Forgery Detection",
                "D. Graph-Based Neural Networks for Explainable Face Manipulation Recognition",
                "E. Uncertainty-Driven Framework for Video Content Authenticity Verification"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Vulnerability-Aware Spatio-Temporal Learning for Generalizable and Interpretable Deepfake Video Detection"
            ],
            "img_path": "2501.01184/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, provide a description of the specific category of techniques whose strategic adaptation and integration forms the primary basis of FakeSTormer's novelty in addressing the dual challenges of generalizability and interpretability in video deepfake detection, considering their prior status in the video-level context according to the authors.",
            "options": [
                "A. Novel neural network architectures exclusively designed for long-range temporal dependencies in videos, representing a complete departure from image-based detection paradigms.",
                "B. Data augmentation techniques focused solely on diversifying artifact types within existing public fake video datasets to cover unseen manipulations.",
                "C. Mechanisms such as multi-task learning and sophisticated data synthesis (like blending-based approaches), which were primarily proven effective in image-based deepfake detection but previously underexplored or disregarded for video applications.",
                "D. A training methodology that completely eschews pseudo-fake data generation, relying exclusively on anomaly detection from real videos to enhance robustness.",
                "E. The pioneering development and analysis of entirely new classes of spatio-temporal artifacts inherent to video generation models, previously uncatalogued in the literature."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Mechanisms such as multi-task learning and sophisticated data synthesis (like blending-based approaches), which were primarily proven effective in image-based deepfake detection but previously underexplored or disregarded for video applications."
            ],
            "img_path": "2501.01184/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01646",
        "img_path": "2501.01646/DMRG.drawio.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Adaptive Quantum Circuit Optimization for Efficient Ground State Energy Estimation",
                "B. Hybrid Classical-Quantum Algorithms for Enhanced Molecular Simulation Accuracy",
                "C. Resource-Efficient Variational Quantum Algorithms Leveraging Parameter Initialization Strategies",
                "D. Noise-Mitigated Variational Quantum Eigensolver with Pre-training and Zero-Noise Extrapolation",
                "E. Error-Resilient Quantum Computing via Layered Noise Reduction Techniques"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Noise-Mitigated Variational Quantum Eigensolver with Pre-training and Zero-Noise Extrapolation"
            ],
            "img_path": "2501.01646/DMRG.drawio.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence best synthesizes the multifaceted approach used to ensure both circuit stability and robust noise elimination, ultimately enabling accurate molecular ground state energy calculations in noisy environments?",
            "options": [
                "A. The algorithm primarily relies on an advanced neural network architecture to directly correct errors originating from depolarizing, thermal relaxation, and bit-flip noise during quantum computations.",
                "B. Superior performance is achieved by meticulously designing quantum circuits based on matrix product states, which inherently cancels all forms of quantum decoherence and measurement errors.",
                "C. The method integrates matrix product state-inspired circuit pre-training for initial stability with a synergistic combination of zero-noise extrapolation enhanced by neural networks and an intelligent Pauli string measurement grouping strategy to comprehensively mitigate diverse noise impacts.",
                "D. The core innovation lies in a novel gradient descent optimization technique applied to the classical part of the VQE, significantly improving the convergence speed towards the true ground state energy.",
                "E. By exclusively focusing on reducing the number of Hamiltonian Pauli string measurements through intelligent grouping, the algorithm effectively minimizes the dominant source of error, identified as sampling inefficiency, thereby achieving high precision."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The method integrates matrix product state-inspired circuit pre-training for initial stability with a synergistic combination of zero-noise extrapolation enhanced by neural networks and an intelligent Pauli string measurement grouping strategy to comprehensively mitigate diverse noise impacts."
            ],
            "img_path": "2501.01646/DMRG.drawio.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01496",
        "img_path": "2501.01496/x3.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. HERA: A Batch-Processing, Multi-Layer Neural Network for Astronomical Image Segmentation",
                "B. SPECTRE: An Online, Adaptive Deep Feature Extractor for Stellar Spectral Analysis",
                "C. LUMINA: A Hierarchical Machine Learning Framework for Real-Time Telescope Data Compression",
                "D. NEBULA: A Deep Convolutional Network for Variable Star Classification Using Time-Series Photometry",
                "E. ORACLE: A Real-Time, Hierarchical, Deep-Learning Photometric Classifier for the LSST"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "ORACLE: A Real-Time, Hierarchical, Deep-Learning Photometric Classifier for the LSST"
            ],
            "img_path": "2501.01496/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the numerical result of multiplying the number of letters in the acronym of the specific recurrent unit type used in ORACLE by the total count of distinct dataset categories for which explicit phase augmentation factors are provided?",
            "options": [
                "A. 3",
                "B. 6",
                "C. 9",
                "D. 12",
                "E. 33"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "9"
            ],
            "img_path": "2501.01496/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01672",
        "img_path": "2501.01672/CLWE.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Andrew D. Kent",
                "B. Truc Anh Nguyen",
                "C. Zhang Ruoyan",
                "D. Zheng Zhongxiang",
                "E. Bao Wankang"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Zhang Ruoyan"
            ],
            "img_path": "2501.01672/CLWE.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement most accurately synthesizes the core mechanisms ensuring the confidentiality of the fine-tuned private LoRA matrices against model extraction, the cryptographic problem underpinning this specific security, and the method used to protect user input during interactions with these matrices?",
            "options": [
                "A. The private LoRA matrices are secured using Private Linear Layers (PLL) to prevent model extraction, a defense whose hardness is reducible to the Learning with Errors (LWE) problem, while user inputs interacting with these LoRA matrices are protected through Fully Homomorphic Encryption (FHE).",
                "B. Fully Homomorphic Encryption (FHE) is applied directly to the LoRA matrices to ensure their confidentiality against model extraction attacks, with the Learning with Errors (LWE) problem guaranteeing the security of this FHE application, and Private Linear Layers (PLL) are used to encrypt user inputs.",
                "C. The primary defense for LoRA matrices is their server-side isolation within the 'Private-LoRA' component, with model extraction security further enhanced by the CLWE problem's difficulty when processing user inputs, which are themselves protected by the PLL transformation.",
                "D. Model extraction attacks on LoRA matrices are mitigated by transforming them using a method based on the SolveMatrix problem's hardness, while user input is protected by FHE, and the overall security of the private fine-tuning relies on the 'Open-LLM' component being publicly accessible.",
                "E. The security of private LoRA matrices against model extraction relies on the inherent properties of Parameter-Efficient Fine-Tuning (PEFT) combined with provable security theory, specifically reducing the attack difficulty to the CLWE problem, while user input privacy is ensured by encrypting the entire inference computation with FHE."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The private LoRA matrices are secured using Private Linear Layers (PLL) to prevent model extraction, a defense whose hardness is reducible to the Learning with Errors (LWE) problem, while user inputs interacting with these LoRA matrices are protected through Fully Homomorphic Encryption (FHE)."
            ],
            "img_path": "2501.01672/CLWE.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01007",
        "img_path": "2501.01007/x2.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. A Survey of Machine Learning Techniques for Energy Optimization in Cloud Data Centers",
                "B. Deep Reinforcement Learning for Job Scheduling and Resource Management in Cloud Computing: An Algorithm-Level Review",
                "C. Algorithmic Approaches to Task Allocation in Distributed Computing Environments",
                "D. Evaluating Heuristic Methods for Resource Allocation in Edge Computing Networks",
                "E. An Overview of Metaheuristic Strategies for Load Balancing in High-Performance Computing Systems"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Deep Reinforcement Learning for Job Scheduling and Resource Management in Cloud Computing: An Algorithm-Level Review"
            ],
            "img_path": "2501.01007/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most comprehensively and accurately defines the fundamental context and intellectual contribution of the work, particularly in relation to its examination of adaptive learning strategies for optimizing cloud computing operations against a backdrop of dynamism and multifaceted performance criteria?",
            "options": [
                "A. The document serves as a comprehensive survey evaluating Deep Reinforcement Learning algorithms, including their detailed methodologies, performance metrics, and practical applications, specifically for enhancing job scheduling and resource management within cloud computing, while also delineating emerging trends and future research avenues.",
                "B. The paper's primary intellectual contribution lies in its detailed exposition of how heuristic algorithms, by providing initial problem decompositions and approximate solutions, fundamentally reshape the Deep Reinforcement Learning training landscape to accelerate convergence in complex cloud workflow scenarios.",
                "C. The fundamental context is established by a focused investigation into the design trade-offs of reward functions in Deep Reinforcement Learning, particularly contrasting task-centric objectives like makespan minimization with system-centric goals such as resource utilization maximization and cost reduction in cloud services.",
                "D. The work's central argument and contribution revolve around the introduction and empirical validation of advanced value-based Deep Reinforcement Learning methods, like variations of Deep Q-Networks, as superior alternatives to traditional scheduling algorithms in adapting to real-time cloud environment changes.",
                "E. The intellectual contribution is primarily a critique of traditional, static model-based scheduling approaches, using this critique to motivate the theoretical exploration of Deep Reinforcement Learning principles without extensively detailing their specific algorithmic implementations or application case studies in cloud management."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "This survey provides a comprehensive review of DRL-based algorithms for job scheduling and resource management in cloud computing, analyzing their methodologies, performance metrics, and practical applications. We also highlight emerging trends and future research directions, offering valuable insights into leveraging DRL to advance both job scheduling and resource management in cloud computing."
            ],
            "img_path": "2501.01007/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00946",
        "img_path": "2501.00946/pair_caching.drawio.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Hierarchical Token Aggregation for Enhanced Diffusion Model Efficiency",
                "B. Dynamic Attention Pruning Strategies in Large-Scale Diffusion Networks",
                "C. Redundancy-Aware Token Selection in Generative Diffusion Architectures",
                "D. Cached Adaptive Token Merging: Dynamic Token Reduction and Redundant Computation Elimination in Diffusion Model",
                "E. Adaptive Computation Allocation for Scalable Diffusion Model Training"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Cached Adaptive Token Merging: Dynamic Token Reduction and Redundant Computation Elimination in Diffusion Model"
            ],
            "img_path": "2501.00946/pair_caching.drawio.png"
        },
        "level2_qa": {
            "question": "In this paper, which single numerical value from the empirical results quantifies the specific speedup factor achieved by the CA-ToMe method in the denoising process, distinguishing this specific finding from general performance statements about the broader category of training-free acceleration techniques that also includes token reduction and caching?",
            "options": [
                "A. 2.0",
                "B. 1.24",
                "C. 0.5",
                "D. 0.24",
                "E. 1.0"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1.24"
            ],
            "img_path": "2501.00946/pair_caching.drawio.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01023",
        "img_path": "2501.01023/pipeline.jpg",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Hadamard Attention Recurrent Transformer: A Strong Baseline for Stereo Matching Transformer",
                "B. Spectral Convolution Networks for Enhanced Depth Estimation in Stereo Vision",
                "C. Multi-Scale Feature Aggregation Transformer for Robust 3D Scene Reconstruction",
                "D. Graph-Based Attention Mechanisms for Improved Disparity Map Generation",
                "E. Residual Recurrent Networks with Context-Aware Modules for Stereo Image Analysis"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Hadamard Attention Recurrent Transformer: A Strong Baseline for Stereo Matching Transformer"
            ],
            "img_path": "2501.01023/pipeline.jpg"
        },
        "level2_qa": {
            "question": "In this paper, considering the two main challenges stereo transformers face as explicitly summarized by the authors ('In summary, stereo transformers still face two main challenges: ...') and the two key aspects identified upon which improving matching performance subsequently 'hinges on' ('Moreover, we believe that improving the matching performance of Stereo Transformers hinges on: ...'), how many unique, non-overlapping fundamental issues are identified across these specific summary statements that are then targeted for resolution by the core architectural innovations of HART (HPSA, DAK, and MKOI) through their primary stated functions?",
            "options": [
                "A. 2",
                "B. 4",
                "C. 3",
                "D. 1",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2501.01023/pipeline.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01768",
        "img_path": "2501.01768/x2.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Jiahao Ma",
                "B. Hongzong Li",
                "C. Jian-Dong Huang",
                "D. Ye-Fan Hu",
                "E. Yifan Chen"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Jiahao Ma"
            ],
            "img_path": "2501.01768/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the reported outcomes of empirical experiments on existing benchmarks, what specific numerical value quantifies the minimum margin of increased prediction accuracy, expressed as a percentage figure, demonstrated by the authors' novel tripartite modeling approaches when contrasted with conventional methodologies?",
            "options": [
                "A. 2.0",
                "B. 2.8",
                "C. 3.0",
                "D. 10.5",
                "E. 13.3"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2.8"
            ],
            "img_path": "2501.01768/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01790",
        "img_path": "2501.01790/framework.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Debang Li",
                "B. Di Qiu",
                "C. Changqian Yu",
                "D. Mingyuan Fan",
                "E. Zhengcong Fei"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Zhengcong Fei"
            ],
            "img_path": "2501.01790/framework.png"
        },
        "level2_qa": {
            "question": "In this paper, what key capability gap within the open-source DiT-based video generation landscape does the 'Ingredients' framework primarily address, especially in light of DiT's known architectural challenges and the functional scope of preceding open-source DiT solutions?",
            "options": [
                "A. Introducing the first DiT-based framework that matches the efficiency of U-Net models for general video synthesis while being open-source.",
                "B. Enabling multi-ID video customization within an open-source Diffusion Transformer architecture, thereby overcoming the single-ID limitations of prior open-source DiT tools and navigating DiT-specific complexities.",
                "C. Revolutionizing video diffusion models by shifting from latent space to pixel space denoising for enhanced facial detail in multi-ID outputs.",
                "D. Offering a tuning-free method for multi-ID generation that completely eliminates the need for facial extractors and ID routers by using advanced text embeddings.",
                "E. Optimizing auto-regressive models for multi-ID video customization, making them competitive with DiT approaches for the first time in open-source."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Enabling multi-ID video customization within an open-source Diffusion Transformer architecture, thereby overcoming the single-ID limitations of prior open-source DiT tools and navigating DiT-specific complexities."
            ],
            "img_path": "2501.01790/framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01802",
        "img_path": "2501.01802/BERT4MIMO_architecture.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Transformer-Based Neural Networks for Optimizing Beamforming in Massive MIMO Systems",
                "B. Deep Learning Frameworks for Channel Estimation Using Convolutional Architecture in MIMO",
                "C. BERT4MIMO: A Foundation Model using BERT Architecture for Massive MIMO Channel State Information Prediction",
                "D. Attention-Driven Models for Enhancing Signal Detection in Multi-User MIMO Networks",
                "E. Recurrent Neural Network Approaches to Predicting Channel Quality in Wireless Communication"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "BERT4MIMO: A Foundation Model using BERT Architecture for Massive MIMO Channel State Information Prediction"
            ],
            "img_path": "2501.01802/BERT4MIMO_architecture.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the sum obtained by adding: (i) the count of distinct, explicitly named embedding layer categories that perform the initial encoding of different CSI characteristics, (ii) the total number of sequential processing layers constituting the core of the Transformer encoder, and (iii) the count of distinct, named architectural layer types that form the final classification stage before outputting the enhanced CSI matrix?",
            "options": [
                "A. 4",
                "B. 16",
                "C. 15",
                "D. 27",
                "E. 14"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "15"
            ],
            "img_path": "2501.01802/BERT4MIMO_architecture.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01818",
        "img_path": "2501.01818/app_attack.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Optimizing Network Traffic in Large Language Model Architectures",
                "B. Adaptive Pathways for Scalable Neural Network Deployment",
                "C. Dynamic Resource Allocation in Distributed AI Systems",
                "D. Rerouting LLM Routers",
                "E. Enhancing Communication Protocols for Transformer-based Models"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Rerouting LLM Routers"
            ],
            "img_path": "2501.01818/app_attack.png"
        },
        "level2_qa": {
            "question": "In this paper, when describing the formal construction of the router R_ω^𝓜 for the binary setting, how many distinct components are explicitly stated as comprising the parameter set ω, and what are they (in the order introduced)?",
            "options": [
                "A. Two components: a scoring function S and a threshold τ.",
                "B. Three components: a scoring function S, scoring function parameters θ, and a threshold τ.",
                "C. Four components: a scoring function S, scoring function parameters θ, a threshold τ, and a post-processing step.",
                "D. Three components: a classifier, a cost-performance trade-off parameter, and a threshold.",
                "E. Two components: a cascade of models and a scoring function."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Three components: a scoring function S, scoring function parameters θ, and a threshold τ."
            ],
            "img_path": "2501.01818/app_attack.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01652",
        "img_path": "2501.01652/x1.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. MIRAGE: Assessing the Impact of Language Models on Cross-Cultural Communication Dynamics",
                "B. Evaluating Large Language Models in Multi-Agent Negotiation Scenarios",
                "C. Understanding the Role of Language Models in Collaborative Problem Solving Environments",
                "D. MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments",
                "E. Analyzing Social Behavior Patterns Generated by AI in Virtual Interaction Contexts"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments"
            ],
            "img_path": "2501.01652/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, to achieve a comprehensive evaluation that addresses both the simplicity of evaluation in earlier game simulations like those by Wu et al. and the oversight of foundational LLM social capabilities in agent-focused studies such as Sotopia and Lyfe Agents, MIRAGE incorporates a specific quantity of distinct, objective evaluation metrics. How many such metrics are utilized by MIRAGE for assessing LLMs' performance in its diverse, open-ended murder mystery scenarios?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 8",
                "E. 1"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "four"
            ],
            "img_path": "2501.01652/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01437",
        "img_path": "2501.01437/x1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Evaluating the Scalability of Large-Scale Network Simulations",
                "B. On the reconstruction limits of complex networks",
                "C. Advances in Community Detection Algorithms for Social Networks",
                "D. Analyzing Robustness Criteria in Dynamic Network Structures",
                "E. Optimization Techniques for Resource Allocation in Distributed Networks"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "On the reconstruction limits of complex networks"
            ],
            "img_path": "2501.01437/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific numerical percentage is reported as a 'reasonable' reconstruction index for the mouse brain neuronal activity using the SIS model with an SBM prior, even though it's acknowledged that more detailed models could achieve higher log evidence and potentially yield an even lower index?",
            "options": [
                "A. 2.35",
                "B. 100",
                "C. 20",
                "D. 67",
                "E. 0"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "67"
            ],
            "img_path": "2501.01437/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01785",
        "img_path": "2501.01785/x1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Evaluating Privacy Preservation in Generative Models: Techniques and Applications",
                "B. A Survey of Fairness Metrics in Machine Learning: Challenges and Solutions",
                "C. Impact of Data Augmentation on Model Bias and Performance in Healthcare Analytics",
                "D. Can Synthetic Data be Fair and Private? A Comparative Study of Synthetic Data Generation and Fairness Algorithms",
                "E. Assessing the Robustness of Synthetic Data for Anomaly Detection in Financial Systems"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Can Synthetic Data be Fair and Private? A Comparative Study of Synthetic Data Generation and Fairness Algorithms"
            ],
            "img_path": "2501.01785/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the methodology for evaluating synthetic data generators (SDGs) to answer RQ1, which involves assessing both privacy and fairness under the primary 'Same Train, Real Test' paradigm, what numerical value was specifically set as a default parameter for the PATEGAN generator?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 3",
                "E. 5"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2501.01785/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01588",
        "img_path": "2501.01588/methodology_pipeline.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Adapting PHI-3 for Open-Ended Question Answering: Approaches and Evaluation",
                "B. (WhyPHI) Fine-Tuning PHI-3 for Multiple-Choice Question Answering: Methodology, Results, and Challenges",
                "C. Exploring Transfer Learning Techniques with PHI-3 in Natural Language Processing Tasks",
                "D. Benchmarking PHI-3 on Multi-Modal Question Answering Datasets: A Comparative Study",
                "E. Enhancing PHI-3 Performance through Data Augmentation and Pretraining Strategies"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "(WhyPHI) Fine-Tuning PHI-3 for Multiple-Choice Question Answering: Methodology, Results, and Challenges"
            ],
            "img_path": "2501.01588/methodology_pipeline.png"
        },
        "level2_qa": {
            "question": "In this paper, subsequent to addressing the TruthfulQA dataset's inconsistent option numbers through standardization and evolving from basic text completion prompts to a hybrid approach for better output control, what specific perplexity value was achieved for PHI-3.5?",
            "options": [
                "A. 4.68",
                "B. 2.27",
                "C. 90.8",
                "D. 62",
                "E. 2.41"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2.27"
            ],
            "img_path": "2501.01588/methodology_pipeline.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01457",
        "img_path": "2501.01457/x2.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Enhancing Learning Efficiency via Reward-Driven Deliberation Frameworks",
                "B. Adaptive Decision Making in AI using Hierarchical Reward Structures",
                "C. Optimizing Cognitive Processes through Multi-Modal Reward Integration",
                "D. Leveraging Reward Signals for Improved Problem-Solving Strategies",
                "E. Reinforcing Thinking through Reasoning-Enhanced Reward Models"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Reinforcing Thinking through Reasoning-Enhanced Reward Models"
            ],
            "img_path": "2501.01457/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering both the requirements for training the Discriminative Model (DM) and the data used for Reasoning Process Distillation, what is the minimum number of distinct types of data (defined by origin and content) that must be available from any existing dataset in order for the entire DRR framework—spanning behavioral data generation, DM training, and inference deployment—to function correctly without any manual labeling or access to model internals?",
            "options": [
                "A. One (only the initial input questions are necessary)",
                "B. Two (the initial input questions and the ground-truth final outputs)",
                "C. Three (the initial input questions, ground-truth outputs, and rationales generated by the LLM)",
                "D. Four (the initial input questions, ground-truth outputs, rationales, and environmental feedback labels)",
                "E. Five (the initial input questions, ground-truth outputs, rationales, environmental feedback labels, and access to model internal states)"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Two (the initial input questions and the ground-truth final outputs)"
            ],
            "img_path": "2501.01457/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00663",
        "img_path": "2501.00663/loop-arch.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Giants: Enhancing Model Adaptation Through Dynamic Memory Updates",
                "B. Colossi: Improving Neural Networks with On-the-Fly Data Embedding",
                "C. Leviathans: Adaptive Parameter Tuning for Real-Time Inference",
                "D. Behemoths: Strategies for Incremental Learning During Deployment",
                "E. Titans: Learning to Memorize at Test Time"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Titans: Learning to Memorize at Test Time"
            ],
            "img_path": "2501.00663/loop-arch.png"
        },
        "level2_qa": {
            "question": "In this paper, provide a single sentence that describes a primary operational rationale explicitly stated for the architectural choice of segmenting the input sequence in the first Titan variant (memory as context), particularly concerning the interaction dynamics between the attention mechanism (short-term memory) and the neural long-term memory.",
            "options": [
                "A. Segmenting the input allows the attention mechanism, when processing the current segment (short-term context), to identify and guide the neural long-term memory to selectively store only the most salient information from that segment, thereby optimizing memory capacity and relevance.",
                "B. Input segmentation primarily serves to enable parallel processing of historical context by the long-term memory, independent of the attention module's focus on the current segment.",
                "C. The division into segments is crucial for allowing the persistent memory parameters to be updated exclusively based on historical segments, while attention processes current segments for immediate task performance.",
                "D. Segmentation facilitates a strict decoupling where the long-term memory exclusively processes past segments and attention exclusively processes the current segment, preventing any direct influence of current data on long-term memory updates during the retrieval phase.",
                "E. By processing distinct segments, the first Titan variant ensures that the long-term memory module primarily learns global sequence abstractions from past segments, while the attention module focuses on local dependencies within the current segment without directly influencing long-term memory content selection."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The attention module helps the long-term memory to store only useful information from the current context. That is, not all tokens in each segment are useful and memorizing all of them can result in memory overflow. Therefore, attention is helping the memory to understand which information is useful, better managing the memory capacity."
            ],
            "img_path": "2501.00663/loop-arch.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01101",
        "img_path": "2501.01101/overview.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Adaptive Neural Rendering for Real-Time Visualization of Medical Imagery",
                "B. Sparse Voxel Representations in Augmented Reality for Surgical Navigation",
                "C. High-Resolution Volumetric Modeling Using Deep Learning Techniques in Clinical Environments",
                "D. Optimizing 3D Scene Reconstruction with Multi-Modal Sensor Fusion in Minimally Invasive Surgery",
                "E. Deformable Gaussian Splatting for Efficient and High-Fidelity Reconstruction of Surgical Scenes"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Deformable Gaussian Splatting for Efficient and High-Fidelity Reconstruction of Surgical Scenes"
            ],
            "img_path": "2501.01101/overview.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the exact number of main components that constitute the EH-SurGS framework as described, and what are they?",
            "options": [
                "A. Two: 3D Gaussian canonical space and deformation modeling with life cycle",
                "B. Three: 3D Gaussian canonical space, deformation modeling with life cycle, and adaptive motion hierarchy strategy",
                "C. Four: 3D Gaussian canonical space, deformation modeling with life cycle, adaptive motion hierarchy strategy, and projection matrix optimization",
                "D. Two: deformation modeling with life cycle and adaptive motion hierarchy strategy",
                "E. Three: deformation modeling with life cycle, adaptive motion hierarchy strategy, and surgical tool mask processing"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Three: 3D Gaussian canonical space, deformation modeling with life cycle, and adaptive motion hierarchy strategy"
            ],
            "img_path": "2501.01101/overview.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00906",
        "img_path": "2501.00906/use-case-flow.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Distributed Reinforcement Learning Framework for Real-Time Multimedia Data Analysis in IoT Networks",
                "B. Large Language Model Based Multi-Agent System Augmented Complex Event Processing Pipeline for Internet of Multimedia Things",
                "C. Edge Computing Enabled Adaptive Event Detection in Heterogeneous Sensor Environments",
                "D. Hybrid Neural Network Architectures for Scalable Internet of Things Multimedia Streaming",
                "E. Context-Aware Middleware Solutions for Efficient Multi-Agent Coordination in Smart Multimedia Systems"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Large Language Model Based Multi-Agent System Augmented Complex Event Processing Pipeline for Internet of Multimedia Things"
            ],
            "img_path": "2501.00906/use-case-flow.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct components explicitly identified as main elements in the IoT data fabric architecture, as illustrated and described in the system overview sections, and which are integral to the orchestration of the autonomous complex event processing pipeline?",
            "options": [
                "A. Two",
                "B. Three",
                "C. Four",
                "D. Five",
                "E. Six"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Three"
            ],
            "img_path": "2501.00906/use-case-flow.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.00880",
        "img_path": "2501.00880/x3.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Improving Autoregressive Visual Generation with Cluster-Oriented Token Prediction",
                "B. Enhancing Convolutional Neural Networks for Image Classification through Adaptive Tokenization",
                "C. Optimizing Generative Adversarial Models with Spatial Attention Mechanisms",
                "D. Towards Efficient Non-Autoregressive Image Synthesis via Hierarchical Token Embedding",
                "E. Leveraging Contextual Token Clustering for Robust Visual Representation Learning"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Improving Autoregressive Visual Generation with Cluster-Oriented Token Prediction"
            ],
            "img_path": "2501.00880/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, acknowledging the fundamental reliance of visual generation on embedding decoding and the observed property that perceptually similar images can arise from distinct but proximate embeddings, which component of the IAR method most directly exploits the structured similarity within the rearranged codebook to maintain generation quality even when the exact token index is not perfectly predicted?",
            "options": [
                "A. The Codebook Rearrangement strategy, which establishes intra-cluster embedding similarity through balanced k-means clustering.",
                "B. The adoption of a standard autoregressive LLM architecture for modeling the image generation process.",
                "C. The Cluster-oriented Cross-entropy Loss, which shifts the prediction objective towards the correct embedding cluster rather than the exact token.",
                "D. The initial discovery of correlation between visual embeddings in the unprocessed visual codebook.",
                "E. The overall enhancement in model training efficiency, such as reducing training time by half for the same FID."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Leveraging the rearranged codebook, we propose a Cluster-oriented Cross-entropy Loss that guides the model to correctly predict the cluster where the target token is located. This approach ensures that even if the model predicts the wrong token index, there is a high probability the predicted token is located in the correct cluster, which significantly enhances the generation quality and robustness."
            ],
            "img_path": "2501.00880/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01481",
        "img_path": "2501.01481/x2.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Unleashing Correlation and Continuity for Hyperspectral Reconstruction from RGB Images",
                "B. Enhancing Spectral Resolution through Spatial-Temporal Constraints in RGB Imaging",
                "C. Fusion of Multispectral Features for Improved Image Reconstruction Techniques",
                "D. Leveraging Deep Learning for High-Fidelity Hyperspectral Image Synthesis",
                "E. Integrating Colorimetric and Textural Analysis in Hyperspectral Data Recovery"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Unleashing Correlation and Continuity for Hyperspectral Reconstruction from RGB Images"
            ],
            "img_path": "2501.01481/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, for the Neighborhood-wise Spectral Continuity Modeling (NeSCM) module, what is the specific channel dimensionality of the 'progressive feature' (denoted as y_t) generated by a single Continuity Modeling Unit (CMU) at an individual t-th step, before any concatenation or fusion with outputs from other CMU steps or branches?",
            "options": [
                "A. C_in",
                "B. n",
                "C. 1",
                "D. k",
                "E. s"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2501.01481/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02406",
        "img_path": "2501.02406/detecting_attribution.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Tara Radvand",
                "B. Gloria Platero",
                "C. Mojtaba Abdolmaleki",
                "D. Mohamed Mostagir",
                "E. Ambuj Tewari"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Tara Radvand"
            ],
            "img_path": "2501.02406/detecting_attribution.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence best describes the fundamental inadequacy of prior approaches that necessitates the development of the proposed zero-shot statistical tests for comprehensive text provenance?",
            "options": [
                "A. Prior methods primarily fail because human linguistic experts possess a low identification rate of only 38.9% for LLM-generated text, which automated systems, including the proposed tests, aim to surpass.",
                "B. The practical infeasibility of developing, training, and maintaining separate supervised classifiers for the rapidly growing number of LLMs and their diverse outputs, alongside their significant performance drops on out-of-domain data, presents the crucial methodological gap that zero-shot tests aim to fill.",
                "C. Existing detection frameworks frequently struggle to provide reliable attribution to specific LLM sources, a critical need for institutional compliance and quality control that the proposed tests address by design.",
                "D. The core deficiency undermining previous detection efforts is their general lack of mathematically proven guarantees for error rate reduction with increasing text length, a theoretical rigor explicitly provided by the paper's statistical framework.",
                "E. The urgent societal and operational challenges, such as combating LLM-driven misinformation and preventing AI model collapse, highlight a general demand for more effective provenance tools, rather than a specific flaw in prior methodologies necessitating zero-shot approaches."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The practical infeasibility of developing, training, and maintaining separate supervised classifiers for the rapidly growing number of LLMs and their diverse outputs, alongside their significant performance drops on out-of-domain data, presents the crucial methodological gap that zero-shot tests aim to fill."
            ],
            "img_path": "2501.02406/detecting_attribution.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01792",
        "img_path": "2501.01792/x7.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Optimizing Transformer Models Through Dynamic Memory Allocation and Gradient Accumulation",
                "B. Hybrid Storage Solutions for Scalable Deep Learning Model Deployment",
                "C. Reducing Computational Overhead in Large Language Models via Layer-wise Compression Techniques",
                "D. Improving Neural Network Inference Speed Using Adaptive Quantization and Memory Partitioning",
                "E. Efficient LLM Inference with Activation Checkpointing and Hybrid Caching"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Efficient LLM Inference with Activation Checkpointing and Hybrid Caching"
            ],
            "img_path": "2501.01792/x7.png"
        },
        "level2_qa": {
            "question": "In this paper, for the OPT-30B model's single-layer execution, by what geometric mean percentage does employing activation recomputation with activation checkpointing reduce latency when compared directly to conventional token recomputation?",
            "options": [
                "A. 22",
                "B. 30",
                "C. 50",
                "D. 78",
                "E. 119"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "78"
            ],
            "img_path": "2501.01792/x7.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02045",
        "img_path": "2501.02045/x2.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. GENOME-TRACK: A Computational Framework for Viral Mutation Analysis",
                "B. METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring",
                "C. PANDEMIC-GEN: Integrating Genomic Data for Infectious Disease Surveillance",
                "D. META-PATH: Deep Learning Approaches for Pathogen Detection in Metagenomics",
                "E. VIRALFORCE: Predictive Modeling of Viral Evolution Using Metagenomic Data"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring"
            ],
            "img_path": "2501.02045/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value, representing a duration in months, quantifies the period over which the Nucleic Acid Observatory and its partners collected the foundational >1.5 trillion base pair metagenomic dataset from human wastewater using deep metagenomic sequencing, which was subsequently utilized for the pretraining of the 7-billion-parameter METAGENE-1 model?",
            "options": [
                "A. 2",
                "B. 6",
                "C. 7",
                "D. 12",
                "E. 1.5"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "6"
            ],
            "img_path": "2501.02045/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01830",
        "img_path": "2501.01830/x2.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Teaming Large Language Models",
                "B. Auto-RT: Automated Approach to Optimizing Red-Teaming Workflows for Language Models",
                "C. Exploring Robust Defense Mechanisms Against Jailbreak Attempts in Large Language Models",
                "D. Systematic Strategies for Enhancing Red-Teaming Effectiveness in AI Language Models",
                "E. Automated Techniques for Mitigating Adversarial Exploits in Large Language Model Security"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Teaming Large Language Models"
            ],
            "img_path": "2501.01830/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, a single word, show the research results by naming the core vulnerability attribute that Auto-RT distinctly prioritizes for 'from scratch' autonomous discovery, setting its primary evaluation focus apart from many contemporary automated methods that might overemphasize harmfulness potential or, like GCG-Multi, produce outputs with limited practical application.",
            "options": [
                "A. Severity",
                "B. Novelty",
                "C. Exploitability",
                "D. Readability",
                "E. Generality"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Exploitability"
            ],
            "img_path": "2501.01830/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02189",
        "img_path": "2501.02189/x1.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Xiyang Wu",
                "B. Hongyang Du",
                "C. Zongxia Li",
                "D. Fuxiao Liu",
                "E. Huy Nghiem"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Zongxia Li"
            ],
            "img_path": "2501.02189/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the explicitly stated parameters defining the breadth of its systematic overview of Vision Language Models, what single integer represents the most recent year for which developmental information of major VLMs is cataloged?",
            "options": [
                "A. 4",
                "B. 93",
                "C. 262",
                "D. 2024",
                "E. 2025"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "2025"
            ],
            "img_path": "2501.02189/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01837",
        "img_path": "2501.01837/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Model Predictive Control Strategies for Urban Air Mobility Systems",
                "B. AI-Driven Navigation and Coordination in Unmanned Aerial Vehicle Networks",
                "C. Optimization of Flight Path Planning Using Sensor Fusion Techniques",
                "D. Digital Twin-based SIM Communication and Flight Control for Advanced Air Mobility",
                "E. Real-time Data Integration for Autonomous Aircraft Traffic Management"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Digital Twin-based SIM Communication and Flight Control for Advanced Air Mobility"
            ],
            "img_path": "2501.01837/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, to address the lack of high-rate communication and safe flight planning for eVTOLs, the proposed DT-based approach involves an alternating optimization. Which statement most comprehensively and accurately describes the initial optimization step within this alternating process, the specific parameters it refines using distinct algorithms, and how these refined parameters subsequently contribute to the eVTOL's flight adjustments?",
            "options": [
                "A. The eVTOL Digital Twin (DT^e) initiates by optimizing its potential field hyperparameters {k_tar, k_sep, k_com} using a Deep Q-Network (DQN), and these hyperparameters are then sent to the SIM Digital Twin (DT^S) to adjust its phase shift matrix Ψ and transmission power P.",
                "B. The SIM Digital Twin (DT^S) initiates the process by optimizing the transmission power (P) using a fractional programming algorithm and the phase shift matrix (Ψ) using an iterative gradient ascent algorithm; these optimized parameters are then transmitted to the eVTOL Digital Twin (DT^e) to inform its flight control adjustments.",
                "C. The eVTOL Digital Twin (DT^e) primarily optimizes its dynamic status components (position q, velocity v, acceleration acc) using a fractional programming algorithm and its communication components (connection conditions η_nec, QoS requirements η_QoS) via an iterative gradient ascent algorithm, directly influencing the Composite Potential Field (CPF).",
                "D. Both Digital Twins (DT^S and DT^e) simultaneously optimize all their respective parameters (P, Ψ for DT^S; q, v, acc, and {k_tar, k_sep, k_com} for DT^e) using a unified Deep Q-Network (DQN) framework, and these parameters collectively determine the adjustments for the eVTOL's trajectory within the Composite Potential Field.",
                "E. The optimization begins with the SIM Digital Twin (DT^S) refining the eVTOL's potential field hyperparameters {k_tar, k_sep, k_com} using an iterative gradient ascent algorithm to maximize the transmission rate, which then dictates the phase shift matrix Ψ and transmission power P for the SIM antenna system."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The SIM Digital Twin (DT^S) initiates the process by optimizing the transmission power (P) using a fractional programming algorithm and the phase shift matrix (Ψ) using an iterative gradient ascent algorithm; these optimized parameters are then transmitted to the eVTOL Digital Twin (DT^e) to inform its flight control adjustments."
            ],
            "img_path": "2501.01837/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01832",
        "img_path": "2501.01832/x1.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Temporal Attention Networks for Narrative Text Synthesis",
                "B. Sequential Data Modeling for Contextual Image Annotation",
                "C. Recurrent Neural Architectures in Generative Text Summarization",
                "D. Time Series Language Model for Descriptive Caption Generation",
                "E. Dynamic Sequence Prediction for Visual Content Description"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Time Series Language Model for Descriptive Caption Generation"
            ],
            "img_path": "2501.01832/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what approximate percentage of the total initially synthetically generated data is used for training when TSLM achieves its peak BERTScore for SYNTH, after the denoising process has been applied?",
            "options": [
                "A. 50.0%",
                "B. 46.2%",
                "C. 92.4%",
                "D. 7.6%",
                "E. 54.1%"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "46.2"
            ],
            "img_path": "2501.01832/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01988",
        "img_path": "2501.01988/x2.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Nicholas Mankowski",
                "B. Andrea Bucci",
                "C. Wendi Li",
                "D. Hassan Mushtaq",
                "E. Hanliang Guo"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Nicholas Mankowski"
            ],
            "img_path": "2501.01988/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, given the model's differentiation between perceived headway (influenced by reaction time Δ) for lane-changing and forward-moving stages, and true headway for the collision-detecting stage, what is the most direct consequence within the simulation if a vehicle's reaction time Δ is at or above the critical reaction time established for single-lane stability?",
            "options": [
                "A. The frustration level of the driver will automatically decrease, preventing lane change attempts that would be based on inaccurate perceived headways, thereby ensuring stability despite the high reaction time.",
                "B. The simulation will halt movement calculations for any vehicle whose perceived headway, calculated with a critical reaction time, indicates an imminent collision prior to the lane-changing stage.",
                "C. The critical reaction time, being a concept for single-lane linear stability, has no direct bearing on the multi-lane simulation's collision outcomes, which are determined independently by true headway and vehicle size C during the collision-detecting stage.",
                "D. The rescaled lane change probability P*(φ; Δt) will be significantly reduced for drivers with critical reaction times, effectively preventing dangerous lane changes and maintaining overall traffic flow regardless of individual reaction capabilities.",
                "E. Driver decisions regarding movement and lane changes, which are based on perceived headways influenced by the high reaction time, may lead to vehicle actions that are subsequently identified as collisions only when evaluated against true headways in the collision-detecting stage."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Driver decisions regarding movement and lane changes, which are based on perceived headways influenced by the high reaction time, may lead to vehicle actions that are subsequently identified as collisions only when evaluated against true headways in the collision-detecting stage."
            ],
            "img_path": "2501.01988/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01926",
        "img_path": "2501.01926/x2.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Mitigating Hallucination for Large Vision Language Model by Inter-Modality Correlation Calibration Decoding",
                "B. Enhancing Multimodal Understanding through Adaptive Cross-Modal Attention Mechanisms",
                "C. Reducing Semantic Drift in Vision-Language Models via Feature-Level Consistency Regularization",
                "D. Improving Visual Captioning Accuracy by Integrating Hierarchical Textual Context",
                "E. Optimizing Joint Embedding Spaces for Robust Visual Question Answering Systems"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Mitigating Hallucination for Large Vision Language Model by Inter-Modality Correlation Calibration Decoding"
            ],
            "img_path": "2501.01926/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which sentence most accurately delineates the specific composition of CMVED's hallucination-favoring distorted distribution that allows it to transcend the limitations of prior distortion methods in concurrently addressing both uni-modal overreliance and spurious inter-modality correlations?",
            "options": [
                "A. The distorted distribution, by selectively masking value vectors associated with high cross-modal attention weights, preserves the influence of uni-modal overreliance while ensuring spurious inter-modality correlations are retained and important ones are suppressed, thereby creating conditions favorable to hallucination for effective contrastive mitigation.",
                "B. The distorted distribution primarily eliminates all inter-modality correlations by distorting visual content, which, while simplifying the problem, focuses the model solely on rectifying uni-modality overreliance at the expense of inter-modal nuances.",
                "C. The distorted distribution is created by disturbing input instructions, leading to a suboptimal estimation that equally weakens both spurious and genuine inter-modality correlations, albeit preserving strong uni-modal reliance.",
                "D. The distorted distribution exclusively amplifies uni-modal textual priors through the masking of visual value vectors, effectively isolating uni-modal hallucinations but leaving complex inter-modality dynamics entirely unaddressed by this specific distribution.",
                "E. The distorted distribution enhances all inter-modality correlations by uniformly upscaling cross-modal attention weights, a process designed to identify uni-modal errors by their stark contrast to these artificially strengthened inter-modal signals."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "CMVED’s selective distortion does not interfere with uni-modal information exchange during distribution estimation, which preserves the impact of uni-modality overreliance. CMVED performs distortion by selectively masking the value vectors associated with high cross-modal attention weights in self-attention layers, which suppresses important inter-modality correlations while retaining the spurious ones in distorted distribution. By contrasting the distorted distribution that favors hallucination, CMVED facilitates the mitigation of uni-modality overreliance and spurious inter-modality correlations simultaneously."
            ],
            "img_path": "2501.01926/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02451",
        "img_path": "2501.02451/overview.jpg",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Optimizing Feature Extraction in Retinal Imaging through Multi-Scale Network Architectures",
                "B. Evaluating Augmentation Techniques for Improved Classification of Retinal Diseases",
                "C. Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales",
                "D. Integrating Temporal Consistency in Self-Supervised Learning for Ophthalmic Image Analysis",
                "E. Advanced Data Fusion Methods for Enhanced Retinal Image Segmentation"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales"
            ],
            "img_path": "2501.02451/overview.jpg"
        },
        "level2_qa": {
            "question": "In this paper, what single numerical value represents the absolute increase in Area Under the Precision-Recall Curve (AUPR) on the MESSIDOR2 dataset when models were pre-trained with weak augmentation as compared to strong augmentation?",
            "options": [
                "A. 0.010",
                "B. 0.848",
                "C. 0.597",
                "D. 0.074",
                "E. 0.523"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "0.074"
            ],
            "img_path": "2501.02451/overview.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01973",
        "img_path": "2501.01973/overview_up.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Xing Liu",
                "B. Di Jin",
                "C. Yu Liu",
                "D. Jia Qing Yap",
                "E. Andrea Wong"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Di Jin"
            ],
            "img_path": "2501.01973/overview_up.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the methodology for enhancing skintone classification precision by mitigating illumination disturbances through latent facial topological features, what is the precise count of distinct social racial and ethnic categorizations explicitly stated as foundational for generating the diverse synthetic facial imagery required for training the feature extraction model?",
            "options": [
                "A. 2",
                "B. 5",
                "C. 6",
                "D. 10",
                "E. 1"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "6"
            ],
            "img_path": "2501.01973/overview_up.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02461",
        "img_path": "2501.02461/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. FedRSClip: Federated Learning for Remote Sensing Scene Classification Using Vision-Language Models",
                "B. Enhancing Remote Sensing Image Segmentation via Federated Multimodal Networks",
                "C. Vision-Language Fusion Techniques for Distributed Remote Sensing Data Analysis",
                "D. Cross-Modal Representation Learning in Federated Remote Sensing Applications",
                "E. Decentralized Deep Learning Approaches for Scene Understanding in Aerial Imagery"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "FedRSClip: Federated Learning for Remote Sensing Scene Classification Using Vision-Language Models"
            ],
            "img_path": "2501.02461/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, for the specific constituent dataset of Fed-RSIC which is characterized both by its origin from high-resolution Google Earth imagery and by its total of 1,860 images distributed among its land-use classes, what is the exact number of images designated to each individual land-use class?",
            "options": [
                "A. 31",
                "B. 60",
                "C. 256",
                "D. 1860",
                "E. 3"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "60"
            ],
            "img_path": "2501.02461/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01705",
        "img_path": "2501.01705/x3.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Evaluating Narrative Comprehension in Artificial Agents Using Dialogue Systems",
                "B. Exploring Cognitive Models for Interactive Question Answering in Fictional Contexts",
                "C. The Role of Emotional Inference in Character-Based Story Interpretation",
                "D. The Essence of Contextual Understanding in Theory of Mind: A Study on Question Answering with Story Characters",
                "E. Advancements in Machine Learning for Character-Centric Dialogue Analysis"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "The Essence of Contextual Understanding in Theory of Mind: A Study on Question Answering with Story Characters"
            ],
            "img_path": "2501.01705/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, what single word best identifies the fundamental type of information, the critical importance of which for effective Theory-of-Mind is a primary research finding substantiated by both human participant studies and LLM evaluations on the CharToM benchmark?",
            "options": [
                "A. Narrative",
                "B. Backgrounds",
                "C. Context",
                "D. Literal",
                "E. Linguistic"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Context"
            ],
            "img_path": "2501.01705/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01835",
        "img_path": "2501.01835/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Zhengkai Tu",
                "B. Sourabh J. Choure",
                "C. Mun Hong Fong",
                "D. Jihye Roh",
                "E. Itai Levin"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Zhengkai Tu"
            ],
            "img_path": "2501.01835/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, for how many years had the development of the ASKCOS software suite progressed prior to the release of the version detailed, and what year did this development begin?",
            "options": [
                "A. 6 years, beginning in 2018",
                "B. 8 years, beginning in 2016",
                "C. 7 years, beginning in 2017",
                "D. 10 years, beginning in 2014",
                "E. 5 years, beginning in 2019"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "8 years, beginning in 2016"
            ],
            "img_path": "2501.01835/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.01664",
        "img_path": "2501.01664/x1.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Leveraging Machine Learning for Enhanced Anomaly Detection in IoT Networks",
                "B. Deep Neural Networks for Real-Time Intrusion Detection in Cyber-Physical Systems",
                "C. Adaptive Security Frameworks for IoT Devices Using Predictive Analytics",
                "D. BARTPredict: Empowering IoT Security with LLM-Driven Cyber Threat Prediction",
                "E. Evaluating Blockchain-Based Authentication Methods in Internet of Things Environments"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "BARTPredict: Empowering IoT Security with LLM-Driven Cyber Threat Prediction"
            ],
            "img_path": "2501.01664/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value represents the overall accuracy achieved by the intrusion prediction framework, a system that employs one fine-tuned BART model for network traffic prediction and a distinct fine-tuned BART model to classify these predicted packets, with a BERT model also being utilized primarily for the evaluation of the traffic predicted by the first BART model?",
            "options": [
                "A. 98",
                "B. 2",
                "C. 3",
                "D. 1",
                "E. 100"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "98"
            ],
            "img_path": "2501.01664/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02739",
        "img_path": "2501.02739/x2.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Leveraging Semantic Embeddings for Enhanced Text Classification Accuracy",
                "B. TARDiS : Text Augmentation for Refining Diversity and Separability",
                "C. Adaptive Noise Injection Techniques for Robust Natural Language Models",
                "D. Multi-Modal Data Fusion Strategies for Improved Textual Representation",
                "E. Contextualized Word Replacement Methods for Optimizing Language Understanding"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "TARDiS : Text Augmentation for Refining Diversity and Separability"
            ],
            "img_path": "2501.02739/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct generation processes introduced and described within TARDiS, and how many unique types of class-specific prompts are explicitly leveraged across these processes to enhance both intra-class diversity and inter-class separability?",
            "options": [
                "A. Two generation processes and two types of class-specific prompts",
                "B. One generation process and one type of class-specific prompt",
                "C. Two generation processes and three types of class-specific prompts",
                "D. Three generation processes and two types of class-specific prompts",
                "E. Two generation processes and one type of class-specific prompt"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Two generation processes and two types of class-specific prompts"
            ],
            "img_path": "2501.02739/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02979",
        "img_path": "2501.02979/x2.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Aligning Semantic Embeddings for Cross-Lingual Language Models in Neural Machine Translation",
                "B. Registering Source Tokens to Target Language Spaces in Multilingual Neural Machine Translation",
                "C. Optimizing Vocabulary Selection Strategies in Multilingual Translation Systems",
                "D. Investigating Language-Agnostic Representations for Enhanced Neural Translation Accuracy",
                "E. Mapping Contextual Features Across Languages for Improved Machine Translation Performance"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Registering Source Tokens to Target Language Spaces in Multilingual Neural Machine Translation"
            ],
            "img_path": "2501.02979/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, contrasting with gisting's primary objective of information compression for generation, what single-word concept, explicitly likened to a human cognitive process, best encapsulates the fundamental way 'registering' transforms source token understanding for the target language?",
            "options": [
                "A. Rethinking",
                "B. Compression",
                "C. Transferring",
                "D. Pointing",
                "E. Masking"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Rethinking"
            ],
            "img_path": "2501.02979/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02801",
        "img_path": "2501.02801/x3.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Sheng Zhang",
                "B. Haohao Sheng",
                "C. Quansheng Wu",
                "D. Chenhao Liang",
                "E. Hongming Weng"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Chenhao Liang"
            ],
            "img_path": "2501.02801/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, to enable the operation of the proposed topological field effect devices, including a NOR logic gate that functions without a topological phase transition and a high-performance FET leveraging tunable edge states, what is the minimum built-in polarization field (in MV/cm) identified by the authors' first-principles calculations as necessary to induce the foundational Quantum Spin Hall Insulator phase in InAs quantum wells via band inversion?",
            "options": [
                "A. 4.90",
                "B. 4.58",
                "C. 3.85",
                "D. 3.50",
                "E. 53"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3.85"
            ],
            "img_path": "2501.02801/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02962",
        "img_path": "2501.02962/x3.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Yuanzhi Zhu",
                "B. Feiyu Gao",
                "C. Jiawei Liu",
                "D. Zhibo Yang",
                "E. Peng Wang"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Jiawei Liu"
            ],
            "img_path": "2501.02962/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, which sentence most accurately synthesizes the primary functional pathway through which TLCG's generation of 'text lines' and associated layout information directly enables the specific conditional inputs required by the CLTD module for integrated text rendering?",
            "options": [
                "A. The TLCG module generates 'text lines' primarily to enhance semantic coherence and layout reasonability through its MMLM-driven two-step prompting, which incidentally provides a convenient format for subsequent processing by CLTD.",
                "B. The CLTD module dictates the necessity for 'text lines' by requiring specific image-level conditions, which TLCG then endeavors to produce using its advanced MMLM capabilities for visual captioning and layout estimation.",
                "C. TLCG's two-step prompting mechanism, by breaking down the task, allows for precise generation of layout boxes and text content, which are then passed as 'text lines' to CLTD primarily to reduce the overall processing complexity for the diffusion model.",
                "D. The primary role of TLCG generating 'text lines' is to leverage MMLM's instruction-following capabilities for creating reasonable text content and layouts, which CLTD then utilizes directly for diffusion without needing further structured input derived from these layouts.",
                "E. TLCG's output of 'text lines' and their corresponding layouts serves as the foundational input for CLTD, enabling it to adopt 'text lines' as its basic generation unit and to automatically derive essential image-level conditions, such as background regions and text line masks, from these layouts."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "TLCG generates text content taking text lines as basic units.",
                "To align with the generation format of the TLCG phase, CLTD takes text lines as the basic unit for generating text.",
                "The image-level condition comprises three parts: the background image regionPb⁢a⁢c⁢ksubscript𝑃𝑏𝑎𝑐𝑘P_{back}italic_P start_POSTSUBSCRIPT italic_b italic_a italic_c italic_k end_POSTSUBSCRIPT, the text line maskMl⁢i⁢n⁢esubscript𝑀𝑙𝑖𝑛𝑒M_{line}italic_M start_POSTSUBSCRIPT italic_l italic_i italic_n italic_e end_POSTSUBSCRIPT, and the stroke maskMs⁢t⁢r⁢o⁢k⁢esubscript𝑀𝑠𝑡𝑟𝑜𝑘𝑒M_{stroke}italic_M start_POSTSUBSCRIPT italic_s italic_t italic_r italic_o italic_k italic_e end_POSTSUBSCRIPT.",
                "Pb⁢a⁢c⁢ksubscript𝑃𝑏𝑎𝑐𝑘P_{back}italic_P start_POSTSUBSCRIPT italic_b italic_a italic_c italic_k end_POSTSUBSCRIPTandMl⁢i⁢n⁢esubscript𝑀𝑙𝑖𝑛𝑒M_{line}italic_M start_POSTSUBSCRIPT italic_l italic_i italic_n italic_e end_POSTSUBSCRIPTare generated automatically based on text layouts."
            ],
            "img_path": "2501.02962/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02497",
        "img_path": "2501.02497/x1.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Adaptive Computation in Artificial Intelligence: Balancing Intuition and Deliberation",
                "B. Real-Time Cognitive Processing: Exploring Dual-Mode Decision Frameworks",
                "C. Test-Time Compute: from System-1 Thinking to System-2 Thinking",
                "D. Integrating Fast and Slow Learning Paradigms for Efficient Model Inference",
                "E. Dynamic Resource Allocation for Cognitive Workloads in Machine Learning Systems"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Test-Time Compute: from System-1 Thinking to System-2 Thinking"
            ],
            "img_path": "2501.02497/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single term most precisely pinpoints the qualitative nature of the 'slow thinking' in Test-Time Adaptation (TTA)-enhanced System-1 models that fundamentally limits their progression towards the explicit, multi-faceted reasoning capabilities, such as reflection and backtracking, characteristic of strong System-2 models?",
            "options": [
                "A. Adaptive",
                "B. Implicit",
                "C. Linear",
                "D. Robust",
                "E. Perceptual"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "implicit"
            ],
            "img_path": "2501.02497/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02252",
        "img_path": "2501.02252/x2.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Adaptive Beamforming for Multi-user Communications under Dynamic Scattering Conditions",
                "B. Spatial Pilot Allocation Strategies for Enhanced Channel Estimation in Wireless Networks",
                "C. Robust Localization Techniques Using Multi-antenna Systems in Complex Propagation Environments",
                "D. Joint Optimization of Resource Allocation and Positioning in Multi-user MIMO Systems",
                "E. Scattering Environment Aware Joint Multi-user Channel Estimation and Localization with Spatially Reused Pilots"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Scattering Environment Aware Joint Multi-user Channel Estimation and Localization with Spatially Reused Pilots"
            ],
            "img_path": "2501.02252/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the computational complexity order with respect to the number of 3-D grid points Q for the long-timescale algorithm before prior information is used to reduce Q, and what is the corresponding order after such reduction is achieved by leveraging prior information?",
            "options": [
                "A. O(Q^2) before reduction; O(Q^3) after reduction",
                "B. O(Q^3) before reduction; O(Q^2) after reduction",
                "C. O(Q^3) before reduction; O(Q^3) after reduction",
                "D. O(Q^3) before reduction; O(Q) after reduction",
                "E. O(Q^2) before reduction; O(Q^2) after reduction"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "O(Q^3) before reduction; O(Q^2) after reduction"
            ],
            "img_path": "2501.02252/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02060",
        "img_path": "2501.02060/MJD-fig.jpg",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Design and Optimization of the MAJORANA DEMONSTRATOR Detector Array",
                "B. Advanced Data Analysis Techniques for Neutrinoless Double-Beta Decay Experiments",
                "C. The MAJORANA DEMONSTRATOR experiment's construction, commissioning, and performance",
                "D. Development of Low-Background Materials for Rare Event Searches",
                "E. Simulation Studies on Signal Reconstruction in the MAJORANA Experiment"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The MAJORANA DEMONSTRATOR experiment's construction, commissioning, and performance"
            ],
            "img_path": "2501.02060/MJD-fig.jpg"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of HPGe detector units that were operational following the commissioning phase, after accounting for all identified reliability issues?",
            "options": [
                "A. 58",
                "B. 18",
                "C. 35",
                "D. 29",
                "E. 40"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "The text states that Module 1 was deployed with 20 enriched detector units and 9 natural detector units, and Module 2 was deployed with 15 enriched detector units and 14 natural detector units. This gives a total of $20+9+15+14 = 58$ deployed detector units. The text further states that 8 detectors had issues with Vespel connectors or LMFE, 9 detectors had problems with HV cables, and 1 detector was found defective, totaling $8+9+1 = 18$ non-operational units. Therefore, the total number of operational HPGe detector units is $58 - 18 = 40$."
            ],
            "img_path": "2501.02060/MJD-fig.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02487",
        "img_path": "2501.02487/x1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. ACE++: Instruction-Based Image Creation and Editing via Context-Aware Content Filling",
                "B. Contextual Image Generation and Modification through Adaptive Prompt Learning",
                "C. Content-Aware Visual Synthesis Using Instruction-Guided Feature Mapping",
                "D. Multi-Modal Image Editing with Semantic Instruction and Spatial Filling",
                "E. Instruction-Driven Artwork Creation via Dynamic Contextual Infilling"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "ACE++: Instruction-Based Image Creation and Editing via Context-Aware Content Filling"
            ],
            "img_path": "2501.02487/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most comprehensively and accurately synthesizes ACE++'s core methodological strategy, encompassing its input paradigm development, two-stage training rationale including specific model leveraging, and its consequent advantages over prior unified visual generation frameworks?",
            "options": [
                "A. ACE++'s strategic approach integrates its LCU++ paradigm (an LCU evolution inspired by FLUX.1-Fill-dev's inpainting input format) with a two-stage training scheme—first pre-training on 0-ref tasks from a text-to-image model (potentially accelerated by FLUX.1-Fill-dev for painting tasks), then fine-tuning this model on all ACE-defined tasks to adapt diffusion models like FLUX.1-dev—to achieve efficient multi-task instruction-based generation, thereby mitigating the high training costs and restricted multitasking of prior frameworks.",
                "B. ACE++'s strategic approach employs its LCU++ paradigm, directly derived from FLUX.1-Fill-dev's complete architecture for all tasks, coupled with a two-stage training where FLUX.1-dev is first pre-trained on all ACE-defined tasks and then fine-tuned using 0-ref task data with FLUX.1-Fill-dev as the primary generative prior, primarily addressing OminiControl's multitasking limits.",
                "C. ACE++'s core strategy relies on the original LCU paradigm, inspired by FLUX.1-dev's general capabilities, integrated into a two-stage process where FLUX.1-Fill-dev is initially fine-tuned for all ACE tasks, followed by pre-training with 0-ref task data, principally to expand the variety of image generation tasks rather than optimize training efficiency.",
                "D. ACE++'s methodology centers on its LCU++ paradigm, inspired by OmniGen's multimodal input handling, and a two-stage training that first fine-tunes FLUX.1-Fill-dev on 0-ref tasks, then uses this model to further adapt FLUX.1-dev for all ACE-defined tasks, mainly to improve parameter reuse for multitasking as seen in OminiControl.",
                "E. ACE++'s approach is characterized by its LCU++ paradigm (from LCU, FLUX.1-Fill-dev inspired), and a two-stage training where powerful T2I models like FLUX.1-dev are first fine-tuned on all ACE-defined tasks for generality, and subsequently pre-trained on 0-ref task data using initializations like FLUX.1-Fill-dev to enhance efficiency, with the LCU++ itself primarily responsible for minimizing training costs."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "ACE++'s strategic approach integrates its LCU++ paradigm (an LCU evolution inspired by FLUX.1-Fill-dev's inpainting input format) with a two-stage training scheme—first pre-training on 0-ref tasks from a text-to-image model (potentially accelerated by FLUX.1-Fill-dev for painting tasks), then fine-tuning this model on all ACE-defined tasks to adapt diffusion models like FLUX.1-dev—to achieve efficient multi-task instruction-based generation, thereby mitigating the high training costs and restricted multitasking of prior frameworks."
            ],
            "img_path": "2501.02487/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02143",
        "img_path": "2501.02143/pipelinenew.jpg",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. RobustAug: Enhancing Autonomous Navigation through Synthetic Scenario Generation",
                "B. Adaptive Data Synthesis for Improved Driver Behavior Prediction Models",
                "C. Evaluating Simulation-Based Approaches for Critical Event Detection in Driving Data",
                "D. Context-Aware Augmentation Techniques for Traffic Incident Analysis",
                "E. SafeAug: Safety-Critical Driving Data Augmentation from Naturalistic Datasets"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "SafeAug: Safety-Critical Driving Data Augmentation from Naturalistic Datasets"
            ],
            "img_path": "2501.02143/pipelinenew.jpg"
        },
        "level2_qa": {
            "question": "In this paper, which sentence best describes the crucial aspect of the data augmentation process that extends beyond visual alteration to ensure the generated safety-critical scenarios are both realistic and comprehensively prepare autonomous systems?",
            "options": [
                "A. The framework primarily relies on advanced 3D transformation techniques to simulate vehicle proximity, which inherently creates realistic critical scenarios without needing further data adjustments.",
                "B. The core of the augmentation lies in using YOLOv5 and Depth-Anything to achieve high visual authenticity, ensuring that the depicted scenarios are directly translatable to real-world risks.",
                "C. The method ensures comprehensive preparation by systematically adjusting vehicle dynamics data, specifically acceleration, in parallel with visual modifications, thereby creating consistent and congruent representations of hazardous situations.",
                "D. The primary mechanism is the identification of the vehicle directly in front, which is then used to generate a wide variety of critical scenarios solely through image manipulation while keeping metadata constant for baseline comparison.",
                "E. The framework prioritizes minimal compromise on image authenticity by exclusively using naturalistic datasets as the source, which means the inherent vehicle dynamics are preserved, and only visual proximities are altered."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The method ensures comprehensive preparation by systematically adjusting vehicle dynamics data, specifically acceleration, in parallel with visual modifications, thereby creating consistent and congruent representations of hazardous situations."
            ],
            "img_path": "2501.02143/pipelinenew.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02191",
        "img_path": "2501.02191/x2.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Exploring Graph Neural Networks for Multimodal Data Reconstruction",
                "B. Advanced Techniques in Missing Data Recovery via Deep Embedding Models",
                "C. On LLM-Enhanced Mixed-Type Data Imputation with High-Order Message Passing",
                "D. Optimizing High-Dimensional Data Fusion through Hierarchical Attention Mechanisms",
                "E. A Study on Context-Aware Feature Imputation Using Transformer Architectures"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "On LLM-Enhanced Mixed-Type Data Imputation with High-Order Message Passing"
            ],
            "img_path": "2501.02191/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement most accurately synthesizes the specific data characteristics that the BiHMP component is designed to model and a significant limitation of prior machine learning-based imputation techniques that UnIMP, as a comprehensive framework, aims to overcome?",
            "options": [
                "A. BiHMP is engineered to primarily capture intra-column homogeneity using cell-oriented hypergraphs, thereby addressing the inefficiency of early rule-based methods like Mean and Mode in handling diverse datasets.",
                "B. BiHMP's main function is to improve the processing of text data by leveraging high-order message passing, a direct response to the failure of methods like GAIN and GRAPE to support any form of numerical or categorical data imputation.",
                "C. BiHMP is designed to model high-order relationships, inter-column heterogeneity, and intra-column homogeneity, while UnIMP, incorporating BiHMP, seeks to overcome the limitations of many previous ML/DL imputers, such as their struggle with text data and their tendency to require dataset-specific models, which hinders generalizability.",
                "D. BiHMP utilizes progressive masking and chunking techniques to effectively manage high-order relationships in mixed-type data, addressing the primary limitation of LLM-based approaches which only support numerical and categorical data.",
                "E. BiHMP focuses on aggregating global-local information to enhance the performance of statistical methods on text data imputation, a domain where UnIMP introduces Xfusion primarily to improve the generalizability of models trained per feature."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "BiHMP is designed to model high-order relationships, inter-column heterogeneity, and intra-column homogeneity, while UnIMP, incorporating BiHMP, seeks to overcome the limitations of many previous ML/DL imputers, such as their struggle with text data and their tendency to require dataset-specific models, which hinders generalizability."
            ],
            "img_path": "2501.02191/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02029",
        "img_path": "2501.02029/x7.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Analyzing Attention Mechanisms for Enhanced Visual Question Answering",
                "B. Improving Multimodal Understanding with Cross-Attention in Vision-Language Models",
                "C. Exploring Semantic Alignment in Large-Scale Vision and Language Architectures",
                "D. Spot Risks Before Speaking! Unraveling Safety Attention Heads in Large Vision-Language Models",
                "E. Evaluating Robustness of Attention Heads in Multimodal Deep Learning Systems"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Spot Risks Before Speaking! Unraveling Safety Attention Heads in Large Vision-Language Models"
            ],
            "img_path": "2501.02029/x7.png"
        },
        "level2_qa": {
            "question": "In this paper, when a small subset of safety heads, crucial for model safety and identified using linear probes trained with merely 0.1% of the data, have their activations zeroed out, what is the magnitude of the resultant percentage drop in the Reject Rate, given that overall model utility remains almost unaffected?",
            "options": [
                "A. 24",
                "B. 10",
                "C. 15",
                "D. 5",
                "E. 81"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "15"
            ],
            "img_path": "2501.02029/x7.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02460",
        "img_path": "2501.02460/x2.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Enhancing Large Language Models with Domain-Specific Knowledge Integration for Clinical Decision Support",
                "B. Multi-Modal Retrieval Techniques for Improving Medical Text Generation in AI Systems",
                "C. Adaptive Knowledge Fusion Strategies for Scalable Language Models in Healthcare Informatics",
                "D. Context-Aware Generative Models Leveraging Structured Medical Databases for Diagnostic Assistance",
                "E. Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications"
            ],
            "img_path": "2501.02460/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, for how many of the five explicitly enumerated representative medical knowledge source categories within MedOmniKB does the text provide specific details on their distinct multi-step retrieval or data processing methodologies, including named tools (e.g., Qdrant, SQLite), models (e.g., MedCPT-article-encoder), or unique algorithmic procedures (e.g., vector encoding, one-hop relationship extraction, reranking)?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.02460/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02728",
        "img_path": "2501.02728/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Yuming Ai",
                "B. Bowen Fan",
                "C. Xunkai Li",
                "D. Zhilin Guo",
                "E. Rong-Hua Li"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Bowen Fan"
            ],
            "img_path": "2501.02728/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical result is obtained by multiplying the count of State-of-the-Art Graph Unlearning algorithms integrated into OpenGU with the count of distinct primary dimensions explicitly stated as used for the in-depth investigation and insight generation regarding these GU algorithms?",
            "options": [
                "A. 32",
                "B. 48",
                "C. 53",
                "D. 144",
                "E. 19"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "48"
            ],
            "img_path": "2501.02728/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02838",
        "img_path": "2501.02838/x3.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Ivan Velkovsky",
                "B. S. Martinson",
                "C. Zhicheng Dou",
                "D. Min Zhang",
                "E. Qingyao Ai"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Qingyao Ai"
            ],
            "img_path": "2501.02838/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, considering both the initially outlined 'various ways of learning from user feedback in GenIR' (which include continual learning, learning and ranking in the conversational context, and prompt learning) and the subsequently detailed 'strategies for using user feedback information in the GenIR system' (which encompass prompt engineering, fine-tuning with historical data, and capturing user preferences/intents), if 'prompt learning' as a way of learning and 'prompt engineering or instruction construction' as a strategy are treated as a single, unified methodological approach, what is the total count of distinct such approaches explicitly enumerated for integrating user feedback to improve system performance?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "5"
            ],
            "img_path": "2501.02838/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02916",
        "img_path": "2501.02916/x1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Deep Convolutional Networks for Multimodal 3D Object Detection in Space Robotics",
                "B. Spiking monocular event based 6D pose estimation for space application",
                "C. Event-Driven Stereo Vision Systems for Autonomous Satellite Navigation",
                "D. Real-Time 6D Pose Tracking Using Thermal Imaging for Extraterrestrial Exploration",
                "E. Neuromorphic Sensor Fusion Techniques for Orbital Object Recognition"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Spiking monocular event based 6D pose estimation for space application"
            ],
            "img_path": "2501.02916/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the approximate average number of events per ground truth pose across all scenarios described for the SEENIC dataset's test set?",
            "options": [
                "A. 95,560",
                "B. 101,459",
                "C. 144,703",
                "D. 193,846",
                "E. 289,406"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "101459"
            ],
            "img_path": "2501.02916/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03112",
        "img_path": "2501.03112/AutoEval_flowchart_colored.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. PyBiasDetect: A Toolkit for Identifying and Mitigating Bias in Machine Learning Models",
                "B. LangFair: A Python Package for Assessing Bias and Fairness in Large Language Model Use Cases",
                "C. FairEval: Evaluating Ethical Considerations in Natural Language Processing Applications",
                "D. BiasTrack: Monitoring and Analyzing Fairness in Multilingual Language Models",
                "E. ModelCheck: A Framework for Auditing Performance and Equity in AI Systems"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "LangFair: A Python Package for Assessing Bias and Fairness in Large Language Model Use Cases"
            ],
            "img_path": "2501.03112/AutoEval_flowchart_colored.png"
        },
        "level2_qa": {
            "question": "In this paper, what single number indicates the total count of distinctly categorized, practitioner-focused supporting materials that are explicitly enumerated in the description of resources provided to aid users of the `langfair` package, beyond the software library itself?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2501.03112/AutoEval_flowchart_colored.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03006",
        "img_path": "2501.03006/x3.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Luozhou Wang",
                "B. Yijun Li",
                "C. Zhifei Chen",
                "D. Jui-Hsien Wang",
                "E. Zhifei Zhang"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Luozhou Wang"
            ],
            "img_path": "2501.03006/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of individual training instances processed during the fine-tuning of the described RGBA video diffusion models?",
            "options": [
                "A. 5000",
                "B. 8",
                "C. 40000",
                "D. 320000",
                "E. 128"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "40000"
            ],
            "img_path": "2501.03006/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03079",
        "img_path": "2501.03079/wheelgins_overview.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Enhanced GNSS/INS Fusion Techniques for UAV Navigation Using Gyroscope-mounted IMUs",
                "B. Real-time Vehicle Positioning Using INS and GNSS with Pedal-based Sensor Integration",
                "C. Optimization of Marine Navigation Systems Based on GNSS and Inertial Measurement Units",
                "D. Wheel-GINS: A GNSS/INS Integrated Navigation System with a Wheel-mounted IMU",
                "E. Development of a Low-cost IMU/GNSS Hybrid System for Autonomous Robot Localization"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Wheel-GINS: A GNSS/INS Integrated Navigation System with a Wheel-mounted IMU"
            ],
            "img_path": "2501.03079/wheelgins_overview.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the adoption of a classical loosely coupled EKF and the stated novelty of integrating GNSS with a Wheel-IMU, which single sentence best articulates the primary scope of validation the Wheel-GINS system aimed to achieve in addressing the limitations of prior Wheel-IMU based navigation?",
            "options": [
                "A. The paper's use of a classical EKF primarily serves to establish the fundamental viability and practical applicability of integrating GNSS with a wheel-mounted IMU as a novel approach to achieving long-term, drift-corrected navigation, addressing the general outdoor operational limitations not fully resolved by Wheel-INS or Wheel-SLAM.",
                "B. The EKF was implemented primarily to provide a direct and equivalent methodological baseline for demonstrating Wheel-GINS's incremental performance improvements over the established ODO-GINS, especially in scenarios involving frequent GNSS signal blockage.",
                "C. Selecting the classical EKF aimed to capitalize on its proven strengths in maintaining continuous state estimation during GNSS outages and its compatibility with the specific error characteristics of Wheel-IMU data, thereby ensuring maximum system robustness.",
                "D. The classical EKF was chosen as the optimal framework for rigorously validating the online estimation algorithms for Wheel-IMU installation parameters (lever arm, mounting angle, wheel radius error), which are the predominant factors for enhancing Wheel-GINS's localization accuracy.",
                "E. The adoption of a classical EKF reflects a strategic decision to prioritize the demonstration of any functional GNSS/Wheel-IMU linkage, deferring the more complex task of optimizing fusion algorithms or comparing loosely versus tightly coupled approaches until the basic concept was proven."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Because this study focuses on investigating the idea and feasibility of fusing GNSS with Wheel-IMU instead of algorithm research for GNSS/INS fusion, we adopt the classical loosely coupled framework and use the EKF in the proposed Wheel-GINS."
            ],
            "img_path": "2501.03079/wheelgins_overview.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03332",
        "img_path": "2501.03332/x2.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Adaptive Fusion Models for Homogeneous Multimodal Time Series Analysis",
                "B. Scalable Architectures for Unimodal Data Integration in Interaction Networks",
                "C. Optimizing Transfer Learning Techniques for Structured Multimodal Datasets",
                "D. Deep Representation Learning for Consistent Interaction Pattern Recognition",
                "E. CM3T: Framework for Efficient Multimodal Learning for Inhomogeneous Interaction Datasets"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "CM3T: Framework for Efficient Multimodal Learning for Inhomogeneous Interaction Datasets"
            ],
            "img_path": "2501.03332/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement accurately reflects the primary rationale for employing the Video Swin-B transformer as the backbone for CM3T, considering CM3T's model-agnostic design and its approach to multimodal integration?",
            "options": [
                "A. Video Swin-B was chosen because it inherently requires the fewest trainable parameters for video processing among potential backbones, directly aligning with CM3T's overall efficiency goals.",
                "B. The selection of Video Swin-B facilitates easier early fusion of modalities due to its unique input concatenation capabilities, which CM3T preferentially leverages for certain types of side inputs.",
                "C. Video Swin-B's architecture, where different blocks process input at varying spatial resolutions, allows CM3T's cross-attention mechanism to effectively integrate side modal inputs at multiple, potentially optimal, levels.",
                "D. CM3T's model-invariance is largely a theoretical aspiration; Video Swin-B is the only transformer backbone currently validated to successfully work with its cross-attention adapters due to its specific handling of feature downsampling artifacts.",
                "E. The Video Swin-B transformer was selected due to its documented superior performance in complex self-supervised learning pretraining regimes, which is an implicit prerequisite for the effective functioning of CM3T's plugin architecture."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The reason for choosing Video Swin-B is that different blocks process the input at different spatial resolutions. Depending on the side input (other modalities), cross-attention performs well with different blocks, that is, different spatial resolutions."
            ],
            "img_path": "2501.03332/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03122",
        "img_path": "2501.03122/x1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Adapting Layer Normalization for Imbalanced Data Classification",
                "B. Enhancing Deep Learning Models with Dynamic Normalization Techniques",
                "C. Investigating the Effects of Batch Normalization on Imbalanced Image Datasets",
                "D. Normalizing Batch Normalization for Long-Tailed Recognition",
                "E. Improving Feature Representation through Normalization in Skewed Class Distributions"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Normalizing Batch Normalization for Long-Tailed Recognition"
            ],
            "img_path": "2501.03122/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most accurately details the specific transformation applied to Batch Normalization parameters by NBN and the immediate, intended impact of this transformation on both the parameters themselves and the resultant feature representations critical for long-tailed recognition?",
            "options": [
                "A. NBN enhances feature strength for rare classes by directly adding a learnable bias to the Batch Normalization layer's output, thereby re-calibrating the feature space.",
                "B. The core of NBN involves normalizing the convolutional weights preceding Batch Normalization layers, which indirectly balances the BN parameters and improves feature discrimination.",
                "C. NBN transforms Batch Normalization Weight/Bias parameters by representing them as vectors, normalizing them to unit length, and then multiplying by a learnable scalar, which directly results in a more balanced distribution of these BN parameters and subsequently more even strength across class-specific features.",
                "D. NBN's primary transformation is to regularize the variance of Batch Normalization parameters through the training objective, forcing them towards a uniform magnitude to strengthen otherwise weak rare-class features.",
                "E. By decoupling the direction and magnitude of Batch Normalization parameters, NBN primarily accelerates the convergence of the network during training, leading to implicitly stronger features for rare classes due to more efficient optimization."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "NBN transforms Batch Normalization Weight/Bias parameters by representing them as vectors, normalizing them to unit length, and then multiplying by a learnable scalar, which directly results in a more balanced distribution of these BN parameters and subsequently more even strength across class-specific features."
            ],
            "img_path": "2501.03122/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03190",
        "img_path": "2501.03190/ICASSP2025_derail_diagram2.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Multimodal Machine Learning Can Predict Videoconference Fluidity and Enjoyment",
                "B. Evaluating User Engagement in Virtual Meetings Using Single-Modal Data Analysis",
                "C. Adaptive Algorithms for Enhancing Audio Quality in Online Video Communication",
                "D. Predictive Models for Network Latency Impact on Remote Collaboration Efficiency",
                "E. Analyzing Speaker Behavior to Improve Interaction Dynamics in Video Conferencing"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Multimodal Machine Learning Can Predict Videoconference Fluidity and Enjoyment"
            ],
            "img_path": "2501.03190/ICASSP2025_derail_diagram2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the maximum ROC-AUC achieved by the models designed to predict subjective conversational outcomes, a key aspect of identifying negative user experiences, using multimodal signals?",
            "options": [
                "A. 0.78",
                "B. 0.87",
                "C. 3",
                "D. 4",
                "E. 0.92"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "0.87"
            ],
            "img_path": "2501.03190/ICASSP2025_derail_diagram2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02994",
        "img_path": "2501.02994/x1.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Graph Neural Networks for Spatiotemporal Data on Complex Manifolds",
                "B. Deep Learning Approaches to Manifold Regularization in High-Dimensional Spaces",
                "C. Bayesian Inference Methods for Density Estimation in Product Metric Spaces",
                "D. NeuroPMD: Neural Fields for Density Estimation on Product Manifolds",
                "E. Hierarchical Neural Models for Feature Extraction on Composite Manifolds"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "NeuroPMD: Neural Fields for Density Estimation on Product Manifolds"
            ],
            "img_path": "2501.02994/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, describe in a single sentence the rationale for the unsuitability of data-driven functional basis construction methods for the density estimation problem addressed.",
            "options": [
                "A. These methods are unsuitable primarily due to the exponential growth of the parameter space with increasing dimensionality (D), making them computationally intractable for high-dimensional product manifold domains.",
                "B. These methods are unsuitable because their computational cost scales with the number of observations (n), which is excessively large in the motivating structural connectomics application (n > 10^6).",
                "C. These methods are unsuitable as they fail to mitigate the curse of dimensionality that broadly limits traditional kernel and basis expansion estimators in high-dimensional settings, a challenge the proposed neural network overcomes.",
                "D. These methods are unsuitable due to the inherent difficulty in selecting appropriate bandwidths for high-dimensional manifold domains, leading to issues of over-smoothing or under-smoothing frequently encountered in kernel density estimation.",
                "E. These methods are unsuitable because the specific problem setting lacks both the necessary replicated functions and the applicability of a direct signal plus noise observation model."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "These methods are unsuitable because the specific problem setting lacks both the necessary replicated functions and the applicability of a direct signal plus noise observation model."
            ],
            "img_path": "2501.02994/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03462",
        "img_path": "2501.03462/framework.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Teng Shi",
                "B. Yu-Cheng Liu",
                "C. Chao Xiao",
                "D. Yunshan Yang",
                "E. An-Zi Yen"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Yu-Cheng Liu"
            ],
            "img_path": "2501.03462/framework.png"
        },
        "level2_qa": {
            "question": "In this paper, what single number, presented as research data, quantifies the Pearson correlation coefficient that, when evaluated against its reported p-value, underpins the conclusion that student pass rates on Taiwan's university entrance exams are not significantly correlated with the assessed difficulty of English vocabulary questions?",
            "options": [
                "A. 0.113",
                "B. -0.118",
                "C. 6",
                "D. 0.118",
                "E. 0.05"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "-0.118"
            ],
            "img_path": "2501.03462/framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03624",
        "img_path": "2501.03624/MADRS.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. LlaMADRS: Prompting Large Language Models for Interview-Based Depression Assessment",
                "B. Enhancing Mental Health Diagnostics through Multimodal Neural Networks",
                "C. Evaluating Cognitive Load in Clinical Interviews Using Transformer Models",
                "D. Automated Anxiety Detection Using Contextual Language Understanding",
                "E. Developing Behavioral Markers for PTSD Assessment with Deep Learning Techniques"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "LlaMADRS: Prompting Large Language Models for Interview-Based Depression Assessment"
            ],
            "img_path": "2501.03624/MADRS.png"
        },
        "level2_qa": {
            "question": "In this paper, what single numerical value quantifies the corpus of transcribed human-led clinical interactions from the CAMI dataset that served as the direct empirical basis for evaluating the scoring performance of the LlaMADRS framework?",
            "options": [
                "A. 3",
                "B. 2",
                "C. 236",
                "D. 280",
                "E. 1979"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "236"
            ],
            "img_path": "2501.03624/MADRS.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03499",
        "img_path": "2501.03499/new1.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Evaluating Machine Learning Techniques for Mobile Image Classification",
                "B. Enhancing Real-Time Object Detection on Mobile Devices Using Neural Networks",
                "C. Can Deep Learning Trigger Alerts from Mobile-Captured Images?",
                "D. A Comparative Study of Alert Systems Based on Sensor Data from Mobile Platforms",
                "E. Optimizing Mobile Image Processing Pipelines for Improved Event Recognition"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Can Deep Learning Trigger Alerts from Mobile-Captured Images?"
            ],
            "img_path": "2501.03499/new1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct pollutant types that the 'HealthCamCNN' model, specifically in its role within the described dashboard system, is stated to ultimately predict through its defined operational stages?",
            "options": [
                "A. 2",
                "B. 5",
                "C. 3",
                "D. 7",
                "E. 6"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "7"
            ],
            "img_path": "2501.03499/new1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03301",
        "img_path": "2501.03301/x1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Advancing Privacy Preservation in Federated Recommendation Through Differential Aggregation Methods",
                "B. Analyzing Communication Efficiency in Federated Learning for Robust Recommendation Systems",
                "C. Optimizing Collaborative Filtering under Adversarial Conditions with Dense Aggregation Techniques",
                "D. Evaluating Trust Mechanisms in Distributed Recommendation Networks Using Sparse Data Models",
                "E. Rethinking Byzantine Robustness in Federated Recommendation from Sparse Aggregation Perspective"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Rethinking Byzantine Robustness in Federated Recommendation from Sparse Aggregation Perspective"
            ],
            "img_path": "2501.03301/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct types of vulnerabilities that arise specifically from the long tail distribution of item degrees in federated recommendation under sparse aggregation, as theoretically analyzed and explicitly discussed in relation to individual item robustness?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2501.03301/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04014",
        "img_path": "2501.04014/aicat.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Evaluating AI Compliance Frameworks for International Policy Integration",
                "B. AICat: An AI Cataloguing Approach to Support the EU AI Act",
                "C. Machine Learning Techniques for Automated Legal Document Analysis",
                "D. Advancing European AI Regulation through Predictive Risk Assessment Models",
                "E. Developing a Smart Registry System for AI Technologies under International Standards"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "AICat: An AI Cataloguing Approach to Support the EU AI Act"
            ],
            "img_path": "2501.04014/aicat.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement accurately synthesizes AICat's foundational approach to extending DCAT, encompassing both the specific structural additions it introduces as a 'minimal extension' and the explicitly named mechanism intended for the future detailed specification of information element necessities?",
            "options": [
                "A. AICat's foundational approach establishes it as a minimal extension of DCAT by introducing `aicat:Catalog` along with `airo:AISystem` and `airo:AIModel` as new types of `dcat:Resource`, while concurrently planning to utilize the Shapes Constraint Language (SHACL) for the future specification of the necessity level of information elements.",
                "B. AICat extends DCAT primarily by leveraging DCAT-AP to currently define mandatory, recommended, and optional elements through `aicat:Catalog` and `airo:AISystem`, with SHACL being a secondary consideration for general interoperability rather than for defining necessity levels.",
                "C. As a minimal extension, AICat introduces `aicat:Catalog`, `airo:AISystem`, and `airo:AIModel`, and relies on the inherent properties of DCAT-AP itself, rather than an external mechanism like SHACL, for the eventual definition of normative profiles based on AI Act guidelines.",
                "D. The minimal extension of DCAT by AICat is solely characterized by the addition of `aicat:Catalog`, with `airo:AISystem` and `airo:AIModel` being managed via SHACL shapes that already specify their mandatory and optional components based on existing AI Act recommendations.",
                "E. AICat's foundational approach is to use SHACL to define `aicat:Catalog` and a generic `airo:Resource` as minimal extensions of DCAT, thereby enabling immediate compliance with AI Act requirements for distinguishing information element necessity without further guidelines."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "AICat's foundational approach establishes it as a minimal extension of DCAT by introducing `aicat:Catalog` along with `airo:AISystem` and `airo:AIModel` as new types of `dcat:Resource`, while concurrently planning to utilize the Shapes Constraint Language (SHACL) for the future specification of the necessity level of information elements."
            ],
            "img_path": "2501.04014/aicat.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03835",
        "img_path": "2501.03835/x3.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. TACLR: Enhancing Deep Learning Models for Industrial Product Classification",
                "B. A Novel Framework for Attribute Extraction in E-commerce Product Catalogs",
                "C. TACLR: A Scalable and Efficient Retrieval-based Method for Industrial Product Attribute Value Identification",
                "D. Scalable Neural Approaches to Product Recommendation in Manufacturing Systems",
                "E. Efficient Data Mining Techniques for Identifying Product Specifications in Industrial Databases"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "TACLR: A Scalable and Efficient Retrieval-based Method for Industrial Product Attribute Value Identification"
            ],
            "img_path": "2501.03835/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, identify the single-word characteristic of TACLR's outputs, stemming from its retrieval-based nature and use of a predefined taxonomy, that inherently mitigates a primary concern associated with generation-based PAVI methods.",
            "options": [
                "A. Implicit",
                "B. Scalable",
                "C. Normalized",
                "D. Efficient",
                "E. OOD"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Normalized"
            ],
            "img_path": "2501.03835/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03827",
        "img_path": "2501.03827/x1.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Optimization of Cryogenic Resonators for Enhanced Microwave Astronomy Detectors",
                "B. Characterization of High-Resolution Bolometers for Ground-Based Submillimeter Imaging",
                "C. Development of Novel Polarimetric Techniques Using Superconducting Transition Edge Sensors",
                "D. Demonstration of Ultra-Sensitive KIDs for Future THz Space Borne Polarimeters",
                "E. Analysis of Noise Reduction Methods in Spaceborne Far-Infrared Spectrometers"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Demonstration of Ultra-Sensitive KIDs for Future THz Space Borne Polarimeters"
            ],
            "img_path": "2501.03827/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific percentage is reported as the overall plane-wave coupling efficiency for a pixel, a figure that is explicitly linked to the use of a 40 nm-thick aluminum film which differentiates the current device's performance from that detailed in reference [6]?",
            "options": [
                "A. 71.7",
                "B. 55.4",
                "C. 51.6",
                "D. 78.1",
                "E. 72.7"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "51.6"
            ],
            "img_path": "2501.03827/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04063",
        "img_path": "2501.04063/FIEMF.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Fuzzy Information Entropy and Region Biased Matrix Factorization for Web Service QoS Prediction",
                "B. Enhanced Web Service Reliability Analysis Using Probabilistic Entropy Models",
                "C. Region Adaptive Matrix Decomposition for Dynamic QoS Optimization in Cloud Services",
                "D. Entropy-Based Clustering Approaches for Web Service Performance Evaluation",
                "E. Biased Factorization Techniques for Predicting User Satisfaction in Distributed Web Systems"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Fuzzy Information Entropy and Region Biased Matrix Factorization for Web Service QoS Prediction"
            ],
            "img_path": "2501.04063/FIEMF.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the highest matrix density, expressed as a numerical percentage value, at which the FIEMF method—which distinctively addresses limitations of prior matrix factorization by incorporating user information entropy for local similarity assessment and region bias for non-interactive effects—is explicitly documented to achieve superior predictive performance over established state-of-the-art approaches?",
            "options": [
                "A. 3",
                "B. 5",
                "C. 15",
                "D. 20",
                "E. 25"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "20"
            ],
            "img_path": "2501.04063/FIEMF.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02471",
        "img_path": "2501.02471/x3.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine",
                "B. Hengqin-RA-v1: Integrating Machine Learning and Western Medicine Approaches for Rheumatoid Arthritis Management",
                "C. Development of a Multi-Modal Diagnostic System for Rheumatoid Arthritis Using Biomedical Imaging and Electronic Health Records",
                "D. Evaluating Traditional Herbal Remedies through Computational Models in the Treatment of Autoimmune Diseases",
                "E. Advanced Neural Networks for Predicting Treatment Outcomes in Rheumatoid Arthritis Patients Using Clinical Data"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine"
            ],
            "img_path": "2501.02471/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement most accurately synthesizes the multifaceted strategy employed to address the identified deficiencies of general-purpose LLMs in the specialized domain of Traditional Chinese Medicine for rheumatoid arthritis, considering data resourcing, model creation, and operational enhancement?",
            "options": [
                "A. The paper primarily focuses on creating Hengqin-RA-v1, whose superiority stems from its advanced architecture, effectively overcoming language bias and domain specificity through inherent model capabilities rather than extensive specialized data or subsequent enhancements.",
                "B. The core innovation is the HQ-GCM-RA-C1 dataset, which, by meticulously curating ancient Chinese medical texts and modern clinical studies into prompt-form data, enables existing general-purpose LLMs to achieve culturally informed TCM diagnoses for RA without needing a new model architecture.",
                "C. The paper's strategy relies on fine-tuning existing state-of-the-art LLMs using the HQ-GCM-RA-C1 dataset, whose unique structure, derived from a five-step journal data processing method for dialogue generation, is the principal factor in improving TCM reasoning for RA.",
                "D. The solution involves developing a specialized LLM (Hengqin-RA-v1) trained on a comprehensive, RA-specific TCM Chinese corpus (HQ-GCM-RA-C1) that includes diverse sources like ancient texts, dissertations, and exam questions to improve reasoning, further enhanced by an instance-oriented retrieval method that integrates external examples to ensure accurate, culturally relevant, and context-aware outputs.",
                "E. The instance-oriented retrieval enhancement is presented as the central mechanism to adapt general-purpose LLMs for TCM in RA, dynamically incorporating RA patient records to compensate for deficiencies in their training data and generalist design, thereby minimizing the need for a newly developed corpus or model."
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "The solution involves developing a specialized LLM (Hengqin-RA-v1) trained on a comprehensive, RA-specific TCM Chinese corpus (HQ-GCM-RA-C1) that includes diverse sources like ancient texts, dissertations, and exam questions to improve reasoning, further enhanced by an instance-oriented retrieval method that integrates external examples to ensure accurate, culturally relevant, and context-aware outputs."
            ],
            "img_path": "2501.02471/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02407",
        "img_path": "2501.02407/image8325.jpg",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Enhancing Privacy in Neural Language Models",
                "B. A Framework for Secure Text Generation",
                "C. Techniques for Obfuscating User Data in Language Processing",
                "D. Towards the Anonymization of the Language Modeling",
                "E. Evaluating the Impact of Masking on Language Model Performance"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Towards the Anonymization of the Language Modeling"
            ],
            "img_path": "2501.02407/image8325.jpg"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most accurately describes the fundamental basis upon which the 'distinguishable nature' of an indirect identifier is established, and how this basis affects the scope of protection offered by the proposed methodologies that identify such identifiers primarily through analysis of the fine-tuning dataset?",
            "options": [
                "A. The distinguishable nature of an indirect identifier is solely determined by its statistical rarity within the fine-tuning dataset, meaning the proposed methodologies offer complete protection if all such rare terms are masked.",
                "B. The distinguishable nature of an indirect identifier is established by its presence in official PII lists recommended by data protection authorities, making the proposed methodologies effective by cross-referencing these lists during preprocessing of the fine-tuning dataset.",
                "C. The distinguishable nature of an indirect identifier fundamentally depends on the adversary's auxiliary knowledge, implying that the proposed methodologies, by focusing on identifiers within the fine-tuning dataset, might not cover all terms an adversary considers identifying if their knowledge base differs significantly.",
                "D. The distinguishable nature of an indirect identifier is an inherent property of the word itself regardless of context or population, allowing the proposed methodologies to use universal lexicons of generally sensitive terms for masking from the fine-tuning dataset.",
                "E. The distinguishable nature of an indirect identifier is primarily established through its detection by advanced Named Entity Recognition (NER) models applied to the fine-tuning dataset, which is the core mechanism the proposed methodologies leverage for comprehensive privacy for all identifier types."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "This distinguishable nature depends on the adversary’s auxiliary knowledge.",
                "To achieve this goal [detecting indirect identifiers], an analysis of the data corpus can be carried out.",
                "Note that the indirect identifiers detected from the attacker’s auxiliary information are most likely different from the indirect identifiers from the dataset used to fine-tune the model."
            ],
            "img_path": "2501.02407/image8325.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02524",
        "img_path": "2501.02524/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Evaluating Performance Metrics of NVMe over Fabrics in Distributed Storage Systems",
                "B. Design and Implementation of Hybrid Memory Architectures for High-Speed Computing",
                "C. A Full-System Simulation Framework for CXL-Based SSD Memory System",
                "D. Modeling Data Consistency in Persistent Memory Systems with RDMA Support",
                "E. A Scalable Cache Management Approach for Multi-Level Storage Hierarchies"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "A Full-System Simulation Framework for CXL-Based SSD Memory System"
            ],
            "img_path": "2501.02524/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, how many of the explicitly listed CXL-specific transaction types added to gem5’s Packet class represent requests initiated from the host (Memory to Slave/Switch) perspective towards the CXL device?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 3",
                "E. 4"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.02524/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02512",
        "img_path": "2501.02512/final_framework.jpg",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Kadirya Tursun",
                "B. Andrea K. Dupree",
                "C. Shuanglin Li",
                "D. Zhijie Xie",
                "E. Syed Mohsen Naqvi"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Shuanglin Li"
            ],
            "img_path": "2501.02512/final_framework.jpg"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct, pre-existing technological elements (defined as named models, specific mechanisms, or foundational architectural concepts) are explicitly identified as either being directly incorporated into, forming a primary structural basis for, or having a specific, noted limitation directly addressed by the novel components of the proposed long-sequence depression estimation framework?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2501.02512/final_framework.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02583",
        "img_path": "2501.02583/sequence-v4.jpg",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Eye Movement Patterns in Virtual Reality Learning Environments for Children with ADHD",
                "B. Social Interaction Dynamics in Classroom Settings Using Robot-Assisted Therapy",
                "C. Gaze Behavior During a Long-Term, In-Home, Social Robot Intervention for Children with ASD",
                "D. Visual Attention and Engagement Metrics in Short-Term Robot-Led Play Sessions with Neurotypical Children",
                "E. Comparative Study of Human-Robot Interaction Effects on Cognitive Development in Early Childhood"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Gaze Behavior During a Long-Term, In-Home, Social Robot Intervention for Children with ASD"
            ],
            "img_path": "2501.02583/sequence-v4.jpg"
        },
        "level2_qa": {
            "question": "In this paper, what is the numerical result of multiplying the count of male children who completed the study by the diagnostic cutoff score of the ADOS?",
            "options": [
                "A. 20",
                "B. 32",
                "C. 52",
                "D. 58.4",
                "E. 25"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "32"
            ],
            "img_path": "2501.02583/sequence-v4.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02786",
        "img_path": "2501.02786/x1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. CCStereo: Audio-Visual Contextual and Contrastive Learning for Binaural Audio Generation",
                "B. Multimodal Fusion Techniques for Enhanced 3D Audio Reconstruction",
                "C. Deep Contrastive Models for Spatial Sound Source Localization",
                "D. Context-Aware Neural Networks for Real-Time Binaural Audio Processing",
                "E. Audio-Visual Synchronization and Contrastive Learning in Virtual Acoustic Environments"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "CCStereo: Audio-Visual Contextual and Contrastive Learning for Binaural Audio Generation"
            ],
            "img_path": "2501.02786/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, regarding the conceptual underpinnings of the audio-visual conditional normalisation layer, what is the total count of distinct prior application domains or methodological categories of normalisation techniques that are explicitly mentioned as either sources of inspiration for, or points of contrast with, its design?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2501.02786/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02843",
        "img_path": "2501.02843/v7-RAHF-framework.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. RAHN: A Reputation Based Hourglass Network for Web Service QoS Prediction",
                "B. A Trust-Driven Cascade Architecture for Enhancing Web Service Performance Evaluation",
                "C. Leveraging User Feedback in Multi-Layer Networks for Service Quality Assessment",
                "D. Adaptive Graph Models for Predicting Reliability in Cloud-Based Web Services",
                "E. Hybrid Deep Learning Framework for Dynamic QoS Analysis in Distributed Web Environments"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "RAHN: A Reputation Based Hourglass Network for Web Service QoS Prediction"
            ],
            "img_path": "2501.02843/v7-RAHF-framework.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement most accurately synthesizes the design rationale of the Reputation Calculation Module (RCM), its operational methodology, and its specific objective related to user data quality, when contextualized by the stated inspirations from prior deep learning research?",
            "options": [
                "A. The RCM, directly adopting topic-aware heterogeneous graph neural networks from Peng et al. for its operational methodology, calculates user reputation primarily to mitigate the QoS data sparsity issues highlighted by Jia et al.",
                "B. Inspired by the general success of deep learning, the RCM's design rationale is to utilize its clustering algorithm and Logit model primarily for extracting high-dimensional nonlinear latent features from user data, mirroring the approach of Jia et al.'s MLP.",
                "C. While the overall RAHN framework's design, including the conception of RCM, LFEM, and QPHN, was influenced by the demonstrated potential of deep learning techniques in prior works, the RCM's operational methodology specifically employs clustering and Logit models to assess user trustworthiness by addressing the issue of casual and subjective QoS observations, distinguishing its core mechanism from the specific deep learning approaches of Peng et al. or Jia et al.",
                "D. The RCM's design rationale fundamentally stems from its deep learning-based operational methodology, which enhances traditional clustering and Logit models through techniques analogous to Peng et al.'s fine-grained semantic analysis, to directly address the challenge of service homogenization.",
                "E. The RCM was conceived as an independent module whose operational methodology, centered on Logit models, was designed to pre-process user data for QoS prediction without significant influence from the deep learning advancements cited from Peng et al. or Jia et al., focusing instead on simple user trustworthiness scores."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "While the overall RAHN framework's design, including the conception of RCM, LFEM, and QPHN, was influenced by the demonstrated potential of deep learning techniques in prior works, the RCM's operational methodology specifically employs clustering and Logit models to assess user trustworthiness by addressing the issue of casual and subjective QoS observations, distinguishing its core mechanism from the specific deep learning approaches of Peng et al. or Jia et al."
            ],
            "img_path": "2501.02843/v7-RAHF-framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02344",
        "img_path": "2501.02344/DJI_0054_MOV-55.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Accurate Crop Yield Estimation of Blueberries using Deep Learning and Smart Drones",
                "B. Optimization of Blueberry Growth with IoT Sensors and Machine Learning Techniques",
                "C. Remote Sensing and Climate Data Analysis for Predicting Blueberry Harvest Quality",
                "D. Comparative Study of Traditional and AI-based Methods for Berry Crop Disease Detection",
                "E. Enhancing Blueberry Post-Harvest Shelf Life through Automated Quality Assessment Systems"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Accurate Crop Yield Estimation of Blueberries using Deep Learning and Smart Drones"
            ],
            "img_path": "2501.02344/DJI_0054_MOV-55.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement best synthesizes the divergent data augmentation strategies for the Bush and Berry models, correctly identifying the primary rationale for the Berry Model's specific approach in the context of the YOLO architecture and object characteristics?",
            "options": [
                "A. Both the Bush and Berry models primarily utilized tiling of images into 640x640 segments to improve YOLO's performance on small objects, with the Bush model also incorporating hue and saturation adjustments for environmental variability.",
                "B. The Bush Model's training data was augmented through variations like hue, saturation, and scale, while the Berry Model's data augmentation involved dividing images into smaller, square tiles principally because the YOLO architecture is more effective with such input formats.",
                "C. Data augmentation for the Berry Model focused on tiling due to the high number of berries per image (over 1000 on average), whereas the Bush Model required geometric transformations because bushes have more variable shapes and sizes.",
                "D. To address the challenges of annotating occluded and shadowy berries, both models employed identical data augmentation techniques, including tiling and photometric adjustments, ensuring consistency in training.",
                "E. The Berry Model exclusively used tiling for data augmentation to manage the large dataset size (over 120,000 annotations), while the Bush Model used diverse augmentations because its dataset was significantly smaller and required more artificial expansion."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The Bush Model's training data was augmented through variations like hue, saturation, and scale, while the Berry Model's data augmentation involved dividing images into smaller, square tiles principally because the YOLO architecture is more effective with such input formats."
            ],
            "img_path": "2501.02344/DJI_0054_MOV-55.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02215",
        "img_path": "2501.02215/x3.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Planetary Edge Trends (PET). I. The Inner Edge-Stellar Mass Correlation",
                "B. Planetary Edge Trends (PET). II. The Outer Edge-Orbital Dynamics Relationship",
                "C. Analyzing Planetary Boundaries: Stellar Age Effects on Inner Orbital Limits",
                "D. Planetary Edge Trends (PET). III. Correlating Stellar Luminosity with Orbital Eccentricity",
                "E. Investigating the Impact of Stellar Metallicity on Planetary Orbit Boundaries"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Planetary Edge Trends (PET). I. The Inner Edge-Stellar Mass Correlation"
            ],
            "img_path": "2501.02215/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total count of distinct theoretical models discussed whose predicted power-law index for the relationship $a_{\\text{in}}\\propto M_{\\star}^{\\text{index}}$ falls strictly outside the primary empirical range of 0.6 to 1.1 reported for the correlation between the inner edge position and stellar mass?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2501.02215/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03697",
        "img_path": "2501.03697/kernel_chaining-neural.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Analyzing the Role of Kernel Methods in Modern Deep Learning Architectures",
                "B. Deep Networks are Reproducing Kernel Chains",
                "C. Towards Interpretable Representations: A Kernel Perspective on Neural Networks",
                "D. Bridging Feature Maps and Reproducing Kernels in Convolutional Networks",
                "E. Hierarchical Kernel Models for Efficient Deep Representation Learning"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Deep Networks are Reproducing Kernel Chains"
            ],
            "img_path": "2501.03697/kernel_chaining-neural.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the formal definition of an $L$-length neural cRKBS pair $(\\mathcal{B}^L, \\mathcal{B}^{L\\diamond})$, what is the sum of all distinct positive integer indices $j$ such that $\\Omega^j$ is explicitly specified as the domain type for any of the weighting functions $\\beta^1, \\ldots, \\beta^L$ or for the chain dual space $\\mathcal{B}^{L\\diamond}$, when $L=3$?",
            "options": [
                "A. 6",
                "B. 1",
                "C. 3",
                "D. 4",
                "E. 2"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2501.03697/kernel_chaining-neural.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03940",
        "img_path": "2501.03940/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Evaluating Token Importance: Weighted Networks for Natural Language Understanding",
                "B. Attention Mechanisms in Deep Learning: Enhancing Language Model Interpretability",
                "C. Hierarchical Token Embedding Strategies for Improved Text Classification",
                "D. Adaptive Perplexity Models for Robust AI-generated Content Identification",
                "E. Not all tokens are created equal: Perplexity Attention Weighted Networks for AI generated text detection"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Not all tokens are created equal: Perplexity Attention Weighted Networks for AI generated text detection"
            ],
            "img_path": "2501.03940/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value, representing a percentage, is provided as the mean macro-averaged F1 score that demonstrates the PAWN method's multilingual generalization capability with the LLaMA3-1B backbone, specifically when tested in cross-validation across nine languages not seen during supervised training?",
            "options": [
                "A. 81.46",
                "B. 1.00",
                "C. 9.00",
                "D. 50.00",
                "E. 0.00"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "81.46"
            ],
            "img_path": "2501.03940/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03808",
        "img_path": "2501.03808/x1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Private, Auditable, and Distributed Ledger for Financial Institutes",
                "B. Secure and Scalable Consensus Mechanisms for Decentralized Banking Systems",
                "C. Transparent and Immutable Record-Keeping in Multi-Party Financial Networks",
                "D. Enhancing Privacy in Blockchain-Based Transaction Protocols for Banks",
                "E. Distributed Data Validation Techniques for Cross-Institutional Financial Services"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Private, Auditable, and Distributed Ledger for Financial Institutes"
            ],
            "img_path": "2501.03808/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering PADL's design where the 'sender' is initially aware of all participant values (`v_{t,p,a}`) for a given transaction, what is the specific cryptographic mechanism and its operational principle that ensures the confidentiality of an individual participant's value (`v_{t,p,a}`) from other uninvolved participants and from external observers examining the transaction data as it is appended to the public ledger, while still permitting essential structural validations of the transaction?",
            "options": [
                "A. The sender's comprehensive knowledge of values is cryptographically nullified post-transaction submission by the `PACT.Spend` algorithm, making `v_{t,p,a}` accessible only through a participant's `sk_p`, while `Π_p cm_{t,p,a} = 1` confirms overall balance to observers.",
                "B. The Pedersen commitment (`cm_{t,p,a} = g^{v_{t,p,a}} h^{r_{t,p,a}}`) inherently conceals `v_{t,p,a}` from any entity lacking the specific random blinding factor `r_{t,p,a}` for that cell, thereby encrypting it on the ledger. Concurrently, the token (`tk_{t,p,a}`) and its associated proof of consistency (`π^C_{t,p,a}`) allow verification of the participant's involvement and the correct use of `r_{t,p,a}` without exposing the underlying `v_{t,p,a}`.",
                "C. Zero-knowledge proofs, as broadly indicated for PADL, are applied by the sender to demonstrate the validity of `Σ_p v_{t,p,a} = 0` and `Σ_p r_{t,p,a} = 0` for each asset, which indirectly protects individual `v_{t,p,a}` by focusing verifiability on aggregate properties rather than specific cell contents.",
                "D. The confidentiality of `v_{t,p,a}` relies on the 'no-trust setup' where each participant `p` generates their `cm_{t,p,a}` using their unique `sk_p` as the blinding factor, thus ensuring only they can later reveal their `v_{t,p,a}`, and the sender merely aggregates these pre-committed values.",
                "E. Transaction graph anonymity is the principal safeguard, ensuring that while `cm_{t,p,a}` might be public, linking it to a specific, identifiable participant `p` and their actual value `v_{t,p,a}` is rendered computationally infeasible for observers, even if the sender knows the initial mapping."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The Pedersen commitment (`cm_{t,p,a} = g^{v_{t,p,a}} h^{r_{t,p,a}}`) inherently conceals `v_{t,p,a}` from any entity lacking the specific random blinding factor `r_{t,p,a}` for that cell, thereby encrypting it on the ledger. Concurrently, the token (`tk_{t,p,a}`) and its associated proof of consistency (`π^C_{t,p,a}`) allow verification of the participant's involvement and the correct use of `r_{t,p,a}` without exposing the underlying `v_{t,p,a}`."
            ],
            "img_path": "2501.03808/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03948",
        "img_path": "2501.03948/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Kinetic theory of decentralized learning for smart active matter",
                "B. Statistical Mechanics of Autonomous Agents in Distributed Networks",
                "C. Dynamics of Cooperative Behavior in Self-Organizing Robotic Swarms",
                "D. Mathematical Modeling of Adaptive Control in Intelligent Modular Systems",
                "E. Theoretical Framework for Emergent Coordination in Bio-Inspired Active Materials"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Kinetic theory of decentralized learning for smart active matter"
            ],
            "img_path": "2501.03948/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, provide a single sentence that encapsulates the fundamental theoretical mechanism by which the authors bridge the micro-level interactions of policy exchange among agents to the macro-level description of the system’s overall policy dynamics.",
            "options": [
                "A. The paper establishes this bridge by utilizing a kinetic theory framework where local, binary policy exchanges between agents are treated as analogous to collision rules, which then forms the basis for systematically deriving macroscopic hydrodynamic equations for the time-evolution of these policies.",
                "B. The paper models this connection by focusing on how individual agents optimize their internal policies based on stored memory of environmental signals (G(S)), which then collectively shapes the macroscopic policy landscape through emergent behaviors independent of explicit exchange modeling.",
                "C. The paper explains this linkage by directly applying principles of stochastic thermodynamics to the decentralized learning process, allowing for the characterization of policy changes in terms of entropy production and free energy minimization at the system level.",
                "D. The paper achieves this by developing an agent-based model where policies are exclusively fixed parameters evolving solely through evolutionary dynamics, from which macroscopic policy states are inferred through statistical averaging without explicitly modeling exchange mechanisms.",
                "E. The paper outlines the bridge by assuming that agent policies universally and directly converge to a globally optimal state defined by external stimuli, with the macroscopic dynamics simply reflecting this convergence rather than resulting from a complex interplay of modeled local exchanges."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "The paper establishes this bridge by utilizing a kinetic theory framework where local, binary policy exchanges between agents are treated as analogous to collision rules, which then forms the basis for systematically deriving macroscopic hydrodynamic equations for the time-evolution of these policies."
            ],
            "img_path": "2501.03948/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03518",
        "img_path": "2501.03518/x2.png",
        "level1_qa": {
            "question": "Identify the paper that contains this figure.",
            "options": [
                "A. Adaptive Reinforcement Learning Strategies for Quantum-Inspired Optimization Algorithms",
                "B. Hybrid Neural Network Approaches to Quantum Heuristic Methods in Combinatorial Problems",
                "C. Transfer Learning for Deep-Unfolded Combinatorial Optimization Solver with Quantum Annealer",
                "D. Optimization of Quantum Circuits Using Deep Generative Models and Transfer Protocols",
                "E. Scalable Deep Learning Frameworks for Classical Combinatorial Solvers with Quantum Acceleration"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Transfer Learning for Deep-Unfolded Combinatorial Optimization Solver with Quantum Annealer"
            ],
            "img_path": "2501.03518/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, when examining the parameter optimization strategies for classical-quantum transfer learning for DUOM, QAOA, and classical tensor network optimization, what is the total count of *distinct, explicitly articulated rationales* centered on computational expense or inherent representational limitations that serve to explain either (i) a constraint on the categories of parameters that are tuned within a specific methodology, or (ii) the deliberate choice to conduct the entire parameter training phase exclusively within a classical computational framework for one of these methodologies?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2501.03518/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03839",
        "img_path": "2501.03839/image.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Enhancing Medical Image Segmentation with Multi-scale Feature Aggregation",
                "B. Deep Learning Approaches for Large-scale Medical Data Annotation",
                "C. MedFocusCLIP : Improving few shot classification in medical datasets using pixel wise attention",
                "D. Pixel-level Interpretability Techniques for Diagnostic Imaging",
                "E. Cross-modal Fusion Strategies in Medical Image Analysis"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "MedFocusCLIP : Improving few shot classification in medical datasets using pixel wise attention"
            ],
            "img_path": "2501.03839/image.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the numerical difference in the percentage points of accuracy improvement observed by the proposed approach over the pretrained CLIP model when comparing the brain-tumor dataset to the COVID dataset?",
            "options": [
                "A. 5",
                "B. 23",
                "C. 13",
                "D. 15",
                "E. 2"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "13"
            ],
            "img_path": "2501.03839/image.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03496",
        "img_path": "2501.03496/x4.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Yijing Wang",
                "B. Wentao Zhang",
                "C. Rui Zhao",
                "D. Jinming Gao",
                "E. Yang Shi"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Jinming Gao"
            ],
            "img_path": "2501.03496/x4.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the hybrid attack detection framework detailed in Algorithm 3, if agent *i*'s initial assessment after a communication channel (j,i) attack is {φ_ij1(k)=1, φ_ij2(k)=2} for agent *j*, and subsequently a trusted agent ĵ (an out-neighbor of *j*) reports {φ_ĵj1(k)=1, φ_ĵj2(k)=0} regarding agent *j*, while agent *i*'s own assessment of this trusted agent ĵ is {φ_iĵ1(k)=0, φ_iĵ2(k)=0}, what is agent *i*'s conclusive classification of agent *j*'s status?",
            "options": [
                "A. Byzantine",
                "B. Normal",
                "C. Pending",
                "D. Unclassifiable",
                "E. Tolerated"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Byzantine"
            ],
            "img_path": "2501.03496/x4.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04292",
        "img_path": "2501.04292/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. A Comparative Study of Rodent Vocalization Analysis for Neurobehavioral Assessment",
                "B. Ultrasound-Based Behavioral Profiling of Laboratory Mice in Autism Spectrum Models",
                "C. MADUV: The 1st INTERSPEECH Mice Autism Detection via Ultrasound Vocalization Challenge",
                "D. Developing Automated Systems for Analyzing Mouse Vocal Patterns in Social Interaction Studies",
                "E. Challenges in Neural Signal Interpretation for Rodent Communication and Autism Research"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "MADUV: The 1st INTERSPEECH Mice Autism Detection via Ultrasound Vocalization Challenge"
            ],
            "img_path": "2501.04292/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific value to which the frequency dimension was standardized for the feature set that yielded the highest reported unweighted average recall (UAR) at the subject-level in the baseline system?",
            "options": [
                "A. 59",
                "B. 3",
                "C. 5",
                "D. 0.625",
                "E. 500"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "500"
            ],
            "img_path": "2501.04292/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04239",
        "img_path": "2501.04239/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Adaptive Spatial-Temporal Embedding in Graph Convolutional Networks",
                "B. Temporal Feature Extraction for Static Graph Neural Models",
                "C. Hierarchical Clustering Techniques for Dynamic Graph Representations",
                "D. Spatial Attention Mechanisms in Recurrent Graph Architectures",
                "E. Dynamic Localisation of Spatial-Temporal Graph Neural Network"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Dynamic Localisation of Spatial-Temporal Graph Neural Network"
            ],
            "img_path": "2501.04239/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what number represents the quantity of distinct real-world application datasets used to validate DynAGS's performance superiority?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 5",
                "D. 9",
                "E. 11"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "9"
            ],
            "img_path": "2501.04239/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04000",
        "img_path": "2501.04000/fig_taxonomy.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. A Comprehensive Review of Federated Learning for Environmental Monitoring",
                "B. A Survey on Federated Learning in Human Sensing",
                "C. Advances in Federated Learning Techniques for Healthcare Applications",
                "D. An Analysis of Distributed Learning Approaches in Human Activity Recognition",
                "E. Exploring Privacy-Preserving Machine Learning Methods in Wearable Devices"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "A Survey on Federated Learning in Human Sensing"
            ],
            "img_path": "2501.04000/fig_taxonomy.png"
        },
        "level2_qa": {
            "question": "In this paper, which of the following scenarios describing a Federated Learning in Human Sensing study best aligns with the authors' criteria for effectively addressing real-world complexities, such as client variability and data distribution challenges, as outlined in their eight-dimensional assessment?",
            "options": [
                "A. A study utilizing a face recognition dataset where each participating client's local data comprises images from multiple distinct individuals, partitioned synthetically for the experiment.",
                "B. A study that acknowledges the prevalence of non-IID data among clients but proceeds with training on publicly available datasets without specific strategies to ensure robustness or analyze its impact, assuming the datasets are sufficiently representative.",
                "C. A study where the central server possesses a large volume of meticulously labeled data, and clients primarily contribute computational resources to train models on this server-centric labeled dataset.",
                "D. A study that identifies and excludes client devices with \"non-standard\" hardware specifications as outliers to maintain a homogeneous training environment, thereby improving model convergence speed.",
                "E. A study that deploys its FL model across a range of client devices with varying computational power and explicitly analyzes the performance impact of non-IID data originating from these diverse clients."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "A study that deploys its FL model across a range of client devices with varying computational power and explicitly analyzes the performance impact of non-IID data originating from these diverse clients."
            ],
            "img_path": "2501.04000/fig_taxonomy.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04391",
        "img_path": "2501.04391/SchematicLinearShearcell.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Analysis of Shear Strength in Dry Granular Assemblies with Varied Particle Shapes",
                "B. Modeling the Thermal Conductivity of Granular Media under Different Moisture Conditions",
                "C. Comparison of bulk properties of wet granular materials using different capillary force approximations",
                "D. Experimental Investigation of Viscous Forces in Partially Saturated Granular Flows",
                "E. Evaluation of Packing Density Effects on Mechanical Behavior of Cohesionless Granular Materials"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Comparison of bulk properties of wet granular materials using different capillary force approximations"
            ],
            "img_path": "2501.04391/SchematicLinearShearcell.png"
        },
        "level2_qa": {
            "question": "In this paper, which builds upon Roy et al.'s identification of two primary factors for consistent bulk properties across different capillary force models and aims to verify the equivalence of the Willett and Bagheri approximations by examining steady-state cohesion and macroscopic friction coefficient, what is the explicitly stated total relative shearing velocity (identified as V_shear), in m/s, between the oppositely moving 'L'-shaped walls of the described numerical linear split-bottom shear cell?",
            "options": [
                "A. 0.008",
                "B. 0.016",
                "C. 0.032",
                "D. 2",
                "E. 3"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "0.016"
            ],
            "img_path": "2501.04391/SchematicLinearShearcell.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04217",
        "img_path": "2501.04217/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Guang Li",
                "B. Ren Tasai",
                "C. Ren Togo",
                "D. Minghui Tang",
                "E. Takaaki Yoshimura"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Ren Tasai"
            ],
            "img_path": "2501.04217/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, focusing strictly on the inputs to the encoders ϕ_M1 and ϕ_M2 that are utilized for calculating the feature distillation loss L_FD in Stage 3, what is the count of distinct data sources (from the set: D1, D2, the original rehearsal buffer B, the mixed batch 𝐛mix) that are processed by *only one* of these two encoders, but not both?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 3",
                "E. K (where K is the number of clusters D1 is divided into)"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "0"
            ],
            "img_path": "2501.04217/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03464",
        "img_path": "2501.03464/img_icassp.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Hierarchical Graph Convolutional Models for Speech Recognition and Analysis",
                "B. LHGNN: Local-Higher Order Graph Neural Networks For Audio Classification and Tagging",
                "C. Multi-Level Graph Attention Networks for Audio Scene Understanding",
                "D. Spectral Graph Neural Architectures for Music Genre Classification",
                "E. Temporal-Spatial Graph Networks for Real-Time Sound Event Detection"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "LHGNN: Local-Higher Order Graph Neural Networks For Audio Classification and Tagging"
            ],
            "img_path": "2501.03464/img_icassp.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total count of unique, explicitly specified numerical stride values for all convolutional layers detailed in the LHGNN architecture's description, encompassing the initial stem block processing the mel-spectrogram, any intermediate downsampling blocks, and any convolutional operations mentioned in the final processing stages before the fully connected layer?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.03464/img_icassp.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03440",
        "img_path": "2501.03440/sq_architecture.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Optimizing Deployment Pipelines: Efficiency and Sustainability in Cloud Environments",
                "B. Scalable Software Delivery: Balancing Speed and Resource Consumption",
                "C. CI at Scale: Lean, Green, and Fast",
                "D. Green Computing Strategies for Continuous Integration Systems",
                "E. Enhancing Build Performance: Methods for Rapid and Eco-Friendly Development"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "CI at Scale: Lean, Green, and Fast"
            ],
            "img_path": "2501.03440/sq_architecture.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the combined challenges of premature build aborts due to resource strain, delays for smaller changes blocked by larger ones (a limitation explicitly noted for systems like Aviator with cutoff scores), and the general resource inefficiencies observed in sequentially testing models like GitHub’s Merge Queue and GitLab’s Merge Train as well as in high-conflict or rapid-velocity scenarios affecting systems like Airbnb’s Evergreen, what specific percentage reduction, explicitly stated as a direct outcome of implementing the innovative probabilistic model for build prioritization and the speculation threshold, represents the most substantial decrease in consumption of general Continuous Integration resources achieved by the enhanced SubmitQueue?",
            "options": [
                "A. 37%",
                "B. 44%",
                "C. 53%",
                "D. 45%",
                "E. 50%"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "53%"
            ],
            "img_path": "2501.03440/sq_architecture.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03654",
        "img_path": "2501.03654/x1.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Xiaotao Wang",
                "B. J. Mauricio",
                "C. Assaf Shmuel",
                "D. Oren Glickman",
                "E. Teddy Lazebnik"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Assaf Shmuel"
            ],
            "img_path": "2501.03654/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the comprehensive validation process for the proposed data augmentation techniques, what is the specific quantity of distinct AutoDL frameworks, each detailed with capabilities such as automated model selection and hyperparameter management, that were collectively utilized to assess the performance impact on deep learning models for regression tasks?",
            "options": [
                "A. 1, representing solely the final AutoDL model (D) whose performance was enhanced and evaluated.",
                "B. 2, accounting for the initial AutoML model (M) and the subsequent AutoDL model (D) as distinct frameworks.",
                "C. 3, corresponding to the explicitly named and described AutoDL platforms employed for validation.",
                "D. 5, by summing the initial AutoML model (M), the AutoDL model (D), and the three externally referenced AutoDL platforms.",
                "E. 30, reflecting the total number of distinct datasets on which the validation was performed."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The efficacy of these DA strategies was rigorously validated across 30 distinct datasets, with multiple iterations and evaluations using three different automated deep learning (AutoDL) frameworks: AutoKeras, H2O, and AutoGluon."
            ],
            "img_path": "2501.03654/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03643",
        "img_path": "2501.03643/QSSL_meeting_latest_23.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Adaptive Low-Bit Quantization Techniques for Image Recognition Models",
                "B. Scalable Training of Deep Neural Networks with Dynamic Precision Scaling",
                "C. Optimization Strategies for Energy-Efficient Natural Language Processing Architectures",
                "D. Robust Parameter Pruning Methods in Large-Scale Transformer Models",
                "E. Effective and Efficient Mixed Precision Quantization of Speech Foundation Models"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Effective and Efficient Mixed Precision Quantization of Speech Foundation Models"
            ],
            "img_path": "2501.03643/QSSL_meeting_latest_23.png"
        },
        "level2_qa": {
            "question": "In this paper, when the novel mixed-precision quantization approach, detailed as a DARTS-variant supernet methodology for simultaneous training of varied bit-width candidates, is applied to the HuBERT-large model to achieve its optimal average bit-width of 3.5 bits, what specific lossless compression ratio is achieved relative to the 32-bit full-precision system?",
            "options": [
                "A. 1.5",
                "B. 1.7",
                "C. 1.9",
                "D. 3.5",
                "E. 8.6"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "8.6"
            ],
            "img_path": "2501.03643/QSSL_meeting_latest_23.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03567",
        "img_path": "2501.03567/x2.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Jinbin Bai",
                "B. Tianyu Cui",
                "C. Guo-Hua Wang",
                "D. Qing-Guo Chen",
                "E. Zhao Xu"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Tianyu Cui"
            ],
            "img_path": "2501.03567/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct evaluation perspectives are explicitly integrated into the CAMScore framework to enable a comprehensive, fine-grained, reference-free assessment of image captioning models and to directly address the modality gap challenge discussed across the methodology and results sections?",
            "options": [
                "A. One",
                "B. Two",
                "C. Three",
                "D. Four",
                "E. Five"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Three"
            ],
            "img_path": "2501.03567/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03731",
        "img_path": "2501.03731/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Bayesian EM Digital Twins Channel Estimation",
                "B. Deep Learning Approaches for Adaptive Channel Equalization",
                "C. Kalman Filter Optimization in Wireless Signal Processing",
                "D. Neural Network-Based Models for Real-Time Communication Systems",
                "E. Probabilistic Graphical Models in MIMO Channel Prediction"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Bayesian EM Digital Twins Channel Estimation"
            ],
            "img_path": "2501.03731/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, the distinct advantage of the EM-DT framework in pre-computing a priori orthonormal bases {Ū_S, Ū^p_T} stems from leveraging specific information encapsulated in the slow time-varying matrices {Ā(𝜽,𝝋), K̄p(𝝉)}, which are derived from L̄ paths. Once these matrices {Ā(𝜽,𝝋), K̄p(𝝉)} are available, how many fundamental types of matrix decomposition operations are explicitly mentioned as being performed on them to directly yield the orthonormal bases {Ū_S, Ū^p_T}?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. L̄",
                "E. T_B"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2501.03731/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03021",
        "img_path": "2501.03021/cascade_iclr25_v2.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. A Confidence-Based Framework for CT Image Enhancement Using Prior Data",
                "B. Leveraging Auxiliary Data in Multi-Modal MRI Segmentation Techniques",
                "C. Uncertainty-Aware Models for Accelerated MR Image Denoising",
                "D. Incorporating Metadata for Robust Medical Image Fusion Algorithms",
                "E. A Trust-Guided Approach to MR Image Reconstruction with Side Information"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "A Trust-Guided Approach to MR Image Reconstruction with Side Information"
            ],
            "img_path": "2501.03021/cascade_iclr25_v2.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most comprehensively synthesizes the TGVN framework's fundamental approach to resolving ambiguities in ill-posed Linear Inverse Problems (LIPs) by leveraging specific contextual information, its distinction from traditional regularization, and its claimed broad applicability?",
            "options": [
                "A. TGVN fundamentally enhances LIP solutions by integrating problem-specific contextual side information—distinct from general population-based priors—to selectively eliminate ambiguities stemming from the forward operator's ill-conditioning or rank-deficiency, thereby demonstrating versatility for diverse LIPs and various forms of side information, including non-image data.",
                "B. The TGVN framework's primary demonstrated strength is its optimization for multi-contrast knee MR image reconstruction, where it leverages moderately under-sampled PD k-space to significantly improve PDFS-weighted image quality from heavily undersampled data, particularly outperforming baselines in scenarios with trivial null spaces by better preserving anatomical details.",
                "C. TGVN operates as an advanced variational network that primarily learns superior, data-driven general priors from side information, which then act as powerful regularizers to globally constrain the solution space of any ill-posed LIP, making it more robust than methods reliant on predefined mathematical regularizers.",
                "D. TGVN innovatively solves LIPs by substituting parts of the ambiguous reconstruction derived from undersampled main data with corresponding high-quality features directly extracted from the side information, ensuring diagnostic quality by prioritizing the side information's content over strict adherence to the potentially corrupted main measurements.",
                "E. The core mechanism of TGVN involves using side information, such as different image contrasts or prior scans, exclusively to identify and correct hallucinations in reconstructions from highly accelerated medical imaging, thereby improving upon generative models that often suffer from such artifacts in ill-conditioned LIPs."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "TGVN fundamentally enhances LIP solutions by integrating problem-specific contextual side information—distinct from general population-based priors—to selectively eliminate ambiguities stemming from the forward operator's ill-conditioning or rank-deficiency, thereby demonstrating versatility for diverse LIPs and various forms of side information, including non-image data."
            ],
            "img_path": "2501.03021/cascade_iclr25_v2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04099",
        "img_path": "2501.04099/x6.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. I Made Putrama",
                "B. Jakob N. Foerster",
                "C. Guowen Zhang",
                "D. Benedikt Böck",
                "E. Peter Martinek"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "I Made Putrama"
            ],
            "img_path": "2501.04099/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the comprehensive evaluation conducted across both synthetic and real-world datasets, what is the exact total number of datasets (including both types) used to benchmark the 14 alternative resampling methods on nine classifiers, as explicitly reported?",
            "options": [
                "A. 9",
                "B. 14",
                "C. 20",
                "D. 21",
                "E. 29"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "21"
            ],
            "img_path": "2501.04099/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03859",
        "img_path": "2501.03859/overall.png",
        "level1_qa": {
            "question": "Who is the lead researcher of the paper shown in the figure?",
            "options": [
                "A. Mason Belue",
                "B. Mohammadreza Kasaei",
                "C. Haruo Fujiwara",
                "D. Farshid Alambeigi",
                "E. Mohsen Khadem"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Mohammadreza Kasaei"
            ],
            "img_path": "2501.03859/overall.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct modeling methodologies for continuum robot shape estimation are explicitly reviewed or referenced before the introduction of the proposed synergistic ANODE-based approach, considering both model-driven and data-driven categories as described in the Provided Text for Question Generation?",
            "options": [
                "A. 3",
                "B. 4",
                "C. 5",
                "D. 6",
                "E. 7"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "7"
            ],
            "img_path": "2501.03859/overall.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03881",
        "img_path": "2501.03881/lstm-architecture-v2.jpeg",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. An LSTM-based Test Selection Method for Self-Driving Cars",
                "B. A Reinforcement Learning Approach to Traffic Signal Optimization for Autonomous Vehicles",
                "C. Evaluating Sensor Fusion Techniques for Enhanced Object Detection in Self-Driving Cars",
                "D. Deep CNN Models for Lane Departure Warning Systems in Autonomous Driving",
                "E. Predictive Maintenance Scheduling Using Machine Learning for Electric Vehicles"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "An LSTM-based Test Selection Method for Self-Driving Cars"
            ],
            "img_path": "2501.03881/lstm-architecture-v2.jpeg"
        },
        "level2_qa": {
            "question": "In this paper, what single sentence best describes the primary methodological purpose behind evaluating the ITS4SDC model's 'FAIL' classification (sigmoid output < 0.5) on Dataset-1 as part of Setup 1, where SDC-Scissor is also concurrently trained and validated on Dataset-1?",
            "options": [
                "A. This specific evaluation scenario is designed to demonstrate the LSTM model's superior accuracy and precision metrics on its native development dataset (Dataset-1) when compared to SDC-Scissor under identical training conditions.",
                "B. The primary purpose is to confirm that the segment-based feature extraction, combined with the LSTM and dense layers, consistently classifies challenging 'unsafe' road segments as 'FAIL' before comparing recall and F1 scores with SDC-Scissor.",
                "C. The fundamental methodological aim of this specific setup is to ensure a robust and equitable performance comparison by compelling SDC-Scissor to operate on Dataset-1, thereby mitigating biases that would arise if each model were only tested on its original development dataset.",
                "D. This evaluation on Dataset-1 within Setup 1 serves to benchmark the LSTM model's performance in a simulation environment, primarily to validate its novel deep learning approach for road classification before broader application.",
                "E. The evaluation of ITS4SDC's 'FAIL' output specifically on Dataset-1 in Setup 1 is principally aimed at optimizing the 0.5 threshold for the sigmoid layer to maximize the F1 score, crucial for balancing precision and recall in test selection."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "In order to make the comparison between the two models fair, both models are trained and validated on each dataset during the evaluation (Setup 1 and Setup 2)."
            ],
            "img_path": "2501.03881/lstm-architecture-v2.jpeg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03626",
        "img_path": "2501.03626/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. VulnTrace: Analyzing Security Flaws in Distributed Code Repositories",
                "B. CommitShield: Tracking Vulnerability Introduction and Fix in Version Control Systems",
                "C. PatchWatch: Monitoring Bug Fixes and Their Impact on Software Reliability",
                "D. SecureGit: Enhancing Code Integrity through Automated Vulnerability Detection",
                "E. BugMap: Visualizing Defect Propagation in Collaborative Development Environments"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "CommitShield: Tracking Vulnerability Introduction and Fix in Version Control Systems"
            ],
            "img_path": "2501.03626/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, during historical commit tracing for Vulnerability Introduction Detection (VID), which condition regarding the length (x lines) of a patch representing a modification not internal to a function leads CommitShield to deem further context extension unnecessary?",
            "options": [
                "A. x is less than 10.",
                "B. x is greater than 10 but less than 30.",
                "C. x is greater than 30.",
                "D. The modification is confirmed to be internal to the function by LLM analysis.",
                "E. The patch context is already expanded to the full function where the patch is located."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "when x is greater than 30, we consider that there is sufficient context information, rendering further extension unnecessary."
            ],
            "img_path": "2501.03626/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03727",
        "img_path": "2501.03727/x6.png",
        "level1_qa": {
            "question": "From which research paper was this image taken?",
            "options": [
                "A. Mapping Cognitive Decline Using Linguistic Patterns in Narrative Speech under Auditory Stimuli",
                "B. Detecting Neurocognitive Disorders through Analyses of Topic Evolution and Cross-modal Consistency in Visual-Stimulated Narratives",
                "C. Evaluating Emotional Processing Deficits through Multimodal Analysis of Storytelling in Neurodegenerative Patients",
                "D. Automated Assessment of Working Memory Load via Temporal Dynamics in Visual Narrative Tasks",
                "E. Cross-Modal Integration and its Role in Language Comprehension among Individuals with Mild Cognitive Impairment"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Detecting Neurocognitive Disorders through Analyses of Topic Evolution and Cross-modal Consistency in Visual-Stimulated Narratives"
            ],
            "img_path": "2501.03727/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the ADReSS Corpus (summing its training and testing subsets) and the CU-MARVEL-RABBIT Corpus (version “2024-06-13”), what is the combined total count of participants identified as Healthy Controls (HCs)?",
            "options": [
                "A. 78",
                "B. 467",
                "C. 369",
                "D. 914",
                "E. 545"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "545"
            ],
            "img_path": "2501.03727/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03941",
        "img_path": "2501.03941/MIA2.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Yu Wei",
                "B. Lipika Ramaswamy",
                "C. Andre Manoel",
                "D. Alexa Haushalter",
                "E. Amy Steier"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Amy Steier"
            ],
            "img_path": "2501.03941/MIA2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the evaluation framework for Membership Inference Attack simulations, what is the minimum numerical value that *both* precision and accuracy metrics must simultaneously achieve or surpass for the simulation's outcome to be categorized under the explicitly defined grade that signifies the most successful privacy breach, according to the provided grading criteria?",
            "options": [
                "A. 0.05",
                "B. 0.5",
                "C. 0.8",
                "D. 0.65",
                "E. 1.0"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "0.8"
            ],
            "img_path": "2501.03941/MIA2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03997",
        "img_path": "2501.03997/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper from this image source?",
            "options": [
                "A. Numerical Analysis of Carrier Transport in Pulsed Semiconductor Devices Using a Hydrodynamic Framework",
                "B. Modeling Charge Dynamics in Semiconductor Switches Under High-Intensity Optical Excitation",
                "C. Two-fluid mobility model from coupled hydrodynamic equations for simulating laser-driven semiconductor switches",
                "D. Coupled Electron-Hole Transport Equations for Simulation of Optically Activated Semiconductor Components",
                "E. Hydrodynamic Simulation Techniques for Transient Response in Semiconductor Switching Applications"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Two-fluid mobility model from coupled hydrodynamic equations for simulating laser-driven semiconductor switches"
            ],
            "img_path": "2501.03997/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, the derivation of a minimal ambipolar Auger coefficient for high-purity silicon ($1.8\\times10^{-41}\\,{\\rm cm^6/ns}$) significantly lower than the widely used value ($3.8\\times10^{-40}\\,{\\rm cm^6/ns}$) is most directly attributed to the novel capability of the presented methodology to:",
            "options": [
                "A. Primarily account for carrier-phonon scattering using constant mobility values derived from undoped Si, an aspect often overlooked in earlier models that relied on data from highly doped silicon.",
                "B. Incorporate momentum conservation in electron-hole scattering and investigate carrier dynamics at high injection levels (up to $10^{20}\\,\\rm cm^{-3}$), allowing for a more accurate simultaneous characterization of intrinsic momentum relaxation and recombination processes.",
                "C. Correctly apply Matthiessen's rule to electron-hole scattering for the first time within the context of Laser-Driven Semiconductor Switch simulations, thereby rectifying foundational errors in Klaassen's model which misapplied it only to ionized-impurity scattering.",
                "D. Focus exclusively on direct minority-carrier lifetime measurements in exceptionally pure n-type silicon, similar to other recent reassessments, but uniquely extending these direct measurements to carrier densities up to $10^{20}\\,\\rm cm^{-3}$.",
                "E. Re-evaluate the contribution of carrier-screening effects by adapting the Conwell-Weisskof approach specifically for high-density plasmas, leading to a revised understanding of e-h scattering that was previously only considered applicable to the classical mutual diffusion of two distinct gases."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Incorporate momentum conservation in electron-hole scattering and investigate carrier dynamics at high injection levels (up to $10^{20}\\,\\rm cm^{-3}$), allowing for a more accurate simultaneous characterization of intrinsic momentum relaxation and recombination processes."
            ],
            "img_path": "2501.03997/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04004",
        "img_path": "2501.04004/x2.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. DeepSensorFusion: Integrating Camera and LiDAR Data for Urban Traffic Analysis",
                "B. AutoSceneNet: End-to-End Learning of 3D Object Detection in Autonomous Driving",
                "C. LiDARNet: Robust Point Cloud Classification for Dynamic Road Environments",
                "D. LiMoE: Mixture of LiDAR Representation Learners from Automotive Scenes",
                "E. Adaptive Feature Learning for Multi-Modal Sensor Data in Automotive Perception"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "LiMoE: Mixture of LiDAR Representation Learners from Automotive Scenes"
            ],
            "img_path": "2501.04004/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, how many large-scale LiDAR datasets were used to experimentally demonstrate the effectiveness and superiority of the proposed LiMoE framework?",
            "options": [
                "A. Five",
                "B. Seven",
                "C. Nine",
                "D. Eleven",
                "E. Thirteen"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "eleven"
            ],
            "img_path": "2501.04004/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04229",
        "img_path": "2501.04229/flow-chart.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Adaptive Multilevel Preconditioning Techniques for Sparse Linear Systems in High-Performance Computing",
                "B. An Efficient Block-Iterative Solver Using Dynamic Parameter Tuning for Large-Scale Sparse Matrices",
                "C. Three-precision iterative refinement with parameter regularization and prediction for solving large sparse linear systems",
                "D. Hybrid Sparse Matrix Factorization Methods with Error Control for Enhanced Numerical Stability",
                "E. Optimization of Convergence Rates in Krylov Subspace Methods via Regularized Parameter Estimation"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Three-precision iterative refinement with parameter regularization and prediction for solving large sparse linear systems"
            ],
            "img_path": "2501.04229/flow-chart.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement accurately synthesizes the precision management strategy specifically for the Gaussian Process Regression (GPR) based prediction of the parameter $\\alpha$, including its training phase?",
            "options": [
                "A. The GPR prediction for $\\alpha$ exclusively employs FP16 precision, mirroring the main GADI-IR computations to ensure consistency and accelerate parameter determination.",
                "B. Generation of the GPR training set for $\\alpha$ utilizes high-precision (e.g., FP64) arithmetic to ensure maximum accuracy of $\\alpha_k$ values, while the subsequent GPR prediction step uses FP32 for speed.",
                "C. The entire GPR process for $\\alpha$, including small system analysis, $\\alpha_k$ determination via dichotomy, and the final GPR prediction, is conducted in FP32 precision primarily to reduce the time taken for parameter prediction without sacrificing overall GADI-IR performance.",
                "D. While GPR prediction for $\\alpha$ is done in FP32, the critical step of analyzing the linear system structure to create training examples is performed in FP16 to maximize time savings in the GPR pipeline.",
                "E. The GPR methodology for $\\alpha$ prediction uses mixed precision internally, with FP32 for training set generation to improve its accuracy and FP16 for the GPR prediction step itself to accelerate computation, thereby enhancing GADI-IR's numerical stability."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The entire GPR process for α, including small system analysis, αk determination via dichotomy, and the final GPR prediction, is conducted in FP32 precision primarily to reduce the time taken for parameter prediction without sacrificing overall GADI-IR performance."
            ],
            "img_path": "2501.04229/flow-chart.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04234",
        "img_path": "2501.04234/bootstrap_viz.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Evaluating Model Robustness through Performance Variability Analysis in Deep Learning",
                "B. Confidence Interval Estimation for Individual Metrics in Neural Network Evaluation",
                "C. Statistical Uncertainty Quantification for Aggregate Performance Metrics in Machine Learning Benchmarks",
                "D. Bayesian Methods for Error Propagation in Machine Learning Performance Assessments",
                "E. Multi-Objective Optimization Approaches for Benchmarking Algorithm Efficiency"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Statistical Uncertainty Quantification for Aggregate Performance Metrics in Machine Learning Benchmarks"
            ],
            "img_path": "2501.04234/bootstrap_viz.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the referenced statistical literature, what is the publication year of the work that is cited as having introduced bootstrapped confidence intervals and Bayesian hierarchical modeling for league tables, which the authors claim to approach similarly when comparing models on leaderboards based on benchmarks?",
            "options": [
                "A. 1994",
                "B. 2022",
                "C. 2023",
                "D. 1996",
                "E. 2021"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "1996"
            ],
            "img_path": "2501.04234/bootstrap_viz.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04416",
        "img_path": "2501.04416/x1.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Unsupervised Voice Transformation Using Hierarchical Variational Autoencoders and GANs",
                "B. Cross-lingual Speech Synthesis through Latent Space Alignment and Contrastive Learning",
                "C. Neural Speaker Adaptation with Multi-scale Feature Disentanglement and Reinforcement Learning",
                "D. Latent Diffusion Networks for High-fidelity Voice Style Transfer in Low-resource Settings",
                "E. ZSVC: Zero-shot Style Voice Conversion with Disentangled Latent Diffusion Models and Adversarial Training"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "ZSVC: Zero-shot Style Voice Conversion with Disentangled Latent Diffusion Models and Adversarial Training"
            ],
            "img_path": "2501.04416/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most comprehensively details the specific methodological approach ZSVC implements to achieve its primary goal of style transformation while preserving speaker identity, by directly addressing the critical challenge of separating speaking style from speaker timbre, a separation not typically achieved by contemporary in-context learning speech models?",
            "options": [
                "A. Style voice conversion aims to transform the speaking style of source speech into a desired style while keeping the original speaker’s identity.",
                "B. Recent advancements in speech language models avoid this limitation by adopting the promising in-context learning strategy, predicting the target voice based on speech prompts.",
                "C. To disentangle speaking style and speaker timbre, we introduce information bottleneck to filter speaking style in the source speech and employ Uncertainty Modeling Adaptive Instance Normalization (UMAdaIN) to perturb the speaker timbre in the style prompt.",
                "D. Experiments conducted on 44,000 hours of speech data demonstrate the superior performance of ZSVC in generating speech with diverse speaking styles in zero-shot scenarios.",
                "E. Moreover, we propose a novel adversarial training strategy to enhance in-context learning and improve style similarity."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "To disentangle speaking style and speaker timbre, we introduce information bottleneck to filter speaking style in the source speech and employ Uncertainty Modeling Adaptive Instance Normalization (UMAdaIN) to perturb the speaker timbre in the style prompt."
            ],
            "img_path": "2501.04416/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04040",
        "img_path": "2501.04040/t5.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. An Analysis of Neural Network Architectures for Natural Language Understanding",
                "B. Exploring the Impact of Pretraining Data on Language Model Performance",
                "C. A Comparative Study of Text Generation Techniques in Artificial Intelligence",
                "D. Evaluating Optimization Methods for Training Deep Language Models",
                "E. A Survey on Large Language Models with some Insights on their Capabilities and Limitations"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "A Survey on Large Language Models with some Insights on their Capabilities and Limitations"
            ],
            "img_path": "2501.04040/t5.png"
        },
        "level2_qa": {
            "question": "In this paper, considering its broad survey of LLM advancements including architectural details of models like BERT and T5, their general capabilities, and applications, provide the single sentence that precisely delineates the authors' explicit, focused contribution towards understanding the genesis of specific, sophisticated thought-like processes within certain LLMs.",
            "options": [
                "A. Central to this work are the questions of how LLMs generalize across diverse tasks, exhibit planning, and reasoning abilities, and whether these emergent abilities can be systematically elicited or enhanced.",
                "B. This survey paper explores the foundational components, scaling mechanisms, and architectural strategies that drive these capabilities.",
                "C. By analyzing these factors, this paper aims to foster the ongoing discussion on the capabilities and limits of LLMs, promoting their responsible development and application in novel and increasingly complex environments.",
                "D. Emphasizing models like GPT and LLaMA, we analyze the impact of exponential data and computational growth on LLM performance, while also addressing the trade-offs associated with scaling.",
                "E. In particular, we provide some insights into the CoT (Chain of Thought) and PoT (Plan of Thought) abilities within LLMs, focusing on how pre-training data influences their emergence."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "In particular, we provide some insights into the CoT (Chain of Thought) and PoT (Plan of Thought) abilities within LLMs, focusing on how pre-training data influences their emergence."
            ],
            "img_path": "2501.04040/t5.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04695",
        "img_path": "2501.04695/Reranking_framework.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Bairu Hou",
                "B. Mohammad A. Amir Khojastepour",
                "C. Srimat T. Chakradhar",
                "D. Matin Mortaheb",
                "E. Sennur Ulukus"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Matin Mortaheb"
            ],
            "img_path": "2501.04695/Reranking_framework.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the evaluation performed to demonstrate the enhancement of the retrieval process, what is the exact name of the dataset used to measure the improvement in selecting relevant context and response accuracy?",
            "options": [
                "A. ImageNet dataset",
                "B. COCO dataset",
                "C. CLIP-400M dataset",
                "D. MS MARCO dataset",
                "E. Visual Genome dataset"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "COCO dataset"
            ],
            "img_path": "2501.04695/Reranking_framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04557",
        "img_path": "2501.04557/x1.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. Performance Analysis of Terrestrial Network Handoffs Using Stochastic Models",
                "B. Optimizing Ground Station Connectivity for Hybrid Satellite Networks",
                "C. A Probabilistic Approach to Frequency Allocation in Multi-Layer Satellite Systems",
                "D. Satellite-Terrestrial Routing or Inter-Satellite Routing? A Stochastic Geometry Perspective",
                "E. Modeling Interference in Satellite and Terrestrial Integrated Communication Networks"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Satellite-Terrestrial Routing or Inter-Satellite Routing? A Stochastic Geometry Perspective"
            ],
            "img_path": "2501.04557/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single-word term refers to the specific theoretical constructs developed that directly facilitate the quantitative verification of the primary design goal stated for the novel routing relay selection algorithms?",
            "options": [
                "A. Probabilities",
                "B. Algorithms",
                "C. Expressions",
                "D. Models",
                "E. Insights"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Expressions"
            ],
            "img_path": "2501.04557/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04742",
        "img_path": "2501.04742/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Deep Neural Networks for Polyphonic Instrument Recognition in Western Classical Music",
                "B. Meta-learning-based percussion transcription and $t\\bar{a}la$ identification from low-resource audio",
                "C. Unsupervised Learning Techniques for Melody Extraction from Monophonic Audio Signals",
                "D. Cross-modal Analysis of Rhythmic Patterns in Electronic Dance Music Using CNNs",
                "E. Probabilistic Models for Automatic Tempo Estimation and Beat Tracking in Jazz Recordings"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Meta-learning-based percussion transcription and $t\\bar{a}la$ identification from low-resource audio"
            ],
            "img_path": "2501.04742/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, focusing on the $t\bar{a}la$s detailed as the primary subjects of the study, what is the total combined number of $vibh\bar{a}gs$ for those $t\bar{a}la$s explicitly stated to possess unequal $vibh\bar{a}gs$?",
            "options": [
                "A. 2",
                "B. 10",
                "C. 7",
                "D. 17",
                "E. 13"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "7"
            ],
            "img_path": "2501.04742/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04364",
        "img_path": "2501.04364/x1.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. A comparative study of data preprocessing techniques in web usage mining",
                "B. Optimizing feature extraction for improved pattern recognition in web analytics",
                "C. Assessing user behavior modeling through advanced session identification methods",
                "D. Integrating real-time analytics frameworks to enhance web usage data interpretation",
                "E. An innovative data collection method to eliminate the preprocessing phase in web usage mining"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "An innovative data collection method to eliminate the preprocessing phase in web usage mining"
            ],
            "img_path": "2501.04364/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value results from summing the distinct number of architectural tiers explicitly defined for the proposed API model with the precise count of fundamental information security principles that the API is stated to uphold?",
            "options": [
                "A. 3",
                "B. 4",
                "C. 5",
                "D. 6",
                "E. 7"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "6"
            ],
            "img_path": "2501.04364/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03933",
        "img_path": "2501.03933/efr_pipeline.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Data-driven Optimization for the Evolve-Filter-Relax regularization of convection-dominated flows",
                "B. Machine Learning Approaches to Turbulence Modeling in Fluid Dynamics",
                "C. Adaptive Mesh Refinement Techniques for High Reynolds Number Flows",
                "D. Numerical Analysis of Stabilization Methods in Convection-Diffusion Equations",
                "E. Deep Neural Network Integration for Multiphysics Simulation Enhancement"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Data-driven Optimization for the Evolve-Filter-Relax regularization of convection-dominated flows"
            ],
            "img_path": "2501.03933/efr_pipeline.png"
        },
        "level2_qa": {
            "question": "In this paper, what single numerical value, presented as research data, quantifies the maximum percentage by which the accuracy of simulating convection-dominated flows is enhanced when transitioning from standard EFR algorithms with fixed parameters to Opt-EFR strategies—characterized by time-dependent, adaptively optimized parameters derived from fully-resolved reference data—specifically within the context of an under-resolved turbulent flow past a cylinder at Re=1000, provided that the optimization's objective function critically incorporates both a global metric and spatial gradient information?",
            "options": [
                "A. 3",
                "B. 2",
                "C. 100",
                "D. 99",
                "E. 1000"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "99"
            ],
            "img_path": "2501.03933/efr_pipeline.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.03746",
        "img_path": "2501.03746/x6.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. An Optimized Deep Learning Framework for Vibration Analysis in Induction Motors",
                "B. Feature Extraction Techniques for Predictive Maintenance of Electrical Machines",
                "C. Enhanced Signal Processing Methods for Fault Detection in Rotating Machinery",
                "D. A Multimodal Lightweight Approach to Fault Diagnosis of Induction Motors in High-Dimensional Dataset",
                "E. Adaptive Neural Networks for Real-Time Monitoring of Industrial Motor Efficiency"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "A Multimodal Lightweight Approach to Fault Diagnosis of Induction Motors in High-Dimensional Dataset"
            ],
            "img_path": "2501.03746/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total count of distinct conventional machine learning algorithms and diverse pre-trained Convolutional Neural Network architectures (excluding the main model, ShuffleNetV2) that were explicitly stated as being implemented for the purpose of image classification using spectral image datasets derived from both current and vibration signals?",
            "options": [
                "A. 5",
                "B. 3",
                "C. 8",
                "D. 9",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "8"
            ],
            "img_path": "2501.03746/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02850",
        "img_path": "2501.02850/methodology.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Leon Fernando",
                "B. Ulindu De Silva",
                "C. Billy Lau Pik Lik",
                "D. Zann Koh",
                "E. Sam Conrad Joyce"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Ulindu De Silva"
            ],
            "img_path": "2501.02850/methodology.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific percentage, derived from qualitative evaluations of the innovative GenAI pipeline, represents its measured accuracy in maintaining spatial consistency and quality when converting extensive video datasets, such as CCTV footage, into customized textual summaries?",
            "options": [
                "A. 80",
                "B. 20",
                "C. 10",
                "D. 3",
                "E. 70"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "70"
            ],
            "img_path": "2501.02850/methodology.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02811",
        "img_path": "2501.02811/x2.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. First-place Solution for Streetscape Shop Sign Recognition Competition",
                "B. A Novel Approach to Urban Shopfront Detection Using Deep Learning",
                "C. Evaluating Automated Text Extraction Techniques for Retail Signage",
                "D. Benchmarking Computer Vision Models for Outdoor Advertisement Analysis",
                "E. Multi-modal Recognition of Commercial Storefronts in Urban Environments"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "First-place Solution for Streetscape Shop Sign Recognition Competition"
            ],
            "img_path": "2501.02811/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which outlines a multi-stage text recognition framework encompassing signboard detection (enhanced with DCN, keypoint regression, and advanced augmentation) and a text recognition phase (improving the SAR baseline with VIT, BiLSTM, multiple self-supervised training including Sequential Contrast Learning and MAE-based masking, plus Center Loss), what is the exact number of images in the specialized 'Signboard OCR data' dataset, characterized by close-up signboard views with multi-line text annotations for position and content, that is used for training these text recognition models?",
            "options": [
                "A. 4",
                "B. 100",
                "C. 73",
                "D. 3",
                "E. 14,331"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "14,331"
            ],
            "img_path": "2501.02811/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.02630",
        "img_path": "2501.02630/x7.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Robust Grasping Techniques for Textile Material Handling in Robotics",
                "B. Soft and Compliant Contact-Rich Hair Manipulation and Care",
                "C. Adaptive Control Strategies for Rigid Object Manipulation in Cluttered Environments",
                "D. Automated Systems for Synthetic Fiber Conditioning and Maintenance",
                "E. Precision Tools for Delicate Surface Interaction and Adjustment"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Soft and Compliant Contact-Rich Hair Manipulation and Care"
            ],
            "img_path": "2501.02630/x7.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific maximum percentage by which the proposed force estimation method, leveraging both visual deformation data and tendon tensions, improves sensing accuracy (reduces sensing errors) over a baseline method that *solely* utilizes actuator current load for force inference?",
            "options": [
                "A. 20.3",
                "B. 39.8",
                "C. 12.0",
                "D. 60.1",
                "E. 40.2"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "60.1"
            ],
            "img_path": "2501.02630/x7.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05134",
        "img_path": "2501.05134/x1.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Entropy Methods and Stability Analysis in Compressible Fluid Flows",
                "B. Global Existence and Uniqueness of Solutions for Navier-Stokes Equations",
                "C. Maximal dissipation and well-posedness of the Euler system of gas dynamics",
                "D. Nonlinear Wave Propagation in Magnetohydrodynamic Gas Systems",
                "E. Numerical Approaches to Shock Formation in Inviscid Compressible Fluids"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Maximal dissipation and well-posedness of the Euler system of gas dynamics"
            ],
            "img_path": "2501.05134/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, a single sentence, describe the context we give you.",
            "options": [
                "A. The paper primarily demonstrates that Dafermos' original criterion of maximal dissipation is sufficient to guarantee both the existence and uniqueness of maximal dissipative solutions for any finite energy initial data.",
                "B. The research culminates in a single, unified framework where the proposed two-step selection procedure is shown to be equivalent to applying the refined Dafermos' criterion, leading to identical unique solutions for any initial data.",
                "C. The paper introduces both a refined Dafermos' criterion ensuring a unique solution for any finite energy initial data, and a distinct selection procedure for achieving unique semigroup solutions from the broader class of dissipative solutions, thereby addressing solution uniqueness through multiple, specific mechanisms.",
                "D. The paper's central finding is that only admissible dissipative solutions, selected via a two-step process, can be considered true weak solutions, while maximal dissipative solutions consistently fail Dafermos' criterion of maximal dissipation.",
                "E. The paper concludes that the concept of an absolute energy minimizer, whose existence is definitively proven for all general initial data within the study, provides the most comprehensive basis for understanding all categories of dissipative solutions discussed."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Finally, we introduce a refined version of Dafermos' criterion yielding a unique solution of the problem for any finite energy initial data. In addition, we propose a simple, at most two step, selection procedure to identify a unique semigroup solution in the class of dissipative solutions to the Euler system."
            ],
            "img_path": "2501.05134/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04939",
        "img_path": "2501.04939/x1.png",
        "level1_qa": {
            "question": "What is the official title of the paper shown in the figure?",
            "options": [
                "A. Cross-Domain Spatial Attention Networks for Video Object Tracking",
                "B. Multi-Context Temporal Consistent Modeling for Referring Video Object Segmentation",
                "C. Unsupervised Scene Understanding via Temporal Feature Aggregation",
                "D. Hierarchical Contextual Learning for Video Caption Generation",
                "E. Adaptive Multi-Modal Fusion Techniques in Visual Object Detection"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Multi-Context Temporal Consistent Modeling for Referring Video Object Segmentation"
            ],
            "img_path": "2501.04939/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific J&F numerical result on the MeViS dataset is presented as a key demonstration of the proposed module's efficacy in enhancing performance by addressing both query-induced mask instability and context-deficient text-to-instance mapping in existing video object segmentation architectures?",
            "options": [
                "A. 11.9",
                "B. 4",
                "C. 46.7",
                "D. 47.6",
                "E. 50.0"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "47.6"
            ],
            "img_path": "2501.04939/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04975",
        "img_path": "2501.04975/x2.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. V2C-CBM: Building Concept Bottlenecks with Vision-to-Concept Tokenizer",
                "B. V2C-Transformer: Enhancing Vision-to-Concept Mapping with Tokenized Representations",
                "C. Conceptual Bottlenecks in Vision Models: A Tokenizer-Based Approach",
                "D. Tokenized Feature Encoding for Robust Vision-to-Concept Integration",
                "E. Building Interpretable Vision Models Using Conceptual Token Embeddings"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "V2C-CBM: Building Concept Bottlenecks with Vision-to-Concept Tokenizer"
            ],
            "img_path": "2501.04975/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, the V2C-CBM methodology is presented as distinct from both LLM-supervised CBMs (which rely on language models for concept generation) and certain dictionary-based concept discovery approaches like DN-CBM (which necessitate additional training for components like sparse autoencoders); the paper attributes V2C-CBM's ability to construct its vision-oriented concept bottleneck directly using VLMs without these specific dependencies primarily to its strategic utilization of:",
            "options": [
                "A. Class-specific concept descriptions directly generated and refined by Large Language Models.",
                "B. A specialized sparse autoencoder, pre-trained on a vast, domain-specific labeled image corpus to discover foundational concepts.",
                "C. Extensive, manually curated concept annotations provided by domain experts for every visual class and image instance.",
                "D. A substantial corpus of auxiliary unlabeled images, employed in conjunction with VLM capabilities for tokenizer construction.",
                "E. Advanced submodular optimization techniques applied post-hoc to filter verbose and non-visual concepts from an LLM-generated pool."
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "A substantial corpus of auxiliary unlabeled images, employed in conjunction with VLM capabilities for tokenizer construction."
            ],
            "img_path": "2501.04975/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05017",
        "img_path": "2501.05017/x2.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Continuous Knowledge-Preserving Decomposition for Few-Shot Continual Learning",
                "B. Adaptive Feature Extraction Techniques for Incremental Few-Shot Learning",
                "C. Hierarchical Representation Learning in Multi-Task Continual Systems",
                "D. Robust Model Updating Strategies for Streamlined Knowledge Integration",
                "E. Dynamic Network Architectures for Lifelong Few-Shot Classification"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Continuous Knowledge-Preserving Decomposition for Few-Shot Continual Learning"
            ],
            "img_path": "2501.05017/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the CKPD-FSCIL framework's approach to adapter-based adaptation, what is the exact number of trainable parameter groups that are updated in each incremental session (excluding the base session) under the adaptive layer selection strategy, assuming that K layers are selected per session, and the decomposition rank r is fixed, with each selected layer receiving a single low-rank adapter?",
            "options": [
                "A. K × r",
                "B. 2K × r",
                "C. K",
                "D. K × (R − r)",
                "E. N × r"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "K × r"
            ],
            "img_path": "2501.05017/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04966",
        "img_path": "2501.04966/mdoel_part1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Optimization of Artistic Styles through Generative Adversarial Networks",
                "B. Adaptive Learning in Neural Networks for Visual Pattern Synthesis",
                "C. Evolutionary Approaches to Image Classification in Computer Vision",
                "D. Recognition-Enhanced Models for Abstract Art Generation",
                "E. Emergence of Painting Ability via Recognition-Driven Evolution"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Emergence of Painting Ability via Recognition-Driven Evolution"
            ],
            "img_path": "2501.04966/mdoel_part1.png"
        },
        "level2_qa": {
            "question": "In this paper, what single word identifies the principal quantifiable metric the model employs to assess the success of 'informational conveyance'—a core component of its defined 'visual communication efficiency'—which is then optimized subject to resource minimization?",
            "options": [
                "A. Complexity",
                "B. Aesthetics",
                "C. Accuracy",
                "D. Parsimony",
                "E. Saliency"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "accuracy"
            ],
            "img_path": "2501.04966/mdoel_part1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05220",
        "img_path": "2501.05220/x3.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education",
                "B. Deep Learning Techniques for Personalized Learning Path Optimization",
                "C. Evaluating the Impact of Adaptive Feedback Mechanisms in Online Education",
                "D. A Framework for Automated Assessment of Student Performance Using NLP",
                "E. Integrating Semantic Analysis for Enhanced Content Recommendation in E-Learning Platforms"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"
            ],
            "img_path": "2501.05220/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific quantity of unique reference questions, sourced from the MixKhanQ dataset, formed the basis for the human annotation task where annotators compared pairs of generated questions (one from a relevant topic, one from an alternative topic) to assess their alignment with these reference questions?",
            "options": [
                "A. 2",
                "B. 6",
                "C. 30",
                "D. 60",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "30"
            ],
            "img_path": "2501.05220/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05243",
        "img_path": "2501.05243/x1.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Joint Communications and Sensing for 6G Satellite Networks: Use Cases and Challenges",
                "B. Advanced Beamforming Techniques for 6G Terrestrial Networks: Applications and Limitations",
                "C. Resource Allocation Strategies in 6G Aerial Networks: Performance Analysis and Optimization",
                "D. Machine Learning Approaches to Interference Management in Next-Generation Satellite Systems",
                "E. Energy-Efficient Protocols for Integrated Sensing and Communication in 5G Urban Environments"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Joint Communications and Sensing for 6G Satellite Networks: Use Cases and Challenges"
            ],
            "img_path": "2501.05243/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, recognizing that advanced on-board processing is pivotal for realizing the transformative potential of JCAS in Satellite Networks, what single word, explicitly mentioned in the description of a specific type of communication payload repeater, denotes the signal representation crucial for enabling such sophisticated processing capabilities in orbit?",
            "options": [
                "A. Transparent",
                "B. Baseband",
                "C. Waveform",
                "D. Channel",
                "E. Doppler"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Baseband"
            ],
            "img_path": "2501.05243/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05241",
        "img_path": "2501.05241/x1.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Contrast-Free Myocardial Scar Segmentation in Cine MRI using Motion and Texture Fusion",
                "B. Deep Learning-Based Myocardial Tissue Characterization in Dynamic Cardiac MRI",
                "C. Automated Detection of Cardiac Fibrosis Using Multi-Sequence MRI and Texture Analysis",
                "D. Motion-Corrected Segmentation of Left Ventricular Borders in Cine MRI",
                "E. Integration of Temporal and Spatial Features for Enhanced Cardiac MRI Interpretation"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Contrast-Free Myocardial Scar Segmentation in Cine MRI using Motion and Texture Fusion"
            ],
            "img_path": "2501.05241/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which statement best synthesizes the specific advancements in cardiac motion analysis offered by the MTI-MyoScarSeg model when compared to prior contrast-free cine MRI techniques that also incorporate motion information?",
            "options": [
                "A. It offers explicit, full-cycle cardiac motion characterization relative to the end-diastolic phase, improving upon both the lack of interpretability in implicit motion techniques and the limited scope of adjacent-frame optical flow methods.",
                "B. It primarily enhances motion interpretability by synthesizing LGE-style images from cine MRI, unlike methods that directly estimate scars from temporal information.",
                "C. It introduces cardiac motion tracking through deep neural networks for full cardiac image cycle registration, a completely novel concept not previously explored in any contrast-free scar detection methods using cine MRI.",
                "D. It uniquely integrates ECG data with cine MRI motion analysis to provide superior and more interpretable motion extraction compared to all other non-contrast approaches that rely solely on image data.",
                "E. It replaces reliance on optical flow for motion detection with generative adversarial networks focused on motion, thus providing direct scar quantification from these advanced motion features alone without needing texture information."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Our approach involves extracting cardiac motion by calculating the displacement fields from each frame relative to the end-diastolic (ED) phase.",
                "Nonetheless, implicit motion extraction lacks interpretability, while most explicit approaches rely on optical flow applied to detect motion only between adjacent frames[13]."
            ],
            "img_path": "2501.05241/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05120",
        "img_path": "2501.05120/network.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Optimizing Deep Learning Architectures for Lung Cancer Segmentation in CT Scans",
                "B. Enhancing CNN Models for Brain Tumor Detection in MRI Imaging",
                "C. Evaluating Transfer Learning Approaches for Pancreatic Cancer Localization Using PET Scans",
                "D. Advanced Feature Extraction Techniques for Automated Skin Lesion Classification",
                "E. Improving the U-Net Configuration for Automated Delineation of Head and Neck Cancer on MRI"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Improving the U-Net Configuration for Automated Delineation of Head and Neck Cancer on MRI"
            ],
            "img_path": "2501.05120/network.png"
        },
        "level2_qa": {
            "question": "In this paper, what was the reported average Dice Similarity Coefficient (DSCagg) for the GTVn class in Task 1, specifically achieved by the ensemble of five models on the private test set of 50 patients?",
            "options": [
                "A. 0.752",
                "B. 0.709",
                "C. 0.794",
                "D. 0.718",
                "E. 0.845"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "0.794"
            ],
            "img_path": "2501.05120/network.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05079",
        "img_path": "2501.05079/x2.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Neural Network Architectures for GNSS Signal Enhancement Using Multimodal Data Fusion",
                "B. Feature Embedding Techniques for Robust Text Generation in Sensor Data Analysis",
                "C. Multimodal-to-Text Prompt Engineering in Large Language Models Using Feature Embeddings for GNSS Interference Characterization",
                "D. Cross-Modal Learning Approaches to Interference Detection in Satellite Navigation Systems",
                "E. Evaluating Prompt Design Strategies for Large Language Models in Environmental Signal Processing"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Multimodal-to-Text Prompt Engineering in Large Language Models Using Feature Embeddings for GNSS Interference Characterization"
            ],
            "img_path": "2501.05079/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the precise numerical value representing the total count of individual GNSS snapshots that constitute the primary dataset utilized for feature extraction via the CLIP visual encoder and for the subsequent interference interpretation tasks performed by the LLaVA model, as detailed in the methodology?",
            "options": [
                "A. 500",
                "B. 1024",
                "C. 14",
                "D. 42,592",
                "E. 341"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "the dataset comprises a total of 42,592 GNSS snapshots."
            ],
            "img_path": "2501.05079/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05006",
        "img_path": "2501.05006/x2.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Integrating Graph and Relational Models for Unified Data Management",
                "B. Optimizing Query Performance in NoSQL Databases with Structured Indexing",
                "C. A Framework for Distributed Processing of Semi-Structured and Unstructured Data",
                "D. Hybrid Data Analytics: Combining SQL and Machine Learning for Big Data Systems",
                "E. CHASE: A Native Relational Database for Hybrid Queries on Structured and Unstructured Data"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "CHASE: A Native Relational Database for Hybrid Queries on Structured and Unstructured Data"
            ],
            "img_path": "2501.05006/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, when discussing the performance overheads of the traditional iterator model, how many distinct, consequential issues stemming directly from the implementation and invocation characteristics of `theNext` function are enumerated?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2501.05006/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05032",
        "img_path": "2501.05032/x1.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Optimizing Neural Network Architectures for Text Summarization",
                "B. Evaluating Sentiment Analysis Techniques in Social Media Data",
                "C. Developing Context-Aware Dialogue Systems for Customer Support",
                "D. Improving Machine Translation Accuracy with Multilingual Corpora",
                "E. Enhancing Human-Like Responses in Large Language Models"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Enhancing Human-Like Responses in Large Language Models"
            ],
            "img_path": "2501.05032/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct model fine-tuning techniques are explicitly discussed in the context of improving the human-likeness of LLM responses, considering both optimization approaches and architectural methods, and requiring careful distinction between training data strategies and parameter update mechanisms?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.05032/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04606",
        "img_path": "2501.04606/x2.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Enhancing Low-Cost Video Editing with Lightweight Adaptors and Temporal-Aware Inversion",
                "B. Optimizing High-Resolution Video Synthesis Using Deep Neural Networks and Spatial Attention",
                "C. Real-Time Video Compression Techniques Incorporating Multi-Scale Feature Extraction",
                "D. Adaptive Frame Interpolation for Smooth Video Playback in Resource-Constrained Devices",
                "E. Temporal Consistency in Video Style Transfer Through Recurrent Neural Architectures"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Enhancing Low-Cost Video Editing with Lightweight Adaptors and Temporal-Aware Inversion"
            ],
            "img_path": "2501.04606/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, according to the description of the 'lightweight adapter', what is its specified 'total size' in millions of parameters?",
            "options": [
                "A. 16.155",
                "B. 0.755",
                "C. 15.4",
                "D. 860",
                "E. 843.845"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "860"
            ],
            "img_path": "2501.04606/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04926",
        "img_path": "2501.04926/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. WaveBoost: Enhancing Audio Quality through Multi-Stage Neural Upsampling Techniques",
                "B. SoundStep: A Novel Framework for Progressive Audio Resolution Enhancement Using Deep Learning",
                "C. HighResFlow: Integrating Flow-Based Models for Improved Audio Signal Reconstruction",
                "D. FLowHigh: Towards Efficient and High-Quality Audio Super-Resolution with Single-Step Flow Matching",
                "E. AudioForge: Single-Pass Deep Generative Models for Real-Time Audio Refinement"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "FLowHigh: Towards Efficient and High-Quality Audio Super-Resolution with Single-Step Flow Matching"
            ],
            "img_path": "2501.04926/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence describes the specific technical strategy employed by Generative Adversarial Networks (GANs) as a class for audio super-resolution, setting this description apart from both the general assertion that generative models address the inherent one-to-many mapping problem and the specific architectural details of advanced individual GAN-based models?",
            "options": [
                "A. The proposed method generates high-fidelity, high-resolution audio through a single-step sampling process across various input sampling rates.",
                "B. Recent works[8,9,10]have employed generative models to address the one-to-many problem.",
                "C. Several studies have leveraged generative adversarial networks (GANs), such as AERO[11], mdctGAN[12], and MS-BWE[13], which focus on spectrum estimation for inverse transformation.",
                "D. Fre-painter[14]has demonstrated state-of-the-art performance by integrating a masked autoencoder and GANs with effective masking strategies.",
                "E. While these studies have yielded promising results, GANs are prone to training instability and mode collapse, which can impede model convergence."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Several studies have leveraged generative adversarial networks (GANs), such as AERO[11], mdctGAN[12], and MS-BWE[13], which focus on spectrum estimation for inverse transformation."
            ],
            "img_path": "2501.04926/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04643",
        "img_path": "2501.04643/Overall_1.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Jiaqi Wang",
                "B. Zhiqiang Gao",
                "C. Hangchi Shen",
                "D. Zhihao Dou",
                "E. Xiangbo Zhang"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Zhiqiang Gao"
            ],
            "img_path": "2501.04643/Overall_1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the specific example of the Pyramid Fusion (PF) method's first routing operation, what is the numerical value representing the ratio of the explicitly stated total count of prediction tensors in the U^1,0 layer to the total number of groups these same tensors are organized into for further processing?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 0.5",
                "D. S",
                "E. 4"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.04643/Overall_1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04657",
        "img_path": "2501.04657/x1.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Broadband electron paramagnetic resonance spectroscopy of $^{167}$Er:$^{7}$LiYF$_4$ at mK temperatures",
                "B. High-frequency nuclear magnetic resonance studies of $^{167}$Er doped $^{7}$LiYF$_4$ crystals at cryogenic temperatures",
                "C. Temperature-dependent optical spectroscopy of rare-earth ions in lithium yttrium fluoride matrices",
                "D. Microwave absorption characteristics of $^{7}$LiYF$_4$ doped with erbium isotopes under varying magnetic fields",
                "E. Quantum coherence effects in $^{167}$Er:$^{7}$LiYF$_4$ studied via pulsed electron spin resonance at low temperatures"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Broadband electron paramagnetic resonance spectroscopy of $^{167}$Er:$^{7}$LiYF$_4$ at mK temperatures"
            ],
            "img_path": "2501.04657/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what characteristic of the DPPH signal, when found to be very small or too low, necessitates the use of erbium isotopes as an alternative for magnetic field calibration?",
            "options": [
                "A. Linewidth",
                "B. SNR",
                "C. g-factor",
                "D. Stability",
                "E. Purity"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "SNR"
            ],
            "img_path": "2501.04657/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04424",
        "img_path": "2501.04424/x2.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Yamin Zhou",
                "B. Andrea Stanco",
                "C. Paweł Batorski",
                "D. Jannik Brinkmann",
                "E. Paul Swoboda"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Paweł Batorski"
            ],
            "img_path": "2501.04424/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct operational components (base filters and transformation primitives combined) available within the extended version of the domain-specific language referred to as ARGAe, which is utilized to facilitate the combinatorial search aspect of the proposed neuro-symbolic approach?",
            "options": [
                "A. 16",
                "B. 27",
                "C. 31",
                "D. 19",
                "E. 29"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "31"
            ],
            "img_path": "2501.04424/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04421",
        "img_path": "2501.04421/pipeline.jpg",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Optimizing Energy Portfolio Allocation through Deep Reinforcement Learning",
                "B. Adaptive Strategies for Crude Oil Futures Using Probabilistic Forecasting Models",
                "C. Robust Control Methods in Renewable Energy Markets under Uncertainty",
                "D. Risk-averse policies for natural gas futures trading using distributional reinforcement learning",
                "E. Dynamic Hedging Techniques for Commodity Derivatives with Bayesian Optimization"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Risk-averse policies for natural gas futures trading using distributional reinforcement learning"
            ],
            "img_path": "2501.04421/pipeline.jpg"
        },
        "level2_qa": {
            "question": "In this paper, what is the sum of units in the first LSTM layer of the QR-DQN model and the first LSTM layer of the ψθ component within the IQN model architecture?",
            "options": [
                "A. 192",
                "B. 256",
                "C. 320",
                "D. 384",
                "E. 448"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "256"
            ],
            "img_path": "2501.04421/pipeline.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04762",
        "img_path": "2501.04762/Main-Framework.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Scalable Optimization Techniques for Large Language Models in Personalized Content Delivery",
                "B. Efficient and Responsible Adaptation of Large Language Models for Robust and Equitable Top-k Recommendations",
                "C. Fairness-Aware Training Methods for Enhanced User Engagement in Recommendation Systems",
                "D. Robust Feature Selection Approaches for Improving Top-k Predictions in Machine Learning Models",
                "E. Adaptive Frameworks for Balancing Efficiency and Accuracy in Natural Language Processing Tasks"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Efficient and Responsible Adaptation of Large Language Models for Robust and Equitable Top-k Recommendations"
            ],
            "img_path": "2501.04762/Main-Framework.png"
        },
        "level2_qa": {
            "question": "In this paper, based on the provided text detailing the criteria for an 'extremely weak user', specifically concerning the sparsity threshold `t_s`, how many distinct approaches for defining or assigning a value to `t_s` are explicitly stated?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 3",
                "E. 4"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.04762/Main-Framework.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04901",
        "img_path": "2501.04901/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Adaptive Scaling of Large Language Models for Real-Time Text Summarization",
                "B. Evaluating the Impact of Model Size on Multilingual Sentiment Analysis",
                "C. ThriftLLM: On Cost-Effective Selection of Large Language Models for Classification Queries",
                "D. Energy-Efficient Architectures for Large Language Model Training in Cloud Environments",
                "E. Optimizing Transformer-Based Models for Question Answering Tasks in Low-Resource Settings"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "ThriftLLM: On Cost-Effective Selection of Large Language Models for Classification Queries"
            ],
            "img_path": "2501.04901/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most comprehensively details the authors' pivotal strategic maneuver to address the Optimal Ensemble Selection (OES) problem's inherent intractability—stemming from its non-submodular prediction accuracy objective—by identifying the alternative mathematical construct utilized, its essential characteristics enabling theoretical tractability, the resultant algorithmic development, and the specific nature of the performance assurance achieved under a declared initial condition?",
            "options": [
                "A. Building on this, we formalize an optimization problem, dubbed Optimal Ensemble Selection (OES for short): given a set of LLMs, a specific budget, and a query, the objective is to identify a subset of LLMs whose total cost is within the budget while the aggregated prediction accuracy on the query is maximized.",
                "B. We conduct an in-depth theoretical analysis of the prediction accuracy function in the OES problem and establish that it is non-decreasing and non-submodular.",
                "C. We show how our algorithms and approximation guarantees can be extended to the case when the success probabilities are unknown and are estimated within confidence intervals.",
                "D. In this paper, we formalize the performance of an ensemble of models (LLMs) using the notion of prediction accuracy which we formally define.",
                "E. Nevertheless, we leverage a surrogate objective function that upper bounds the prediction accuracy, show that it is non-decreasing and submodular, and devise an algorithm for OES that achieves an instance-dependent approximation guarantee with high probability, when LLM success probabilities are known."
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Nevertheless, we leverage a surrogate objective function that upper bounds the prediction accuracy, show that it is non-decreasing and submodular, and devise an algorithm for OES that achieves an instance-dependent approximation guarantee with high probability, when LLM success probabilities are known."
            ],
            "img_path": "2501.04901/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04279",
        "img_path": "2501.04279/x1.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Meiling Wang",
                "B. Yinan Deng",
                "C. Yujie Tang",
                "D. Zibo Zheng",
                "E. Jingchuan Deng"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Yujie Tang"
            ],
            "img_path": "2501.04279/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what numerical value corresponds to the percentage of 'instance queries' out of the total 85 queries conducted to evaluate query success rate across 5 Gibson scenes, a category where the CRSG's feature of recording carrying relationships proved crucial for accurate object localization?",
            "options": [
                "A. 17.65",
                "B. 32.94",
                "C. 49.41",
                "D. 82.4",
                "E. 55.0"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "49.41"
            ],
            "img_path": "2501.04279/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04281",
        "img_path": "2501.04281/x1.png",
        "level1_qa": {
            "question": "Who is the primary author of the paper shown here?",
            "options": [
                "A. Monika Eisenmann",
                "B. Etienne Le Naour",
                "C. Mirmojtaba Gharibi",
                "D. Tommaso Giovannini",
                "E. John-Paul Clarke"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Mirmojtaba Gharibi"
            ],
            "img_path": "2501.04281/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, when the RF-leg planar CRP algorithm executes its gradient descent procedure to determine the flight path angles (θ^a), what is the precise number of distinct, explicitly stated conditions under which this specific gradient descent procedure will terminate?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. N_RF",
                "E. 0"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.04281/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04255",
        "img_path": "2501.04255/Overview.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Global stability analysis of turbulent wake behind a NACA0012 airfoil",
                "B. Nonlinear dynamic modeling of vortex shedding in separated airfoil flows",
                "C. Spectral analysis of laminar-turbulent transition over curved airfoil surfaces",
                "D. Biglobal resolvent analysis of separated flow over a NACA0012 airfoil",
                "E. Parametric study of aerodynamic forces in compressible flow around NACA0012"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Biglobal resolvent analysis of separated flow over a NACA0012 airfoil"
            ],
            "img_path": "2501.04255/Overview.png"
        },
        "level2_qa": {
            "question": "In this paper, what specific Reynolds number value marks the lower boundary of the range identified for the transition to three-dimensional dynamics at $\\alpha=14^\\circ$, a flow characteristic implicitly validated by the consistent observation of the frequency-dependent shift from wake to shear layer response modes across all explicitly studied Reynolds numbers ($Re=1000$ and higher) given the stated prerequisite of three-dimensionality for such a modal shift?",
            "options": [
                "A. 380",
                "B. 750",
                "C. 1000",
                "D. 2000",
                "E. 500000"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "750"
            ],
            "img_path": "2501.04255/Overview.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05369",
        "img_path": "2501.05369/pipeline.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. Advancements in Multi-Network Approaches for Enhanced Virtual Fitting",
                "B. Unified Frameworks for Realistic Garment Simulation in Digital Try-On",
                "C. Exploring Deep Learning Architectures for Multi-Stage Virtual Clothing Transfer",
                "D. 1-2-1: Renaissance of Single-Network Paradigm for Virtual Try-On",
                "E. A Comparative Study of Modular Networks in Online Fashion Visualization"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "1-2-1: Renaissance of Single-Network Paradigm for Virtual Try-On"
            ],
            "img_path": "2501.05369/pipeline.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence describes the context—specifically, the assessment of inter-modality relationships and resultant processing utility—that leads to the rejection of independently normalizing garment, target, and text features as a strategy for MNVTON?",
            "options": [
                "A. Combining mismatched modalities, such asFltextsubscriptsuperscript𝐹text𝑙F^{\\rm text}_{l}italic_F start_POSTSUPERSCRIPT roman_text end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPTandFlgarmentsubscriptsuperscript𝐹garment𝑙F^{\\rm garment}_{l}italic_F start_POSTSUPERSCRIPT roman_garment end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT, introduces blurriness and artifacts in the garment features.",
                "B. However, as discussed earlier, the Garment Image and Target Image/Video share similar characteristics, and separating them does not yield additional benefits.",
                "C. Aligning similar modalities, likeFlgarmentsubscriptsuperscript𝐹garment𝑙F^{\\rm garment}_{l}italic_F start_POSTSUPERSCRIPT roman_garment end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPTandFltargetsubscriptsuperscript𝐹target𝑙F^{\\rm target}_{l}italic_F start_POSTSUPERSCRIPT roman_target end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT, produces garment features that are both clear and informative.",
                "D. Text information provides complementary semantic context for VTON task.",
                "E. Our method, namely MNVTON, introduces a Modality-specific Normalization strategy that separately processes text, image and video inputs, enabling them to share the same attention layers in a VTON network."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "However, as discussed earlier, the Garment Image and Target Image/Video share similar characteristics, and separating them does not yield additional benefits."
            ],
            "img_path": "2501.05369/pipeline.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05595",
        "img_path": "2501.05595/framework.jpg",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Human-centered Geospatial Data Science",
                "B. Algorithmic Approaches to Large-scale Geospatial Analytics",
                "C. Machine Learning Techniques for Environmental Spatial Data",
                "D. Statistical Methods in Geospatial Information Processing",
                "E. Automated Spatial Data Integration and Analysis"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Human-centered Geospatial Data Science"
            ],
            "img_path": "2501.05595/framework.jpg"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence encapsulates the fundamental interrogative context that emerges from the insufficient attention to social and ethical implications in Geospatial Data Science, probing the relationship between humans and the technology?",
            "options": [
                "A. However, limited strategies have been developed to address these social and ethical issues associated with Geospatial Data Science.",
                "B. The use and potential misuse of Geospatial Data Science may pose several challenging ethical issues and raise deep concerns related to geoprivacy, bias and fairness, and explainability and transparency(Pavlovskaya,2018; Nelson et al.,2022).",
                "C. Questions arise such as where is the human element in these technologies, and who are the humans behind these technologies?",
                "D. Developing ethical GIScience technology involves prioritizing fundamental human values—fairness, transparency, privacy, safety, trust, inclusivity, sustainability, and legal compliance—to ensure technological innovation respects human rights.",
                "E. Incorporating these human-centered social and ethical considerations into the development of Geospatial Data Science supports more equitable and inclusive design and decision-making, ultimately creating environments that enhance human life and social well-being."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Questions arise such as where is the human element in these technologies, and who are the humans behind these technologies?"
            ],
            "img_path": "2501.05595/framework.jpg",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05474",
        "img_path": "2501.05474/zhutu.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Cross-Modal Attention Mechanisms for Robust Sentiment Classification in Incomplete Data",
                "B. Temporal Fusion Networks for Enhanced Multimodal Emotion Recognition Using Partial Inputs",
                "C. Modality-Invariant Bidirectional Temporal Representation Distillation Network for Missing Multimodal Sentiment Analysis",
                "D. Hierarchical Bidirectional Encoding for Multimodal Sentiment Understanding with Missing Modalities",
                "E. Adaptive Representation Learning for Multimodal Sentiment Analysis under Data Sparsity Conditions"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Modality-Invariant Bidirectional Temporal Representation Distillation Network for Missing Multimodal Sentiment Analysis"
            ],
            "img_path": "2501.05474/zhutu.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the description of existing missing modality MSA studies [22,23,24], what is the total count of distinct categories of loss constraints explicitly mentioned as being employed across their typically separate modality representation learning and modality missing reconstruction modules?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2501.05474/zhutu.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05387",
        "img_path": "2501.05387/PanA_XAI_Methodology.png",
        "level1_qa": {
            "question": "What is the name of the paper associated with this image?",
            "options": [
                "A. Advancing Malware Detection through Deep Learning on Unencrypted Network Traffic",
                "B. A Comparative Study of AI Models for Predicting Network Intrusions in Cloud Environments",
                "C. Utilizing Machine Learning for Anomaly Detection in IoT Device Communications",
                "D. Optimizing Network Security Protocols with Hybrid AI and Signature-Based Methods",
                "E. Integrating Explainable AI for Effective Malware Detection in Encrypted Network Traffic"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Integrating Explainable AI for Effective Malware Detection in Encrypted Network Traffic"
            ],
            "img_path": "2501.05387/PanA_XAI_Methodology.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of raw malicious network traffic samples explicitly stated as collected for the custom dataset construction from sources *other than* the Information Security and Object Lab and the CTU-13 dataset?",
            "options": [
                "A. 175",
                "B. 341",
                "C. 480",
                "D. 516",
                "E. 650"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "480"
            ],
            "img_path": "2501.05387/PanA_XAI_Methodology.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05426",
        "img_path": "2501.05426/x1.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Advancing Brain Tumor Detection Using Deep Learning Techniques",
                "B. Integrating Multimodal Data for Enhanced Neurological Disorder Analysis",
                "C. Evaluating Machine Learning Models in Predicting Cancer Treatment Outcomes",
                "D. Neural Network Approaches for Classifying Medical Imaging in Oncology",
                "E. From Images to Insights: Transforming Brain Cancer Diagnosis with Explainable AI"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "From Images to Insights: Transforming Brain Cancer Diagnosis with Explainable AI"
            ],
            "img_path": "2501.05426/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of MRI images comprising the dataset specifically collected and utilized for the primary investigation, which featured the DenseNet169 model and the application of four distinct Explainable AI techniques (GradCAM, GradCAM++, ScoreCAM, and LayerCAM) to enhance diagnostic transparency?",
            "options": [
                "A. 3,264",
                "B. 4,480",
                "C. 6,056",
                "D. 300,000",
                "E. 3,000"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "6056"
            ],
            "img_path": "2501.05426/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05327",
        "img_path": "2501.05327/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Michael Hentschel",
                "B. Federico Valbusa",
                "C. Costin Luchian",
                "D. Mariana F. Ramos",
                "E. Martin Achleitner"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Mariana F. Ramos"
            ],
            "img_path": "2501.05327/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which operational condition for Oblivious Transfer (OT) generation is most consistent with achieving the 'highest security' fingerprint matching application performance of 128 OTs in 20 minutes and 39 seconds, considering the explicitly stated QOT rates and limitations?",
            "options": [
                "A. The application relied primarily on the back-to-back QOT generation rate, which is stated to be limited by the entanglement source, accepting slower performance to ensure the statistical security for the honest sender.",
                "B. The application's performance indicates the direct and unmodified use of the entanglement source's raw output capacity for QOT generation, corresponding to the $9.3 \\times 10^{-3}$ OTs/second rate, without leveraging any key pre-distribution or similar rate enhancement techniques.",
                "C. The application's reported time for 128 OTs suggests an operational mode for OT generation significantly faster than the baseline back-to-back QOT setup, likely leveraging a mechanism similar in efficiency to the use of pre-distributed keys.",
                "D. The 'highest security' for the fingerprint application was principally achieved by deliberately operating QOT generation at its lowest reported rate (1 minute and 48 seconds per OT) to maximize the statistical correctness and computational hiding properties of the protocol.",
                "E. The 20 minutes and 39 seconds timeframe for 128 OTs is predominantly determined by the computational complexity of the MASCOT protocol and the secret-sharing scheme, largely independent of the underlying physical QOT generation rate."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "The application's reported time for 128 OTs suggests an operational mode for OT generation significantly faster than the baseline back-to-back QOT setup, likely leveraging a mechanism similar in efficiency to the use of pre-distributed keys."
            ],
            "img_path": "2501.05327/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05173",
        "img_path": "2501.05173/x1.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Advances in Metamaterial Antennas for Next-Generation Wireless Networks: A Comprehensive Review",
                "B. Wave-Based Signal Processing Techniques for Optical Communication Systems: Challenges and Opportunities",
                "C. Holographic Metasurfaces Enabling Wave Computing for 6G: Status Overview, Challenges, and Future Research Trends",
                "D. Emerging Trends in Terahertz Metasurfaces for High-Speed Data Transmission",
                "E. Design and Optimization of Reconfigurable Surfaces for Beyond 5G Connectivity"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Holographic Metasurfaces Enabling Wave Computing for 6G: Status Overview, Challenges, and Future Research Trends"
            ],
            "img_path": "2501.05173/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the total number of distinct types of reconfigurable multi-functional metasurfaces explicitly mentioned as motivating the investigation of metasurface technologies for over-the-air manipulation of electromagnetic waves in wireless communication systems, according to the detailed enumeration given in the text?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2501.05173/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04740",
        "img_path": "2501.04740/x3.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Benjamin D. Goddard",
                "B. Yunke Wang",
                "C. Laibin Chang",
                "D. Bo Du",
                "E. Chang Xu"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Laibin Chang"
            ],
            "img_path": "2501.04740/x3.png"
        },
        "level2_qa": {
            "question": "In this paper, how many total strided convolutional layers are used in the condition network of the Global Color Correction (GCC) module, and what is the channel size of each layer?",
            "options": [
                "A. Four strided convolutional layers, each with a channel size of 16",
                "B. Three strided convolutional layers, each with a channel size of 32",
                "C. Two strided convolutional layers, each with a channel size of 32",
                "D. Three strided convolutional layers, each with a channel size of 64",
                "E. Two strided convolutional layers, each with a channel size of 16"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Three strided convolutional layers, each with a channel size of 32"
            ],
            "img_path": "2501.04740/x3.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04985",
        "img_path": "2501.04985/llms_eval.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. SpaLLM-Guard: Pairing SMS Spam Detection Using Open-source and Commercial LLMs",
                "B. Enhancing SMS Spam Filtering with Hybrid Neural Networks and Rule-based Systems",
                "C. Cross-Domain Evaluation of Large Language Models for Email Phishing Detection",
                "D. Multi-Modal Approaches to Text Message Fraud Identification Using Open-Source Algorithms",
                "E. Comparative Analysis of Commercial LLMs in Social Media Content Moderation"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "SpaLLM-Guard: Pairing SMS Spam Detection Using Open-source and Commercial LLMs"
            ],
            "img_path": "2501.04985/llms_eval.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific numerical value, expressed as a percentage, that constitutes the upper limit for both false positive and false negative rates for an LLM strategy to be considered as meeting the criteria for robust SMS spam detection, based on the performance metrics cited for Mixtral?",
            "options": [
                "A. 98.6",
                "B. 2",
                "C. 4",
                "D. 0",
                "E. 1"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.04985/llms_eval.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04908",
        "img_path": "2501.04908/x1.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. SynthNet: Optimizing HDL Code Synthesis Using Deep Learning Techniques",
                "B. VeriGen: Automated Verilog Testbench Creation with Reinforcement Learning",
                "C. CodeAssist: Enhancing HDL Engineer Productivity through AI-Driven Code Recommendations",
                "D. DebugNet: Neural Approaches for Fault Detection in Verilog Designs",
                "E. HaVen: Hallucination-Mitigated LLM for Verilog Code Generation Aligned with HDL Engineers"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "HaVen: Hallucination-Mitigated LLM for Verilog Code Generation Aligned with HDL Engineers"
            ],
            "img_path": "2501.04908/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most accurately delineates the specific approach HaVen employs for embedding HDL engineering practices and detailed Verilog-specific attributes into its code generation process, differentiating this from its methods for handling symbolic or general logical inaccuracies, and specifying the foundational source of this domain-specific enhancement?",
            "options": [
                "A. HaVen's Symbolic Interpretation based Chain-of-Thought (SI-CoT) mechanism translates user prompts containing symbolic modalities into refined natural language, which serves as the primary method for instilling HDL engineering practices and detailed Verilog attributes by ensuring accurate initial specifications.",
                "B. HaVen fine-tunes its CodeGen-LLM using a Knowledge Enhanced Dataset (K-dataset), which is synthesized from curated exemplars derived from textbook exercises and manual designs covering Verilog conventions and attributes, to specifically align generated code with HDL engineering practices and instill detailed Verilog knowledge.",
                "C. The Logical Enhanced Dataset (L-dataset) is primarily responsible for embedding HDL engineering practices and Verilog-specific attributes by fine-tuning the CodeGen-LLM to correct failures in adhering to instructional logic based on high-quality textbook-derived examples.",
                "D. HaVen's primary strategy for instilling HDL engineering practices and Verilog attributes involves a data augmentation process that directly modifies vanilla user prompts using textbook exercises and manual designs before they are processed by the CoT prompting model.",
                "E. The CoT prompting model, by standardizing instructions and appending module headers, is the core component for embedding detailed Verilog knowledge and engineering practices, drawing upon a broad understanding of HDL conventions from its pre-training."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "HaVen fine-tunes its CodeGen-LLM using a Knowledge Enhanced Dataset (K-dataset), which is synthesized from curated exemplars derived from textbook exercises and manual designs covering Verilog conventions and attributes, to specifically align generated code with HDL engineering practices and instill detailed Verilog knowledge."
            ],
            "img_path": "2501.04908/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04595",
        "img_path": "2501.04595/x1.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Adaptive Human-Robot Interaction: Enhancing Mobile Robot Performance with Real-World Data Integration",
                "B. SynthHandoverNet: Leveraging Synthetic Datasets for Collaborative Robot Manipulation Tasks",
                "C. MobileH2R: Learning Generalizable Human to Mobile Robot Handover Exclusively from Scalable and Diverse Synthetic Data",
                "D. Cross-Domain Learning for Efficient Human to Mobile Robot Task Transfer Using Multi-modal Inputs",
                "E. Robotic Grasp Optimization in Mobile Platforms Through Data-Driven Simulation Techniques"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "MobileH2R: Learning Generalizable Human to Mobile Robot Handover Exclusively from Scalable and Diverse Synthetic Data"
            ],
            "img_path": "2501.04595/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct fundamental limitations inherent in previous H2R simulation, data generation, and mobile robot control paradigms does the MobileH2R framework, through its integrated three-component architecture and specific innovations like LLM-enhanced motion prompting, explicitly or implicitly aim to overcome to achieve generalizable vision-based H2MR handover skills?",
            "options": [
                "A. 3",
                "B. 4",
                "C. 5",
                "D. 6",
                "E. 7"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "7"
            ],
            "img_path": "2501.04595/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04947",
        "img_path": "2501.04947/pipeline.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Robust Visual Localization Using Probabilistic Models in Complex Urban Landscapes",
                "B. Seeing with Partial Certainty: Conformal Prediction for Robotic Scene Recognition in Built Environments",
                "C. Uncertainty Quantification Methods for Autonomous Navigation in Indoor Settings",
                "D. Integrating Bayesian Inference with Deep Learning for Enhanced Robotic Perception",
                "E. Adaptive Sensor Fusion Techniques for Environmental Mapping in Smart Cities"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Seeing with Partial Certainty: Conformal Prediction for Robotic Scene Recognition in Built Environments"
            ],
            "img_path": "2501.04947/pipeline.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the definition of `q_hat` as the `ceil((n+1)(1-alpha))/n` percentage quartile of the non-conformity scores `S = {s_i = 1 - f(X_i, Y_i)}`, describe the expected behavior of `q_hat` and its direct consequence on the prediction set construction `C(X_test) = {Y_test | f(X_test, Y_test) >= 1-q_hat}` if the user-chosen error rate `alpha` is set to be extremely close to 1 (e.g., satisfying `alpha >= n/(n+1)`), for a fixed calibration set of size `n > 0`.",
            "options": [
                "A. `q_hat` will approach the maximum non-conformity score observed in `S`, making the threshold `1-q_hat` very low and leading to large prediction sets, a characteristic associated with seeking very high coverage (i.e., `alpha` close to 0).",
                "B. `q_hat` will approach the minimum non-conformity score observed in `S`, resulting in an effectively high decision threshold `1-q_hat`; this aligns with achieving minimal coverage `1-alpha` (close to 0) and consequently tends to produce small or potentially empty prediction sets.",
                "C. `q_hat` will invariably approach 1, because `1-alpha` approaches 0, leading to a decision threshold `1-q_hat` near 0, thus including almost all possible descriptions in the prediction set regardless of the VLM's actual performance on the calibration set.",
                "D. `q_hat` will invariably approach 0, because the term `(1-alpha)` significantly reduces `ceil((n+1)(1-alpha))`, yielding a decision threshold `1-q_hat` near 1; this makes prediction sets small but accurately reflects such `alpha` setting only if the VLM assigned a perfect score `f(X_i,Y_i)=1` to at least one calibration pair.",
                "E. The calculation of `q_hat` becomes ill-defined as `alpha` approaches 1 because `ceil((n+1)(1-alpha))` evaluates to 1, an index too small for standard quartile definitions based on dividing data into four parts, thus invalidating the CP guarantee."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "`q_hat` will approach the minimum non-conformity score observed in `S`, resulting in an effectively high decision threshold `1-q_hat`; this aligns with achieving minimal coverage `1-alpha` (close to 0) and consequently tends to produce small or potentially empty prediction sets."
            ],
            "img_path": "2501.04947/pipeline.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05037",
        "img_path": "2501.05037/x2.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Xiaojian Ma",
                "B. Hai Ci",
                "C. Rujie Wu",
                "D. Yue Fan",
                "E. Yuxuan Wang"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Rujie Wu"
            ],
            "img_path": "2501.05037/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the numerical difference between the GPT-4 score achieved by human annotators and the GPT-4 score achieved by the proprietary model, Gemini-1.5-Pro, on the LongViTU benchmark questions?",
            "options": [
                "A. 2.4",
                "B. 28.7",
                "C. 31.1",
                "D. 52.3",
                "E. 3.7"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "28.7"
            ],
            "img_path": "2501.05037/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05278",
        "img_path": "2501.05278/system_design.png",
        "level1_qa": {
            "question": "What paper does the figure in this image belong to?",
            "options": [
                "A. Off-Policy Evaluation and Counterfactual Methods in Dynamic Auction Environments",
                "B. On-Policy Learning and Simulation Techniques for Static Bidding Models",
                "C. Adaptive Pricing Strategies in Multi-Agent Auction Frameworks",
                "D. Counterfactual Analysis and Reinforcement Learning in Online Marketplaces",
                "E. Dynamic Game Theory Applications in Sequential Bidding Processes"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Off-Policy Evaluation and Counterfactual Methods in Dynamic Auction Environments"
            ],
            "img_path": "2501.05278/system_design.png"
        },
        "level2_qa": {
            "question": "In this paper, provide a single sentence describing the explicit function of Test-3's results when Off-Policy Evaluation (OPE) methods are employed to indirectly assess Policy Y against Policy Z using data solely from Test-1 (X vs Y) and Test-2 (X vs Z).",
            "options": [
                "A. Test-3's results are directly integrated by OPE methods as input data alongside Test-1 and Test-2 to enhance the predictive accuracy of the Y vs Z comparison.",
                "B. Test-3's results provide the ground truth for validating the OPE approaches' capability to accurately compare Policy Y and Policy Z using only the data from Test-1 and Test-2.",
                "C. Test-3's results are used to train the proxy policies Y' and Z' which are then employed by OPE methods to compare Policy Y and Policy Z based on Test-1 and Test-2 data.",
                "D. Test-3's results determine whether Policy Y or Policy Z should be selected for deployment after the OPE methods have conducted the indirect comparison using Test-1 and Test-2 data.",
                "E. Test-3's results are primarily used to optimize the parameters of Policy X before it is used as a baseline in the OPE-driven comparison of Policy Y and Policy Z derived from Test-1 and Test-2."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Test-3's results provide the ground truth for validating the OPE approaches' capability to accurately compare Policy Y and Policy Z using only the data from Test-1 and Test-2."
            ],
            "img_path": "2501.05278/system_design.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05131",
        "img_path": "2501.05131/x2.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Multi-view Synthesis for 3D Reconstruction Using DiT Networks",
                "B. Efficient Scene Rendering with Layered Instance Segmentation",
                "C. Sparse Point Cloud Generation via Differentiable Rendering Techniques",
                "D. 3DIS-FLUX: simple and efficient multi-instance generation with DiT rendering",
                "E. Novel Framework for Real-time 3D Object Detection in Complex Environments"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "3DIS-FLUX: simple and efficient multi-instance generation with DiT rendering"
            ],
            "img_path": "2501.05131/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, by what percentage point value does the Instance Success Ratio (ISR) improvement of 3DIS-FLUX over the state-of-the-art (SOTA) adapter-based method exceed its ISR improvement over the previous 3DIS-SDXL version?",
            "options": [
                "A. 5.5",
                "B. 6.9",
                "C. 12.4",
                "D. 19.3",
                "E. 34.1"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "5.5"
            ],
            "img_path": "2501.05131/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05310",
        "img_path": "2501.05310/x1.png",
        "level1_qa": {
            "question": "Who is the first author of the study depicted in this image?",
            "options": [
                "A. Aemon Yat Fei Chiu",
                "B. Paco Kei Ching Fung",
                "C. Roger Tsz Yeung Li",
                "D. Jingyu Li",
                "E. Tan Lee"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Aemon Yat Fei Chiu"
            ],
            "img_path": "2501.05310/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single term from the text best defines the targeted quality of comprehension regarding speaker representations that the study's comprehensive analysis of speaker-specific and para-linguistic features aims to provide, in contrast to the application-driven focus of most prior investigations?",
            "options": [
                "A. Adaptive",
                "B. Hierarchical",
                "C. Intrinsic",
                "D. Refined",
                "E. Generalised"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "intrinsic"
            ],
            "img_path": "2501.05310/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05228",
        "img_path": "2501.05228/x1.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. Evaluating the Impact of Multimodal Transformers on Image Classification Accuracy",
                "B. Adapting Vision-Language Models for Real-Time Object Recognition in Noisy Environments",
                "C. Exploring Self-Supervised Learning Techniques for Cross-Domain Visual Understanding",
                "D. Integrating Large Language Models with Reinforcement Learning for Enhanced Data Interpretation",
                "E. Harnessing Large Language and Vision-Language Models for Robust Out-of-Distribution Detection"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Harnessing Large Language and Vision-Language Models for Robust Out-of-Distribution Detection"
            ],
            "img_path": "2501.05228/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the experimental validation of the proposed framework's enhanced OOD detection capabilities, what is the specific maximum percentage by which the rate of in-distribution samples being incorrectly classified as out-of-distribution is reduced, when the true positive rate for out-of-distribution samples is maintained at 95%?",
            "options": [
                "A. 2.9",
                "B. 9.7",
                "C. A value greater than 12.6, as \"up to 12.6%\" implies it could be higher but was capped in reporting.",
                "D. A value less than 12.6, representing an average reduction rather than the maximum.",
                "E. 12.6"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "12.6"
            ],
            "img_path": "2501.05228/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05686",
        "img_path": "2501.05686/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Hierarchical Attention Networks for Cross-modal Representation Learning",
                "B. Deep Reversible Consistency Learning for Cross-modal Retrieval",
                "C. Temporal Fusion Techniques in Multi-modal Data Analysis",
                "D. Adversarial Training Strategies for Image-Text Matching",
                "E. Graph-based Embedding Approaches for Hybrid Retrieval Systems"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Deep Reversible Consistency Learning for Cross-modal Retrieval"
            ],
            "img_path": "2501.05686/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, how many distinct categories of limitations specifically concerning prior subspace learning approaches (both traditional and deep learning-based) are detailed in the section discussing the evolution from linear models to deep neural networks for cross-modal retrieval?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 5",
                "E. 6"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "4"
            ],
            "img_path": "2501.05686/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05295",
        "img_path": "2501.05295/x2.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. GaussDB-Cloud: Scalable Database Solutions for Hybrid Environments",
                "B. GaussDB-Edge: Optimizing Data Processing for Distributed Networks",
                "C. GaussDB-Analytics: Enhancing Query Performance in Large-Scale Databases",
                "D. GaussDB-Security: Advanced Encryption Techniques for Distributed Systems",
                "E. GaussDB-Global: A Geographically Distributed Database System"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "GaussDB-Global: A Geographically Distributed Database System"
            ],
            "img_path": "2501.05295/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, considering the bi-directional transition mechanisms between GTM and GClock modes facilitated by DUAL mode, which option precisely identifies the unique set of circumstances and procedural outcomes where the system successfully avoids the abortion of pre-existing transactions *and* concurrently bypasses the mandated DUAL mode interim waiting period before finalizing the switch to the target transaction management mode?",
            "options": [
                "A. During a GTM-to-GClock transition, if all CNs rapidly acknowledge the switch to DUAL mode, this minimizes the error bound, thereby preventing old GTM transaction aborts and eliminating the DUAL mode wait time because DUAL mode itself bridges timestamping.",
                "B. When transitioning from GClock back to GTM mode, the system ensures no old transactions are aborted because the GTM server, having tracked the largest GClock timestamp, issues new GTM timestamps that are definitively larger. This specific transition (GClock-to-GTM) also inherently eliminates the need for a DUAL mode wait period, allowing immediate progression to GTM once all nodes are in DUAL mode.",
                "C. If the GTM server remains in DUAL mode for a duration precisely equal to twice the maximum observed error bound during the GTM-to-DUAL transition, this guarantees that subsequent GClock timestamps will be larger than all previous timestamps, thereby preventing old GTM transaction aborts and rendering the DUAL-to-GClock wait period unnecessary.",
                "D. In any transition involving DUAL mode (either GTM-to-GClock or GClock-to-GTM), if DUAL mode transactions exclusively obtain GClock timestamps first and then request commit timestamps from the GTM server, this unified approach ensures both the avoidance of old transaction aborts and the elimination of any DUAL mode wait period due to the harmonized timestamping.",
                "E. The abortion of old transactions and the DUAL mode wait period are fundamentally unavoidable characteristics of asynchronous replication in geographically distributed systems, and DUAL mode primarily serves to minimize downtime during transitions rather than eliminate these specific issues."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The GTM server keeps track of the largest GClock timestamp issued so far. As a result, no old transactions will need to abort because the GTM server will issue timestamps that are larger than the largest GClock timestamp issued until the moment of transition. This also eliminates the need to wait while in DUAL mode, and nodes can begin switching to GTM mode as soon as all nodes have switched to DUAL mode."
            ],
            "img_path": "2501.05295/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05580",
        "img_path": "2501.05580/x2.png",
        "level1_qa": {
            "question": "Please provide the title of the paper related to this image.",
            "options": [
                "A. Machine Learning Approaches to Forward Simulations in Quantum Field Theory",
                "B. Data-Driven Methods for Parameter Estimation in High-Energy Particle Physics",
                "C. Neural Network Models for Predicting Hadronic Interactions in Particle Colliders",
                "D. Physics-Driven Learning for Inverse Problems in Quantum Chromodynamics",
                "E. Computational Techniques for Solving Direct Problems in Quantum Electrodynamics"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Physics-Driven Learning for Inverse Problems in Quantum Chromodynamics"
            ],
            "img_path": "2501.05580/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the exact number of distinct machine learning architectures explicitly mentioned as being applicable to inverse problems in the context of QCD?",
            "options": [
                "A. Two",
                "B. Three",
                "C. Four",
                "D. Five",
                "E. Six"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "Five"
            ],
            "img_path": "2501.05580/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05452",
        "img_path": "2501.05452/x2.png",
        "level1_qa": {
            "question": "Could you tell me the title of the paper shown here?",
            "options": [
                "A. DeepLens: Enhancing Image Recognition through Sequential Attention Mechanisms",
                "B. StructNet: Integrating Hierarchical Reasoning for Complex Visual Scene Analysis",
                "C. ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding",
                "D. ChainVis: Modeling Multi-Step Reasoning for Semantic Image Segmentation",
                "E. FrameShift: Progressive Visual Transformation for Contextual Understanding in Images"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding"
            ],
            "img_path": "2501.05452/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific average performance gain achieved when finetuning a model with the 14k ReFocus-generated visual chain-of-thought data compared to finetuning the same model with an equivalent set of standard VQA data?",
            "options": [
                "A. 2.6%",
                "B. 6.8%",
                "C. 8.0%",
                "D. 11.0%",
                "E. 8.9%"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "8.0%"
            ],
            "img_path": "2501.05452/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.04670",
        "img_path": "2501.04670/x6.png",
        "level1_qa": {
            "question": "Who is the first author of the study shown in the image?",
            "options": [
                "A. Tao Zhang",
                "B. Shilin Xu",
                "C. Yikang Zhou",
                "D. Shihao Chen",
                "E. Qianyu Zhou"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Yikang Zhou"
            ],
            "img_path": "2501.04670/x6.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific count of visual matching data instances, inclusive of reasoning annotations, that were generated by the described automatic annotation pipeline?",
            "options": [
                "A. 1,510",
                "B. 220,000",
                "C. 790",
                "D. 30",
                "E. 720"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "220000"
            ],
            "img_path": "2501.04670/x6.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05464",
        "img_path": "2501.05464/x1.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Improving Diagnostic Accuracy with Deep Learning Techniques in Medical Imaging",
                "B. Evaluating Clinical Decision Support Systems Using Patient Data Analytics",
                "C. A Comparative Study of Neural Network Architectures for Medical Text Summarization",
                "D. Integrating Electronic Health Records and Natural Language Processing for Treatment Recommendations",
                "E. LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models"
            ],
            "img_path": "2501.05464/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the precise count of distinct types of specialized expert functions that are explicitly listed as being assigned to each query within the multi-agent framework?",
            "options": [
                "A. 2",
                "B. 3",
                "C. 4",
                "D. 7",
                "E. 70"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2501.05464/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05465",
        "img_path": "2501.05465/x1.png",
        "level1_qa": {
            "question": "Which paper does this figure come from?",
            "options": [
                "A. Evaluating the Performance of Medium-Sized Language Models in Contextual Understanding",
                "B. A Comparative Analysis of Large Language Models and Their Training Efficiencies",
                "C. Exploring the Limitations of Tiny Language Models in Complex Natural Language Tasks",
                "D. Advancements in Neural Architectures for Scalable Language Model Deployment",
                "E. Small Language Models (SLMs) Can Still Pack a Punch: A survey"
            ],
            "Ground_Truth": "E",
            "Ground_Truth_List": [
                "Small Language Models (SLMs) Can Still Pack a Punch: A survey"
            ],
            "img_path": "2501.05465/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the specific quantity of training tokens reported for a model that is explicitly identified as an SLM (falling under the general <8B parameter definition, not an exception), which is also noted for its competitive performance achieved after exactly two training epochs?",
            "options": [
                "A. 15 Trillion",
                "B. 2.3 Trillion",
                "C. 1 Million",
                "D. 1.8 Billion",
                "E. 7 Billion"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "2.3 Trillion"
            ],
            "img_path": "2501.05465/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05712",
        "img_path": "2501.05712/HRMCR.png",
        "level1_qa": {
            "question": "What is the title of the paper containing this image?",
            "options": [
                "A. Exploring Sequential Logic Processing in Korean Language Comprehension",
                "B. The Illusion of Complexity in Multi-Level Korean Grammar Structures",
                "C. Multi-Step Reasoning in Korean and the Emergent Mirage",
                "D. Cognitive Pathways and Their Impact on Korean Syntax Interpretation",
                "E. Emergent Patterns in Stepwise Reasoning within East Asian Linguistics"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Multi-Step Reasoning in Korean and the Emergent Mirage"
            ],
            "img_path": "2501.05712/HRMCR.png"
        },
        "level2_qa": {
            "question": "In this paper, describe the authors' interpretation of the 'emergent abilities' observed in LLMs when tested on the HRMCR benchmark.",
            "options": [
                "A. Emergent abilities are definitively confirmed once LLMs exceed \\(2 \\cdot 10^{25}\\) training FLOPs, signifying a fundamental shift in their capacity to perform multi-step, culturally specific reasoning as intended by HRMCR.",
                "B. The 'emergent abilities' observed are attributed by the authors to a critical mass of Korean cultural knowledge being learned, which then unlocks multi-step reasoning, explaining the sudden performance jump.",
                "C. The authors interpret the observed 'emergent abilities' not as a genuinely new capability, but as a phenomenon likely stemming from the compounding of errors across the benchmark's multiple reasoning steps, where the sharp performance increase reflects models overcoming a cumulative error threshold.",
                "D. The authors posit that the HRMCR benchmark's automatic generation of questions with step-by-step solutions inadvertently leads to 'emergent abilities' as models learn to exploit patterns in the solution structures, rather than true reasoning.",
                "E. The authors highlight 'emergent abilities' primarily to underscore the inadequacy of current LLM pre-training (below \\(2 \\cdot 10^{25}\\) FLOPs) for complex reasoning, with the subsequent performance jump being a baseline expectation rather than a novel insight into model capabilities."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Notably, stepwise analysis suggests the observed emergent behavior may stem from compounding errors across multiple steps rather than reflecting a genuinely new capability."
            ],
            "img_path": "2501.05712/HRMCR.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05445",
        "img_path": "2501.05445/x1.png",
        "level1_qa": {
            "question": "Based on the image, what is the title of the paper?",
            "options": [
                "A. Multimodal Fusion Techniques for Enhanced 3D Text Rendering",
                "B. Consistent Flow Distillation for Text-to-3D Generation",
                "C. Adaptive Neural Networks for Real-Time 3D Scene Reconstruction",
                "D. Progressive Refinement Methods in Text-Driven 3D Model Synthesis",
                "E. Context-Aware Generative Models for Interactive 3D Text Applications"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "Consistent Flow Distillation for Text-to-3D Generation"
            ],
            "img_path": "2501.05445/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, when comparing Consistent Flow Distillation (CFD) to prior state-of-the-art score distillation methods in terms of 3D generative quality and diversity, what is the minimum number of different baseline methods (excluding ablation baselines and two-stage pipelines) with which CFD is quantitatively compared using official implementations or reported results?",
            "options": [
                "A. 1",
                "B. 2",
                "C. 3",
                "D. 4",
                "E. 5"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "3"
            ],
            "img_path": "2501.05445/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05948",
        "img_path": "2501.05948/x1.png",
        "level1_qa": {
            "question": "Who conducted the research presented in this image?",
            "options": [
                "A. Runhui Wang",
                "B. Taufiquzzaman Peyash",
                "C. Yash Khare",
                "D. Andrea Vanzo",
                "E. Takuya Yoshioka"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "Yash Khare"
            ],
            "img_path": "2501.05948/x1.png"
        },
        "level2_qa": {
            "question": "In this paper, which single sentence most accurately encapsulates the primary multifaceted advantage offered by the Universal-2-TF model's two-stage neural architecture as presented?",
            "options": [
                "A. This design minimizes computational costs and reduces hallucinations while ensuring flexibility and robustness across diverse linguistic entities and text domains.",
                "B. The model's primary innovation is its capacity for truecasing mixed-case words, a feature notably absent in prior ASR text formatting methodologies.",
                "C. The fundamental strength of the Universal-2-TF model is its exclusive reliance on STT-generated text, thereby achieving high performance without acoustic data.",
                "D. Its key achievement is leveraging a Transformer decoder for ITN to handle diverse entities without handcrafted rules, thus moving beyond traditional rule-based systems.",
                "E. The most critical architectural benefit arises from the shared encoder within the multi-objective classifier, enabling joint PR, truecasing, and span detection for maximal efficiency."
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "This design minimizes computational costs and reduces hallucinations while ensuring flexibility and robustness across diverse linguistic entities and text domains."
            ],
            "img_path": "2501.05948/x1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05756",
        "img_path": "2501.05756/x2.png",
        "level1_qa": {
            "question": "What paper does this image originate from?",
            "options": [
                "A. All-optical computing with beyond 100-GHz clock rates",
                "B. Quantum-dot enabled photonic processors for sub-THz operations",
                "C. Integrated plasmonic circuits for ultrafast signal modulation",
                "D. Hybrid electro-optical architectures for terahertz frequency computing",
                "E. Silicon photonics approaches to GHz-range optical memory devices"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "All-optical computing with beyond 100-GHz clock rates"
            ],
            "img_path": "2501.05756/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, which described operational characteristic of the All-Optical Recurrent Neural Network, when specifically configured for generative tasks by utilizing only its recurrent layer as a highly nonlinear laser cavity, is primarily responsible for enabling the dynamic formation of images through controlled, temporary excursions of cavity modes across the lasing threshold, rather than settling into a steady-state emission typical of conventional lasers?",
            "options": [
                "A. The utilization of quantum fluctuations from spontaneous emission as the sole seed for initiating the generative process.",
                "B. The modulation of gain and intra-cavity connection weights at a clock rate (fc) significantly faster than the cavity roundtrip time, inducing highly non-equilibrium lasing dynamics.",
                "C. The division of the cavity into virtually defined, equally-spaced time bins, where each bin's average power encodes a pixel's greyscale intensity.",
                "D. The inherent Turing-completeness of the Recurrent Neural Network architecture, allowing it to learn and replicate complex image distributions.",
                "E. The employment of a reverse-proton exchange periodically-poled lithium niobate (PPLN) waveguide for strong χ(2) nonlinear optical processes within the recurrent layer."
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "The modulation of gain and intra-cavity connection weights at a clock rate (fc) significantly faster than the cavity roundtrip time, inducing highly non-equilibrium lasing dynamics."
            ],
            "img_path": "2501.05756/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05572",
        "img_path": "2501.05572/Set-Up1.png",
        "level1_qa": {
            "question": "What is the paper's title based on the image provided?",
            "options": [
                "A. Topological advantage for adsorbate chemisorption on conjugated chains",
                "B. Quantum transport phenomena in conjugated polymer systems",
                "C. Impact of molecular topology on electron mobility in organic semiconductors",
                "D. Adsorbate-induced electronic structure changes in carbon-based nanomaterials",
                "E. Role of chain conjugation length on surface catalytic activity"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "Topological advantage for adsorbate chemisorption on conjugated chains"
            ],
            "img_path": "2501.05572/Set-Up1.png"
        },
        "level2_qa": {
            "question": "In this paper, for the trivial phase where electronic friction for the LUMO adparticle is explicitly stated to be absent, what is the specified value of the expression (w-v) associated with the polyacetylene band gap?",
            "options": [
                "A. 0",
                "B. 0.1",
                "C. 1",
                "D. 9.9",
                "E. -0.1"
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "1"
            ],
            "img_path": "2501.05572/Set-Up1.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05755",
        "img_path": "2501.05755/x2.png",
        "level1_qa": {
            "question": "What is the full title of this paper depicted in the image?",
            "options": [
                "A. CognoSpeak: an automatic, remote assessment of early cognitive decline in real-world conversational speech",
                "B. NeuroLex: Automated Analysis of Semantic Patterns in Clinical Speech Samples",
                "C. Remote Monitoring of Language Fluency Variations in Mild Cognitive Impairment",
                "D. DiaTalk: A Machine Learning Approach to Detecting Cognitive Changes through Dialogue",
                "E. SpeechMark: Quantifying Cognitive Load via Real-Time Acoustic Feature Extraction"
            ],
            "Ground_Truth": "A",
            "Ground_Truth_List": [
                "CognoSpeak: an automatic, remote assessment of early cognitive decline in real-world conversational speech"
            ],
            "img_path": "2501.05755/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, given the described limitations of current clinical diagnostic methods such as their high cost, time consumption, and unsuitability for broad cognitive decline screening, and acknowledging the resultant significant rate of under-diagnosis that serves as a primary driver for developing accessible technologies like CognoSpeak, what specific numerical value is presented to quantify the percentage of individuals with early cognitive decline who reportedly do not receive any treatment?",
            "options": [
                "A. 126",
                "B. 50",
                "C. 0.873",
                "D. 75",
                "E. 10"
            ],
            "Ground_Truth": "D",
            "Ground_Truth_List": [
                "75"
            ],
            "img_path": "2501.05755/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    },
    {
        "id": "2501.05510",
        "img_path": "2501.05510/x2.png",
        "level1_qa": {
            "question": "Can you identify the research paper from the image provided?",
            "options": [
                "A. Benchmarking Video-Language Models for Enhanced Offline Video Analysis",
                "B. OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?",
                "C. Evaluating Cross-Modal Learning in Video-Language Models for Streaming Content",
                "D. Assessing Temporal Reasoning Capabilities in Video-Based Language Models",
                "E. Towards Robust Understanding of Video Narratives in Interactive Multimedia Systems"
            ],
            "Ground_Truth": "B",
            "Ground_Truth_List": [
                "OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?"
            ],
            "img_path": "2501.05510/x2.png"
        },
        "level2_qa": {
            "question": "In this paper, what is the count of tasks within the 'Forward Active Responding' scenario for which the generation of questions, answers, and ground-truth timestamps is explicitly attributed to collection by recruited volunteers?",
            "options": [
                "A. 0",
                "B. 1",
                "C. 2",
                "D. 3",
                "E. This specific collection method is not explicitly linked to any task within the 'Forward Active Responding' scenario."
            ],
            "Ground_Truth": "C",
            "Ground_Truth_List": [
                "2"
            ],
            "img_path": "2501.05510/x2.png",
            "question_type": "generated_hard_inferential_v2_text_only_after_seeing_image_openrouter_gemini"
        },
        "source": "Arxiv",
        "time": "2025-01"
    }
]